{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/attach/kubelet.graffle","path":"attach/kubelet.graffle","modified":0,"renderable":0},{"_id":"source/attach/rbm.py","path":"attach/rbm.py","modified":0,"renderable":0},{"_id":"source/images/blacktocat.png","path":"images/blacktocat.png","modified":0,"renderable":0},{"_id":"source/images/bg_hr.png","path":"images/bg_hr.png","modified":0,"renderable":0},{"_id":"source/images/cnn_share.png","path":"images/cnn_share.png","modified":0,"renderable":0},{"_id":"source/images/cnn_lenet5.jpg","path":"images/cnn_lenet5.jpg","modified":0,"renderable":0},{"_id":"source/images/cnn_sparse.png","path":"images/cnn_sparse.png","modified":0,"renderable":0},{"_id":"source/images/icon_download.png","path":"images/icon_download.png","modified":0,"renderable":0},{"_id":"source/images/img322.png","path":"images/img322.png","modified":0,"renderable":0},{"_id":"source/images/img323.png","path":"images/img323.png","modified":0,"renderable":0},{"_id":"source/images/img324.png","path":"images/img324.png","modified":0,"renderable":0},{"_id":"source/images/img325.png","path":"images/img325.png","modified":0,"renderable":0},{"_id":"source/images/img326.png","path":"images/img326.png","modified":0,"renderable":0},{"_id":"source/images/img327.png","path":"images/img327.png","modified":0,"renderable":0},{"_id":"source/images/img319.png","path":"images/img319.png","modified":0,"renderable":0},{"_id":"source/images/img320.png","path":"images/img320.png","modified":0,"renderable":0},{"_id":"source/images/img321.png","path":"images/img321.png","modified":0,"renderable":0},{"_id":"source/images/img328.png","path":"images/img328.png","modified":0,"renderable":0},{"_id":"source/images/img330.png","path":"images/img330.png","modified":0,"renderable":0},{"_id":"source/images/img333.png","path":"images/img333.png","modified":0,"renderable":0},{"_id":"source/images/img331.png","path":"images/img331.png","modified":0,"renderable":0},{"_id":"source/images/img339.png","path":"images/img339.png","modified":0,"renderable":0},{"_id":"source/images/img338.png","path":"images/img338.png","modified":0,"renderable":0},{"_id":"source/images/img334.png","path":"images/img334.png","modified":0,"renderable":0},{"_id":"source/images/img342.png","path":"images/img342.png","modified":0,"renderable":0},{"_id":"source/images/img343.png","path":"images/img343.png","modified":0,"renderable":0},{"_id":"source/images/img344.png","path":"images/img344.png","modified":0,"renderable":0},{"_id":"source/images/iptables-chain.png","path":"images/iptables-chain.png","modified":0,"renderable":0},{"_id":"source/images/rbm_deriv.png","path":"images/rbm_deriv.png","modified":0,"renderable":0},{"_id":"source/images/me.jpg","path":"images/me.jpg","modified":0,"renderable":0},{"_id":"source/images/me2.jpg","path":"images/me2.jpg","modified":0,"renderable":0},{"_id":"source/images/rbm_energy.png","path":"images/rbm_energy.png","modified":0,"renderable":0},{"_id":"source/images/rbm_join_prob.png","path":"images/rbm_join_prob.png","modified":0,"renderable":0},{"_id":"source/images/rbm_marg_v.png","path":"images/rbm_marg_v.png","modified":0,"renderable":0},{"_id":"source/images/rbm_partition.png","path":"images/rbm_partition.png","modified":0,"renderable":0},{"_id":"source/images/rbm_prob_h.png","path":"images/rbm_prob_h.png","modified":0,"renderable":0},{"_id":"source/images/rbm_prob_v.png","path":"images/rbm_prob_v.png","modified":0,"renderable":0},{"_id":"source/images/rbm_updateW.png","path":"images/rbm_updateW.png","modified":0,"renderable":0},{"_id":"source/images/updateW_1.png","path":"images/updateW_1.png","modified":0,"renderable":0},{"_id":"source/images/sprite_download.png","path":"images/sprite_download.png","modified":0,"renderable":0},{"_id":"source/images/xxx.png","path":"images/xxx.png","modified":0,"renderable":0},{"_id":"source/images/k8s-service.png","path":"images/k8s-service.png","modified":0,"renderable":0},{"_id":"source/images/pleg-container-events.png","path":"images/pleg-container-events.png","modified":0,"renderable":0},{"_id":"source/images/rbm.png","path":"images/rbm.png","modified":0,"renderable":0},{"_id":"source/images/sriov01.png","path":"images/sriov01.png","modified":0,"renderable":0},{"_id":"source/images/fip_1.png","path":"images/fip_1.png","modified":0,"renderable":0},{"_id":"themes/maupassant/source/css/jquery.fancybox.css","path":"css/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/maupassant/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/maupassant/source/css/style.scss","path":"css/style.scss","modified":0,"renderable":1},{"_id":"themes/maupassant/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/maupassant/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/maupassant/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/fancybox.js","path":"js/fancybox.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/maupassant/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/codeblock-resizer.js","path":"js/codeblock-resizer.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/share.js","path":"js/share.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/smartresize.js","path":"js/smartresize.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"source/images/kubelet.png","path":"images/kubelet.png","modified":0,"renderable":0},{"_id":"source/images/img_bp.png","path":"images/img_bp.png","modified":0,"renderable":0},{"_id":"source/images/k8s-iptables.png","path":"images/k8s-iptables.png","modified":0,"renderable":0},{"_id":"source/images/addr.png","path":"images/addr.png","modified":0,"renderable":0},{"_id":"source/images/route.png","path":"images/route.png","modified":0,"renderable":0},{"_id":"source/images/bpf.jpg","path":"images/bpf.jpg","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"8ed4065d173acd497300ddffb1531b3cc0ff9950","modified":1550888048179},{"_id":"themes/maupassant/_config.yml","hash":"156994640cf711bf676fed1df3ce24e0f0754952","modified":1488728051000},{"_id":"themes/maupassant/LICENSE","hash":"019dc6a9aba02ae3aaabca45f39aecd6e8e7f1d8","modified":1488710212000},{"_id":"themes/maupassant/.travis.yml","hash":"0339959f29deddc365e8fe8bd85da524410b9a23","modified":1488710212000},{"_id":"themes/maupassant/README.md","hash":"75d8c42569809961953d1934de445418c00ab94c","modified":1488710212000},{"_id":"themes/maupassant/package.json","hash":"81fb4e2ac051ecfb9a93f37b28910291b939771a","modified":1488710212000},{"_id":"source/_drafts/network-draft.md","hash":"af1a41604bd79c290cc945067fcd3dee9a086785","modified":1493199891000},{"_id":"source/_posts/2013-09-08-The-Back-Propagation-Algorithm-Neural-Network.markdown","hash":"7f6b74a63882775623b5d81d701ae29e75e28afa","modified":1488727523000},{"_id":"source/_posts/2013-09-23-Restricted-Boltzmann-Machine.markdown","hash":"c2b1d7170ebe4dcc57bce4a8e669995530d8b84d","modified":1488727534000},{"_id":"source/_posts/2013-09-03-first-page.markdown","hash":"551c9cc3b1cfb5dbfbd11d12271906bdf8366777","modified":1488727275000},{"_id":"source/_posts/2013-10-04-Convolutional-Neural-Network.markdown","hash":"dd000be5e9654fa281b4a323ced6740c6124a163","modified":1488727549000},{"_id":"source/_posts/2015-01-08-connect-nodes-at-same-level.markdown","hash":"cddc7dbc9a3ce8fba70fe6b1b5d14e26292ab5ac","modified":1488808133000},{"_id":"source/_posts/2015-01-09-sort-array-according-order-defined-another-array.markdown","hash":"25a8e60197975c52d2840f030e45f3da303b8f07","modified":1488807974000},{"_id":"source/_posts/2015-01-12-search-an-element-in-a-sorted-and-pivoted-array.markdown","hash":"2e0ac994094a8b913ecb5edef019f1e33ffa7588","modified":1488807868000},{"_id":"source/_posts/2015-11-28-Distributed-Systems-course-6.824-lab2.markdown","hash":"9b36e6f0c6504e5ae293e8324f23796ebc10a7ff","modified":1488727625000},{"_id":"source/_posts/2017-01-21-kubelet.markdown","hash":"6ec288728725c8fc6a1b29b40e7a516a5fa8c5fa","modified":1488727713000},{"_id":"source/_posts/2017-02-28-traffic-control.markdown","hash":"0391568cf8342da1d31539e12fa80f6d372d4f74","modified":1488727631000},{"_id":"source/_posts/2015-11-17-Distributed-Systems-course-6.824-lab1.markdown","hash":"6a0318dd9875187a27c7b34e4423866934d2eff0","modified":1488808381000},{"_id":"source/_posts/2017-03-30-iptables-quick-start.md","hash":"05f57f3565e68ce4235301db328ba59bc36b5992","modified":1490879180000},{"_id":"source/_posts/2017-03-05-golang.markdown","hash":"0ba1fe4b8c511c8329fabfe7800c862aad4f0807","modified":1488807395000},{"_id":"source/_posts/2017-03-07-tcpdump-quick-start.md","hash":"76b082ec8c55d4bae9c4ef1917727be6be967040","modified":1489668429000},{"_id":"source/_posts/2017-03-16-calico-getting-start.md","hash":"e697594a58be302aac9f7ae7f10383c99fe26383","modified":1490149518000},{"_id":"source/_posts/2017-04-18-ipvs-attempt.md","hash":"5547fb1bbca0fea31d726adb17596499acc7d634","modified":1498121623000},{"_id":"source/attach/kubelet.graffle","hash":"6b352b150d94ac7bc9baf608d40e6b7db001545a","modified":1488759284000},{"_id":"source/_posts/2017-06-22-sriov-getting-start.md","hash":"acf6ea02ea964dc96cf58b707ecccfc7af02454b","modified":1498122833000},{"_id":"source/_posts/2018-05-04-k8s-floatingip-evolution.md","hash":"178668047dcd008ba1a9309cb88aefcee4b35703","modified":1525677025713},{"_id":"source/_posts/2019-02-23-k8s-service-ip-problem.md","hash":"2565b00583f694d38df68c3bc0dbe933b8d10a2a","modified":1550887864338},{"_id":"source/attach/rbm.py","hash":"521d987eb2c6c824ede25085027dec304a03e1b9","modified":1488759284000},{"_id":"source/images/blacktocat.png","hash":"4d6897ab7496380b3740dd8d4f80fda5e32cc069","modified":1488727337000},{"_id":"source/images/bg_hr.png","hash":"1495db713f4859f1b77b50b281989138b418e4cc","modified":1488727337000},{"_id":"source/images/cnn_share.png","hash":"36c1dd40d9df62254b869401e20813dcbea432ef","modified":1488727337000},{"_id":"source/images/cnn_lenet5.jpg","hash":"23deaf9c6dab08377a7625245d2a99e3902162ea","modified":1488727337000},{"_id":"source/images/cnn_sparse.png","hash":"cb891f24a325f0fffe579d4834686995ba49086c","modified":1488727337000},{"_id":"source/images/icon_download.png","hash":"0bd93cdb9cb5b6b25f5f0e1d606ca88471ec8841","modified":1488727337000},{"_id":"source/images/img322.png","hash":"0969f75fddfcbcd954cfd184f8ccdcc805aa88cf","modified":1488727337000},{"_id":"source/images/img323.png","hash":"af9bb01d8c92629feb720c06dfe58270f4d2e88b","modified":1488727337000},{"_id":"source/images/img324.png","hash":"709d508ffbb10b3b9771b22b1afd1d87b549607c","modified":1488727337000},{"_id":"source/images/img325.png","hash":"68de11d4d0816c23fd352a30c5e18b771e9c102f","modified":1488727337000},{"_id":"source/images/img326.png","hash":"c6b8fdeb186f086c51a7bef5eea8d0e4431e06b6","modified":1488727337000},{"_id":"source/images/img327.png","hash":"93e6debe358f12c9d9d16484b01809a39cb50962","modified":1488727337000},{"_id":"source/images/img319.png","hash":"314f8b2d368fa3d8baa6bbf10dbd472fba1a4374","modified":1488727337000},{"_id":"source/images/img320.png","hash":"14290727e4d772a732c59956e22b4fc262fc4816","modified":1488727337000},{"_id":"source/images/img321.png","hash":"8f569308494f679eb8c955b9f4df78a0f0817651","modified":1488727337000},{"_id":"source/images/img328.png","hash":"96d62646da701e2cd8e6bf1bc65cf6bcb9d07312","modified":1488727337000},{"_id":"source/images/img330.png","hash":"0d729090821b8a7896adfa5263f663402a6c08d1","modified":1488727337000},{"_id":"source/images/img333.png","hash":"52bc6dd7216bfeb0d34dd18f94faaf44b9334426","modified":1488727337000},{"_id":"source/images/img331.png","hash":"e2a4e68b545cdc077dc23bdf704cf8a0dfdd932a","modified":1488727337000},{"_id":"source/images/img339.png","hash":"3dcdff5c8f0003ec214ed8b8645b45bf1a473049","modified":1488727337000},{"_id":"source/images/img338.png","hash":"65defa51a84e2d597994df25096606afede50bcc","modified":1488727337000},{"_id":"source/images/img334.png","hash":"4282eb513e3596823e4dbadaa4ea2baa55143920","modified":1488727337000},{"_id":"source/images/img342.png","hash":"f28014bc96c3bc442d9ad43e888b3bf128cdce4b","modified":1488727337000},{"_id":"source/images/img343.png","hash":"d11e9dc69ba1c69266e0abdf509b9391de25a892","modified":1488727337000},{"_id":"source/images/img344.png","hash":"809444bb2731f51349a8fd8d2eabdf10a954bf4c","modified":1488727337000},{"_id":"source/images/iptables-chain.png","hash":"8391c95156239f2d5c1d1abfc4dc76cf392aed39","modified":1490875709000},{"_id":"source/images/rbm_deriv.png","hash":"b404d347ebdadf32fe43128863acc2b1afc682a5","modified":1488727337000},{"_id":"source/images/me.jpg","hash":"e49f1cc8e954a15bf94d6206dc3a161b9af4a4a2","modified":1488727337000},{"_id":"source/images/me2.jpg","hash":"862ad02b488d4e9a935f8d60305784ed66c06dc9","modified":1488727337000},{"_id":"source/images/rbm_energy.png","hash":"baba77633bb9973f72cf5ada98e6ded649e6cb0f","modified":1488727337000},{"_id":"source/images/rbm_join_prob.png","hash":"3a5076c327be3db4edcebf92ffa9a6e6f91c4825","modified":1488727337000},{"_id":"source/images/rbm_marg_v.png","hash":"4ce2c433fe0c225b4014f0ee1ba7093b444911f1","modified":1488727337000},{"_id":"source/images/rbm_partition.png","hash":"b1f072f309dacd4543f38785f03e4ebbd9ee617c","modified":1488727337000},{"_id":"source/images/rbm_prob_h.png","hash":"e765e37113082168f18cb974560ce9dcb1f147bf","modified":1488727337000},{"_id":"source/images/rbm_prob_v.png","hash":"73752eafaaa2a64d5711820fcd72a3066f74f73e","modified":1488727337000},{"_id":"source/images/rbm_updateW.png","hash":"940a83a0fafa4b58dc2a2ffe658d9f55697937a1","modified":1488727337000},{"_id":"source/images/updateW_1.png","hash":"6c1a6b2a80eb41dd55a9b543230b94eec8ee3e04","modified":1488727337000},{"_id":"source/images/sprite_download.png","hash":"6350b79a023bfea2aa314e0dc7fec9db2827f511","modified":1488727337000},{"_id":"source/images/xxx.png","hash":"93e6debe358f12c9d9d16484b01809a39cb50962","modified":1488685768000},{"_id":"themes/maupassant/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1488710212000},{"_id":"themes/maupassant/.git/config","hash":"037345b11c41abb3dbbbd6e0242ced24979a7097","modified":1488710212000},{"_id":"source/images/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1525432325721},{"_id":"themes/maupassant/.git/packed-refs","hash":"8aeed9c81ffee31daed3cdfe21471182f83e56e9","modified":1488710212000},{"_id":"themes/maupassant/languages/de-DE.yml","hash":"5d3556a885e355a8c2da65ef3e7b3ee36a628bfa","modified":1488710212000},{"_id":"themes/maupassant/languages/en.yml","hash":"e13ab1a2d2f1edbe67b4c035fd4667cb6a31db8e","modified":1488710212000},{"_id":"themes/maupassant/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1488710207000},{"_id":"themes/maupassant/languages/es-ES.yml","hash":"58e1d04bcd1834fa9d2960e18e027abbbccbedc9","modified":1488710212000},{"_id":"themes/maupassant/languages/ko.yml","hash":"909a33e0befa6978e8e72157c6b415b48551ee31","modified":1488710212000},{"_id":"themes/maupassant/languages/fr-FR.yml","hash":"b47906ec0abf867fb3e3360bc046b7afb68aee25","modified":1488710212000},{"_id":"themes/maupassant/.git/index","hash":"3b15590efebb4c19c77d30177a7aa06e291337c1","modified":1492505306000},{"_id":"themes/maupassant/languages/zh-CN.yml","hash":"ebacfa5d0c14d603e0d505757adb24c0bbe5dd13","modified":1488710212000},{"_id":"themes/maupassant/languages/zh-TW.yml","hash":"56b65995c60e99dcebbf00168447fd225d28e5b2","modified":1488710212000},{"_id":"themes/maupassant/layout/index.jade","hash":"f842164f6cba007c1dfcd7fe7bba24736bc886a9","modified":1488710212000},{"_id":"themes/maupassant/layout/single-column.jade","hash":"c35fff4d9b331a41af5bc10f4278ec3d9da503db","modified":1488710212000},{"_id":"themes/maupassant/layout/page.jade","hash":"8d70fd3b93f2c9087a9ea7ec538dcc1d413bea01","modified":1488710212000},{"_id":"themes/maupassant/layout/post.jade","hash":"9cf29fb0daed95935154ce0fa2b154df5a9b11b1","modified":1488710212000},{"_id":"themes/maupassant/layout/timeline.jade","hash":"f03d8df63a188543cfe4e85e76194abe081411a1","modified":1488710212000},{"_id":"themes/maupassant/layout/archive.jade","hash":"0050c883b4f202add71c8664d65e6072179e7190","modified":1488710212000},{"_id":"themes/maupassant/layout/base-without-sidebar.jade","hash":"779c736a61a999292156ed23625b46e4ad69af86","modified":1488710212000},{"_id":"themes/maupassant/layout/base.jade","hash":"ed5ae4c326bec4100e0c5efbd3d04949530be71c","modified":1488710212000},{"_id":"source/images/k8s-service.png","hash":"2f921bbc2df43210e9e38bb2a91e0a5032c42cff","modified":1550884698295},{"_id":"source/images/pleg-container-events.png","hash":"dff00278618a45d5d4cc668033e97b4b0b48ca95","modified":1488727337000},{"_id":"source/images/rbm.png","hash":"c79956a1cc8370784b79a8badcf08a5b8adc8f4e","modified":1488727337000},{"_id":"source/images/sriov01.png","hash":"225f645c7561616e63e00e83bdd2206a7bb41574","modified":1498103126000},{"_id":"source/images/fip_1.png","hash":"546877346a120de36b91970cc276a751092eb409","modified":1525432362332},{"_id":"themes/maupassant/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1488710207000},{"_id":"themes/maupassant/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1488710207000},{"_id":"themes/maupassant/.git/logs/HEAD","hash":"edd71bf2439257373df9f4247c78781a33c71da4","modified":1488710212000},{"_id":"themes/maupassant/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1488710207000},{"_id":"themes/maupassant/layout/_widget/category.jade","hash":"7c6aed762934ca51aa2669b886254da24b77bc14","modified":1488710212000},{"_id":"themes/maupassant/layout/_widget/recent_posts.jade","hash":"19431336d724d2118e46da43683bce9063176541","modified":1488710212000},{"_id":"themes/maupassant/layout/_widget/recent_comments.jade","hash":"e119c5afa85abc60d139e2da99b0bfcd7a6530f8","modified":1488710212000},{"_id":"themes/maupassant/layout/_widget/search.jade","hash":"193546282908e499813534f86d27ef6e0a1357b3","modified":1488710212000},{"_id":"themes/maupassant/layout/_widget/tag.jade","hash":"132f049ce677d0e38f50073174c4ee4b825d4a06","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/after_footer.jade","hash":"3dbcc9a9f0d6e55da191d3393c18bbfcfe99fa69","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/comments.jade","hash":"6c7f63ba04a4d28323ba31e79a4927f3d3fcc56e","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/helpers.jade","hash":"acdf9e2d52ee86c831fa15ce1570930c5779bc78","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/footer.jade","hash":"aa020b794e697e8e9612530c97c6295efde469fe","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/mathjax.jade","hash":"b54b56faff9e47ab3ca3cdd55056c73e60776f3c","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/mathjax2.jade","hash":"d6ac5dc4e9c7a1b866f1f92d88988cfb35aded4c","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/tag.jade","hash":"0f0e6770e9d5dd8040e330d71bbbfadd2df36a28","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/paginator.jade","hash":"53f9cb77448e84a98da5eb688e2e12b173c555bb","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/post_nav.jade","hash":"a2d698c84bb6da08195fe870dbd7215f65388d3f","modified":1488710212000},{"_id":"themes/maupassant/layout/_partial/totop.jade","hash":"8225bbc3cdb9648bc2e6872e5c616a9a1e4def4f","modified":1488710212000},{"_id":"themes/maupassant/layout/_widget/links.jade","hash":"f57a0c76d243882b2b77330132bdb43bc648948b","modified":1488710212000},{"_id":"themes/maupassant/source/css/jquery.fancybox.css","hash":"f42f761157f26244673eb2f4a9215c70956f80dc","modified":1488710212000},{"_id":"themes/maupassant/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1488710212000},{"_id":"themes/maupassant/source/css/style.scss","hash":"158f1ebecf7b994ffae5332a627465f6bf38113b","modified":1488710212000},{"_id":"themes/maupassant/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1488710212000},{"_id":"themes/maupassant/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1488710212000},{"_id":"themes/maupassant/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1488710212000},{"_id":"themes/maupassant/source/js/fancybox.js","hash":"13c4781570339f4fba76a3d7f202e442817dd605","modified":1488710212000},{"_id":"themes/maupassant/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1488710212000},{"_id":"themes/maupassant/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1488710212000},{"_id":"themes/maupassant/source/js/codeblock-resizer.js","hash":"5d0b786d60bf225d9eabcc9cece2719ff4d9b6cd","modified":1488710212000},{"_id":"themes/maupassant/source/js/search.js","hash":"0c0630e2ef213701d393b041f10572e951a27985","modified":1488710212000},{"_id":"themes/maupassant/source/js/share.js","hash":"f49776e0baa2b913ddc7a20db24b3edd469c8343","modified":1488710212000},{"_id":"themes/maupassant/source/js/smartresize.js","hash":"3ef157fd877167e3290f42c67a624ea375a46c24","modified":1488710212000},{"_id":"themes/maupassant/source/js/totop.js","hash":"7dbf8fcf582a4fb6eb9b2c60d6de9f9c2091ec4c","modified":1488710212000},{"_id":"source/images/kubelet.png","hash":"428e056247ec8e758f33b19cb5a46b27ccc3b768","modified":1488727337000},{"_id":"themes/maupassant/.git/refs/heads/master","hash":"77e07bd7afcad178079617a76eac285e03d4a873","modified":1488710212000},{"_id":"themes/maupassant/.git/objects/pack/pack-3a8a25b0b8206682007a1a2bf060e3ea8fa41fe0.idx","hash":"cae1b2f4aec5181f304bd88a53f8131dbb9090b6","modified":1488710212000},{"_id":"source/images/img_bp.png","hash":"9d1e18a3b4cf4f68881e2a3d0264cdd226a6c3a9","modified":1488727337000},{"_id":"source/images/k8s-iptables.png","hash":"3a3ee3d5c6e2f7e4ee3b312e580cdec439897116","modified":1550884714982},{"_id":"themes/maupassant/.git/logs/refs/heads/master","hash":"edd71bf2439257373df9f4247c78781a33c71da4","modified":1488710212000},{"_id":"themes/maupassant/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1488710212000},{"_id":"themes/maupassant/.git/logs/refs/remotes/origin/HEAD","hash":"edd71bf2439257373df9f4247c78781a33c71da4","modified":1488710212000},{"_id":"source/images/addr.png","hash":"1f8a6791e72a8214d0bce46b372085be40b553d9","modified":1550884736748},{"_id":"themes/maupassant/.git/objects/pack/pack-3a8a25b0b8206682007a1a2bf060e3ea8fa41fe0.pack","hash":"9224b576c7d3fd5e5ed26f1e0d3b24b4050503c5","modified":1488710212000},{"_id":"source/images/route.png","hash":"3c78fcfcdb27c68170c0934d214dec407717477f","modified":1550884726347},{"_id":"public/2019/02/23/k8s-service-ip-problem/index.html","hash":"0a82d65f051d83ba495b552801f53caca8bfab97","modified":1578819643317},{"_id":"public/2018/05/04/k8s-floatingip-evolution/index.html","hash":"159b640b99541c1aa9f547b49fcec3a4cfa5df23","modified":1578819643318},{"_id":"public/2017/06/22/sriov-getting-start/index.html","hash":"0ee066511f37305e30cb2d8f498223215a29e874","modified":1578819643319},{"_id":"public/2017/03/30/iptables-quick-start/index.html","hash":"b2820abfd1e031f610c5f4440a5f4eaa0ce7557f","modified":1578819643319},{"_id":"public/2017/04/18/ipvs-attempt/index.html","hash":"522af332604f5e95962de4bf554078510d20d327","modified":1578819643319},{"_id":"public/2017/03/07/tcpdump-quick-start/index.html","hash":"15841da63f3436f9c62bd8a0ceb7921e70c3e426","modified":1578819643319},{"_id":"public/2015/11/28/Distributed-Systems-course-6.824-lab2/index.html","hash":"a7e62e3d251ef86fe4720d054d31920673c14f18","modified":1578819643320},{"_id":"public/2015/01/09/sort-array-according-order-defined-another-array/index.html","hash":"e428137a0f0f9593297561aff6ea82b652b79562","modified":1578819643320},{"_id":"public/2015/01/08/connect-nodes-at-same-level/index.html","hash":"ade196453d010968a088743832547cd1f83f8ca5","modified":1578819643320},{"_id":"public/2013/09/23/Restricted-Boltzmann-Machine/index.html","hash":"12fd4e6a0061a6243ed9e63d91fbaa218a00a3c3","modified":1578819643320},{"_id":"public/2013/10/04/Convolutional-Neural-Network/index.html","hash":"49453dc030eeae7eddd1aa17e37ec3fe3414804f","modified":1578819643320},{"_id":"public/2015/01/12/search-an-element-in-a-sorted-and-pivoted-array/index.html","hash":"f130533fa0b5382ac6538541e85b4b3e52c7309a","modified":1578819643320},{"_id":"public/2017/03/05/golang/index.html","hash":"506eaa7500a66c543d6fc3cc17efe93a3905cc47","modified":1578819643319},{"_id":"public/archives/index.html","hash":"6a6715718e40a8a10823c90bfd678b45d08e997d","modified":1578819643320},{"_id":"public/archives/2013/index.html","hash":"da9b840c645c912fe9f17f486baf3085d2bc976d","modified":1578819643321},{"_id":"public/2013/09/08/The-Back-Propagation-Algorithm-Neural-Network/index.html","hash":"c58ed05881564b99e934fec06c0934b47edd42f6","modified":1578819643320},{"_id":"public/archives/page/2/index.html","hash":"83f47cc8ee65eab8e6f782a1953fba0efdfcf4b6","modified":1578819643321},{"_id":"public/archives/2013/10/index.html","hash":"a3ab6c1d913edf5801599df6d2645bdc2e7ac631","modified":1578819643321},{"_id":"public/archives/2015/index.html","hash":"ffbb2a04f8792344d5382069c549ba5b214c2a3f","modified":1578819643321},{"_id":"public/archives/2015/01/index.html","hash":"c5c8b960d2dfe277fa6ab09daf7be421f99dddb0","modified":1578819643321},{"_id":"public/archives/2015/11/index.html","hash":"1bcbe2bfe38fd3f60f331e6fae61bb34f9f0f520","modified":1578819643321},{"_id":"public/archives/2017/index.html","hash":"3ee8ca1359a8e30e4ec4fb04fbe5f6fdd8fd9fd2","modified":1578819643321},{"_id":"public/archives/2017/01/index.html","hash":"87dfb1c4f5db542be5685c28dce694151f6bdf3d","modified":1578819643321},{"_id":"public/archives/2017/02/index.html","hash":"10ecba3444cf8d867ca2d4b497a6e525b11c40dd","modified":1578819643322},{"_id":"public/archives/2017/03/index.html","hash":"daf7501d877ab40e2b49abf1911ce0fad453fe46","modified":1578819643322},{"_id":"public/archives/2017/04/index.html","hash":"960cf3743db67e13585228648c64e739b37610b2","modified":1578819643322},{"_id":"public/archives/2017/06/index.html","hash":"c9ef18e7b6e525700bf5207c76e5cc901d4badd9","modified":1578819643322},{"_id":"public/archives/2018/index.html","hash":"932d735e5425fbebc568cb31d493f77ba5c6d25f","modified":1578819643322},{"_id":"public/archives/2018/05/index.html","hash":"932d735e5425fbebc568cb31d493f77ba5c6d25f","modified":1578819643322},{"_id":"public/archives/2019/index.html","hash":"9b8cece4b3be4c0d7d1442adfccc17d0a362dc53","modified":1578819643322},{"_id":"public/archives/2019/02/index.html","hash":"9b8cece4b3be4c0d7d1442adfccc17d0a362dc53","modified":1578819643322},{"_id":"public/page/2/index.html","hash":"f18c35f5a15be3003e73d7235d1e5d2c9619cf53","modified":1578819643322},{"_id":"public/index.html","hash":"5f44dd119c354d3e9f27dae3789e3ef9459ca69a","modified":1578819643322},{"_id":"public/2013/09/03/first-page/index.html","hash":"a9988e02a06100a8858929d1ca6d2bdb577ad4bd","modified":1578819643321},{"_id":"public/tags/neural-network/index.html","hash":"8192f569cf0b92c90398853ab80fa926e0a11c58","modified":1578819643322},{"_id":"public/tags/algorithm/index.html","hash":"10ac3f768617734f68043b583e3ba206ddd41582","modified":1578819643322},{"_id":"public/archives/2013/09/index.html","hash":"f5176e3ec3a4dc21f33a0e01ea6d8fda9730b209","modified":1578819643321},{"_id":"public/tags/kubernetes/index.html","hash":"2b104b4bb0146317a88236cebe8b7701c50d8742","modified":1578819643322},{"_id":"public/tags/tc/index.html","hash":"da8d4a6e9c9cd9a817febe45a2d4c8b8a818b84b","modified":1578819643322},{"_id":"public/tags/kubelet/index.html","hash":"39cd7c90eeed4f71f804228401187117f73b6519","modified":1578819643322},{"_id":"public/tags/network/index.html","hash":"c1a3172e7b47859bf6139687ef5fffaf3c330baa","modified":1578819643323},{"_id":"public/tags/others/index.html","hash":"57677a03b8e879641247c56ccd86c8686d47e4ed","modified":1578819643322},{"_id":"public/tags/tcpdump/index.html","hash":"ae42603dd8c62040a5c54437131073f4292186f4","modified":1578819643323},{"_id":"public/tags/golang/index.html","hash":"2b823d4c6e837ff6bf22ce1426295c386e5c0ae4","modified":1578819643323},{"_id":"public/tags/calico/index.html","hash":"ddd04aed8a3af18abdf412d213fa5dfbf5878c28","modified":1578819643323},{"_id":"public/categories/algorithm/index.html","hash":"10ac3f768617734f68043b583e3ba206ddd41582","modified":1578819643322},{"_id":"public/categories/Distributed-System/index.html","hash":"56952c55e6ac7ad0f7b2167650b79c2a9ab369de","modified":1578819643322},{"_id":"public/categories/lang/index.html","hash":"b2ee51a77d10b2e72f130afdb21c3749a23cdcf5","modified":1578819643322},{"_id":"public/tags/Distributed-System/index.html","hash":"4902c8cabe49faaab2a706bc4712cee9112a82d1","modified":1578819643323},{"_id":"public/tags/lang/index.html","hash":"b2ee51a77d10b2e72f130afdb21c3749a23cdcf5","modified":1578819643323},{"_id":"public/2017/02/28/traffic-control/index.html","hash":"ad98140cb6ad0925eef4a2acf7007aee63534953","modified":1578819643323},{"_id":"public/2017/01/21/kubelet/index.html","hash":"4db3e1092e017d580d3cef12d783b2f56d3f6bfc","modified":1578819643323},{"_id":"public/2017/03/16/calico-getting-start/index.html","hash":"444f834c1bff696c965d882c33f4ffc9a3b1bb34","modified":1578819643323},{"_id":"public/2015/11/17/Distributed-Systems-course-6.824-lab1/index.html","hash":"df1440c43309acc8dd0410947890ed15399f8f43","modified":1578819643323},{"_id":"public/attach/kubelet.graffle","hash":"6b352b150d94ac7bc9baf608d40e6b7db001545a","modified":1578819386004},{"_id":"public/images/bg_hr.png","hash":"1495db713f4859f1b77b50b281989138b418e4cc","modified":1578819386004},{"_id":"public/attach/rbm.py","hash":"521d987eb2c6c824ede25085027dec304a03e1b9","modified":1578819386004},{"_id":"public/images/blacktocat.png","hash":"4d6897ab7496380b3740dd8d4f80fda5e32cc069","modified":1578819386004},{"_id":"public/images/cnn_sparse.png","hash":"cb891f24a325f0fffe579d4834686995ba49086c","modified":1578819386004},{"_id":"public/images/icon_download.png","hash":"0bd93cdb9cb5b6b25f5f0e1d606ca88471ec8841","modified":1578819386004},{"_id":"public/images/img322.png","hash":"0969f75fddfcbcd954cfd184f8ccdcc805aa88cf","modified":1578819386004},{"_id":"public/images/img323.png","hash":"af9bb01d8c92629feb720c06dfe58270f4d2e88b","modified":1578819386004},{"_id":"public/images/cnn_share.png","hash":"36c1dd40d9df62254b869401e20813dcbea432ef","modified":1578819386004},{"_id":"public/images/img324.png","hash":"709d508ffbb10b3b9771b22b1afd1d87b549607c","modified":1578819386004},{"_id":"public/images/img325.png","hash":"68de11d4d0816c23fd352a30c5e18b771e9c102f","modified":1578819386004},{"_id":"public/images/img326.png","hash":"c6b8fdeb186f086c51a7bef5eea8d0e4431e06b6","modified":1578819386004},{"_id":"public/images/img327.png","hash":"93e6debe358f12c9d9d16484b01809a39cb50962","modified":1578819386004},{"_id":"public/images/img319.png","hash":"314f8b2d368fa3d8baa6bbf10dbd472fba1a4374","modified":1578819386004},{"_id":"public/images/img320.png","hash":"14290727e4d772a732c59956e22b4fc262fc4816","modified":1578819386005},{"_id":"public/images/img321.png","hash":"8f569308494f679eb8c955b9f4df78a0f0817651","modified":1578819386005},{"_id":"public/images/img328.png","hash":"96d62646da701e2cd8e6bf1bc65cf6bcb9d07312","modified":1578819386005},{"_id":"public/images/img330.png","hash":"0d729090821b8a7896adfa5263f663402a6c08d1","modified":1578819386005},{"_id":"public/images/img331.png","hash":"e2a4e68b545cdc077dc23bdf704cf8a0dfdd932a","modified":1578819386005},{"_id":"public/images/img338.png","hash":"65defa51a84e2d597994df25096606afede50bcc","modified":1578819386005},{"_id":"public/images/img339.png","hash":"3dcdff5c8f0003ec214ed8b8645b45bf1a473049","modified":1578819386005},{"_id":"public/images/img334.png","hash":"4282eb513e3596823e4dbadaa4ea2baa55143920","modified":1578819386005},{"_id":"public/images/img342.png","hash":"f28014bc96c3bc442d9ad43e888b3bf128cdce4b","modified":1578819386005},{"_id":"public/images/img343.png","hash":"d11e9dc69ba1c69266e0abdf509b9391de25a892","modified":1578819386006},{"_id":"public/images/img344.png","hash":"809444bb2731f51349a8fd8d2eabdf10a954bf4c","modified":1578819386006},{"_id":"public/images/iptables-chain.png","hash":"8391c95156239f2d5c1d1abfc4dc76cf392aed39","modified":1578819386006},{"_id":"public/images/rbm_deriv.png","hash":"b404d347ebdadf32fe43128863acc2b1afc682a5","modified":1578819386006},{"_id":"public/images/me.jpg","hash":"e49f1cc8e954a15bf94d6206dc3a161b9af4a4a2","modified":1578819386006},{"_id":"public/images/rbm_join_prob.png","hash":"3a5076c327be3db4edcebf92ffa9a6e6f91c4825","modified":1578819386006},{"_id":"public/images/rbm_partition.png","hash":"b1f072f309dacd4543f38785f03e4ebbd9ee617c","modified":1578819386006},{"_id":"public/images/me2.jpg","hash":"862ad02b488d4e9a935f8d60305784ed66c06dc9","modified":1578819386006},{"_id":"public/images/rbm_prob_h.png","hash":"e765e37113082168f18cb974560ce9dcb1f147bf","modified":1578819386006},{"_id":"public/images/rbm_marg_v.png","hash":"4ce2c433fe0c225b4014f0ee1ba7093b444911f1","modified":1578819386006},{"_id":"public/images/rbm_energy.png","hash":"baba77633bb9973f72cf5ada98e6ded649e6cb0f","modified":1578819386006},{"_id":"public/images/rbm_prob_v.png","hash":"73752eafaaa2a64d5711820fcd72a3066f74f73e","modified":1578819386006},{"_id":"public/images/rbm_updateW.png","hash":"940a83a0fafa4b58dc2a2ffe658d9f55697937a1","modified":1578819386006},{"_id":"public/images/updateW_1.png","hash":"6c1a6b2a80eb41dd55a9b543230b94eec8ee3e04","modified":1578819386006},{"_id":"public/images/sprite_download.png","hash":"6350b79a023bfea2aa314e0dc7fec9db2827f511","modified":1578819386006},{"_id":"public/images/xxx.png","hash":"93e6debe358f12c9d9d16484b01809a39cb50962","modified":1578819386006},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1578819386008},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1578819386008},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1578819386008},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1578819386008},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1578819386008},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1578819386008},{"_id":"public/images/cnn_lenet5.jpg","hash":"23deaf9c6dab08377a7625245d2a99e3902162ea","modified":1578819386042},{"_id":"public/images/img333.png","hash":"52bc6dd7216bfeb0d34dd18f94faaf44b9334426","modified":1578819386042},{"_id":"public/images/k8s-service.png","hash":"2f921bbc2df43210e9e38bb2a91e0a5032c42cff","modified":1578819386043},{"_id":"public/images/rbm.png","hash":"c79956a1cc8370784b79a8badcf08a5b8adc8f4e","modified":1578819386043},{"_id":"public/images/pleg-container-events.png","hash":"dff00278618a45d5d4cc668033e97b4b0b48ca95","modified":1578819386043},{"_id":"public/images/sriov01.png","hash":"225f645c7561616e63e00e83bdd2206a7bb41574","modified":1578819386043},{"_id":"public/css/jquery.fancybox.css","hash":"f42f761157f26244673eb2f4a9215c70956f80dc","modified":1578819386057},{"_id":"public/js/codeblock-resizer.js","hash":"5d0b786d60bf225d9eabcc9cece2719ff4d9b6cd","modified":1578819386057},{"_id":"public/js/smartresize.js","hash":"3ef157fd877167e3290f42c67a624ea375a46c24","modified":1578819386057},{"_id":"public/js/share.js","hash":"f49776e0baa2b913ddc7a20db24b3edd469c8343","modified":1578819386057},{"_id":"public/js/totop.js","hash":"7dbf8fcf582a4fb6eb9b2c60d6de9f9c2091ec4c","modified":1578819386057},{"_id":"public/css/style.css","hash":"2afb6e7e24abf81c8b7b7d472fb0bb9b9a1eac16","modified":1578819386057},{"_id":"public/images/fip_1.png","hash":"546877346a120de36b91970cc276a751092eb409","modified":1578819386057},{"_id":"public/js/fancybox.js","hash":"13c4781570339f4fba76a3d7f202e442817dd605","modified":1578819386062},{"_id":"public/js/search.js","hash":"0c0630e2ef213701d393b041f10572e951a27985","modified":1578819386062},{"_id":"public/images/kubelet.png","hash":"428e056247ec8e758f33b19cb5a46b27ccc3b768","modified":1578819386065},{"_id":"public/images/img_bp.png","hash":"9d1e18a3b4cf4f68881e2a3d0264cdd226a6c3a9","modified":1578819386074},{"_id":"public/images/k8s-iptables.png","hash":"3a3ee3d5c6e2f7e4ee3b312e580cdec439897116","modified":1578819386077},{"_id":"public/images/addr.png","hash":"1f8a6791e72a8214d0bce46b372085be40b553d9","modified":1578819386090},{"_id":"public/images/route.png","hash":"3c78fcfcdb27c68170c0934d214dec407717477f","modified":1578819386091},{"_id":"source/_posts/2020-01-07-ebpf-intro.md","hash":"d848460c7fd8b75ca1e923ae706d6bdb53654cf7","modified":1578819633480},{"_id":"source/_posts/2020-01-08-linux-kernel-build-and-submit-patch.md","hash":"1b42c14f09a722dccc7ea662c567808c2724d45e","modified":1578819633480},{"_id":"source/images/bpf.jpg","hash":"ee6abf0ac717b6552e753aa063af13f05a876ab5","modified":1578819633481},{"_id":"public/archives/page/3/index.html","hash":"649d96b1af4589c631047b2d371ef7fb50b32369","modified":1578819643326},{"_id":"public/archives/2020/index.html","hash":"862344501137e193ccfd56a526b51e858356f302","modified":1578819643326},{"_id":"public/archives/2020/01/index.html","hash":"862344501137e193ccfd56a526b51e858356f302","modified":1578819643326},{"_id":"public/page/3/index.html","hash":"e467f386eac0cfec5daa26887ded083521f779d4","modified":1578819643326},{"_id":"public/tags/ebpf/index.html","hash":"65c1a7a8bcf56bf4265cf4ef1ffb8addeba3d3d5","modified":1578819643326},{"_id":"public/tags/kernel/index.html","hash":"03b66cdf76b36906c48d56f7dce750c2fa6dab76","modified":1578819643326},{"_id":"public/2020/01/07/ebpf-intro/index.html","hash":"0240c9b0d08b5e3d1bb6c07ebf523a90b8486c62","modified":1578819643326},{"_id":"public/2020/01/08/linux-kernel-build-and-submit-patch/index.html","hash":"d89eea71219c566231b4f0e3c1b6d60b0e3201c3","modified":1578819643326},{"_id":"public/images/bpf.jpg","hash":"ee6abf0ac717b6552e753aa063af13f05a876ab5","modified":1578819643328}],"Category":[{"name":"algorithm","_id":"ck5asapz0000aphv9se6o7cms"},{"name":"Distributed System","_id":"ck5asapz9000rphv9b6gzs199"},{"name":"lang","_id":"ck5asaqif0019phv97batfqk8"}],"Data":[],"Page":[],"Post":[{"title":"network draft","_content":"\n> 介绍一些常见的名词\n\n1. [hairpin](https://supportforums.cisco.com/discussion/11650736/hairpin)\n\n\thairpin一般是交换机的一个功能。通常，一次arp请求查询ip对应的mac地址时，交换机会将该请求发给源端口以外的其他所有端口。如果需要将该请求发回源端口查询，就需要交换机开启hairpin模式。[这篇文档](http://blog.csdn.net/dog250/article/details/45788279)中提到了hairpin。\n\n2. [promiscuous mode, 混杂模式](https://en.wikipedia.org/wiki/Promiscuous_mode)\n\n\t在混杂模式下，网卡会接受那些目的地址并非本卡地址的包\n\n3. [proxy arp](https://en.wikipedia.org/wiki/Proxy_ARP)\n\n\t代理ARP，主要是一个设备应到目的地址不是它的ARP请求。例如路由开启代理ARP，由于子网A所在的路由器知道如何将请求发送给主机B，子网A中的主机发送ARP获取子网B的主机的MAC地址时，路由器会将自己的MAC地址告诉主机A，这样主机A的arp表中主机B的IP对应的MAC地址其实就是路由器的地址。可以看[这个例子](http://www.cisco.com/c/zh_cn/support/docs/ip/dynamic-address-allocation-resolution/13718-5.html)","source":"_drafts/network-draft.md","raw":"---\ntitle: network draft\ntags:\n---\n\n> 介绍一些常见的名词\n\n1. [hairpin](https://supportforums.cisco.com/discussion/11650736/hairpin)\n\n\thairpin一般是交换机的一个功能。通常，一次arp请求查询ip对应的mac地址时，交换机会将该请求发给源端口以外的其他所有端口。如果需要将该请求发回源端口查询，就需要交换机开启hairpin模式。[这篇文档](http://blog.csdn.net/dog250/article/details/45788279)中提到了hairpin。\n\n2. [promiscuous mode, 混杂模式](https://en.wikipedia.org/wiki/Promiscuous_mode)\n\n\t在混杂模式下，网卡会接受那些目的地址并非本卡地址的包\n\n3. [proxy arp](https://en.wikipedia.org/wiki/Proxy_ARP)\n\n\t代理ARP，主要是一个设备应到目的地址不是它的ARP请求。例如路由开启代理ARP，由于子网A所在的路由器知道如何将请求发送给主机B，子网A中的主机发送ARP获取子网B的主机的MAC地址时，路由器会将自己的MAC地址告诉主机A，这样主机A的arp表中主机B的IP对应的MAC地址其实就是路由器的地址。可以看[这个例子](http://www.cisco.com/c/zh_cn/support/docs/ip/dynamic-address-allocation-resolution/13718-5.html)","slug":"network-draft","published":0,"date":"2017-03-06T13:31:48.000Z","updated":"2017-04-26T09:44:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asapym0000phv9ejmjlhir","content":"<blockquote>\n<p>介绍一些常见的名词</p>\n</blockquote>\n<ol>\n<li><p><a href=\"https://supportforums.cisco.com/discussion/11650736/hairpin\" target=\"_blank\" rel=\"external\">hairpin</a></p>\n<p> hairpin一般是交换机的一个功能。通常，一次arp请求查询ip对应的mac地址时，交换机会将该请求发给源端口以外的其他所有端口。如果需要将该请求发回源端口查询，就需要交换机开启hairpin模式。<a href=\"http://blog.csdn.net/dog250/article/details/45788279\" target=\"_blank\" rel=\"external\">这篇文档</a>中提到了hairpin。</p>\n</li>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Promiscuous_mode\" target=\"_blank\" rel=\"external\">promiscuous mode, 混杂模式</a></p>\n<p> 在混杂模式下，网卡会接受那些目的地址并非本卡地址的包</p>\n</li>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Proxy_ARP\" target=\"_blank\" rel=\"external\">proxy arp</a></p>\n<p> 代理ARP，主要是一个设备应到目的地址不是它的ARP请求。例如路由开启代理ARP，由于子网A所在的路由器知道如何将请求发送给主机B，子网A中的主机发送ARP获取子网B的主机的MAC地址时，路由器会将自己的MAC地址告诉主机A，这样主机A的arp表中主机B的IP对应的MAC地址其实就是路由器的地址。可以看<a href=\"http://www.cisco.com/c/zh_cn/support/docs/ip/dynamic-address-allocation-resolution/13718-5.html\" target=\"_blank\" rel=\"external\">这个例子</a></p>\n</li>\n</ol>\n","excerpt":"","more":"<blockquote>\n<p>介绍一些常见的名词</p>\n</blockquote>\n<ol>\n<li><p><a href=\"https://supportforums.cisco.com/discussion/11650736/hairpin\">hairpin</a></p>\n<p> hairpin一般是交换机的一个功能。通常，一次arp请求查询ip对应的mac地址时，交换机会将该请求发给源端口以外的其他所有端口。如果需要将该请求发回源端口查询，就需要交换机开启hairpin模式。<a href=\"http://blog.csdn.net/dog250/article/details/45788279\">这篇文档</a>中提到了hairpin。</p>\n</li>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Promiscuous_mode\">promiscuous mode, 混杂模式</a></p>\n<p> 在混杂模式下，网卡会接受那些目的地址并非本卡地址的包</p>\n</li>\n<li><p><a href=\"https://en.wikipedia.org/wiki/Proxy_ARP\">proxy arp</a></p>\n<p> 代理ARP，主要是一个设备应到目的地址不是它的ARP请求。例如路由开启代理ARP，由于子网A所在的路由器知道如何将请求发送给主机B，子网A中的主机发送ARP获取子网B的主机的MAC地址时，路由器会将自己的MAC地址告诉主机A，这样主机A的arp表中主机B的IP对应的MAC地址其实就是路由器的地址。可以看<a href=\"http://www.cisco.com/c/zh_cn/support/docs/ip/dynamic-address-allocation-resolution/13718-5.html\">这个例子</a></p>\n</li>\n</ol>\n"},{"layout":"post","title":"The BackPropagation Algorithm---Neural Network","_content":"\n\n原始文章见[这里](http://www.speech.sri.com/people/anand/771/html/node37.html)\n\nBack-Propagation NN(BP，反向传播神经网络)是一种简单的含隐层(hidden layer)的神经网络，主要由两步完成对数据的训练：\n\n**1. 前向传播**\n\n> 前向传播主要是计算在当前的权值参数下，各个神经单元的输出。每个神经单元的输出是上一个神经单元的输出与连接边上权值的线性组合，即输入向量与权值向量的内积。而神经单元的输出则是对输入经过非线性变化的结果，通常采用sigmoid函数进行非线性变换。\n> 每一层上各个神经单元的输出都作为输入输连接到下一层的神经单元\n\n**2. 反向反馈**\n> 根据前向传播计算的结果，在输出单元上，可以得到输出的误差。根据输出的误差，将其反馈给产生这些误差的神经单元中，对各个神经单元的连接权重进行调整。\n\n在介绍BP之前，先声明几个符号：\n\n* ![Xj](/images/img319.png) 表示单元j的输入单元向量（Xji表示输入到j的第i个单元）。\n* ![Wj](/images/img320.png) 表示连接到j单元上的权重向量（Wji表示单元i与单元j之间的权重）。\n* ![Zj](/images/img321.png) 输入到j单元上的权重\n* Oj 表示j单元的输出（![Oj](/images/img322.png)）\n* Tj 表示j单元的目标输出（由训练集中给出）\n* Downstream(j) 表示与单元j直接相连的下一层神经单元集合\n* Outputs 表示最后一层单元上的输出\n\n由于神经网络的训练过程是针对每个训练集个体的输入进行参数调整，所以这里只需要将训练集看成一个样本简化即可。这里把误差用E进行简单表示。下面介绍参数调整过程。\n\n首先，对于每一个输出单元j，我们希望计算输入权重Wji的![delta(E)/delta(Wij)](/images/img323.png)。\n\n![Wji](/images/img324.png)\n\n由于无论输入到上j上的需要更新的权重是多少，![deltaZj](/images/img325.png)总是一样的，我们把它标记为![deltaj](/images/img326.png)。\n\n考虑 ![j](/images/img327.png)，我们可以知道：\n\n![E](/images/img328.png)\n\n对于所有的输出单元k，当k不等于j时，输出单元都与Wji想独立，所以我们可以把加和符号去掉，简单的用j上的E进行表示。\n\n![deltaj](/images/img330.png)\n\n于是：\n\n![deltaWji](/images/img331.png)\n\n现在考虑当j是hidden layer的单元时。我们首先观察得出以下两个重要的性质：\n1. 对于每一个属于Downstream(j)的单元k，Zk是关于Zj的函数。\n2. 同一层中除了j之外的其他所有单元l对最终错误的贡献独立于Wji\n\n同样，对于每一个hidden layer上的单元j，我们希望计算权重Wji的![delta(E)/delta(Wij)](/images/img323.png)。\n注意到Wji影响Zj进而影响Oj进而影响![Zk](/images/img333.png)进而影响到了E，所以我们可以得出：\n\n![deltaE/deltaWji](/images/img334.png)\n\n跟上面一样，我们可以把除了上式中Xji意外的项表示为![deltaJ](/images/img326.png)。带入得：\n\n![deltaJ](/images/img338.png)\n\n因此可得：\n\n![deltaJ](/images/img339.png)\n\n*<center>上式左边的k是j</center>*\n\n\n---\n\n## 算法的正式描述\n1. 创建一个包含Ni和输入单元，Nh个hidden单元，No个输出单元的神经网络.\n2. 初始化各个权重Wji\n3. 直到满足终止condition：\n\n> 对于每一个训练样本：\n>> 根据输入计算输出\n\n>> 对于每一个输出单元k，计算\n\n![deltaK](/images/img342.png)\n\n>> 对于每一个hidden layer的单元h，计算：\n\n![deltah](/images/img343.png)\n\n>> 根据下面公式进行更新：\n\n![Wji](/images/img344.png)\n\n一体化公式见下图：\n\n![BP](/images/img_bp.png)\n\n","source":"_posts/2013-09-08-The-Back-Propagation-Algorithm-Neural-Network.markdown","raw":"---\nlayout: post\ntitle: The BackPropagation Algorithm---Neural Network\ntag: [neural network]\n---\n\n\n原始文章见[这里](http://www.speech.sri.com/people/anand/771/html/node37.html)\n\nBack-Propagation NN(BP，反向传播神经网络)是一种简单的含隐层(hidden layer)的神经网络，主要由两步完成对数据的训练：\n\n**1. 前向传播**\n\n> 前向传播主要是计算在当前的权值参数下，各个神经单元的输出。每个神经单元的输出是上一个神经单元的输出与连接边上权值的线性组合，即输入向量与权值向量的内积。而神经单元的输出则是对输入经过非线性变化的结果，通常采用sigmoid函数进行非线性变换。\n> 每一层上各个神经单元的输出都作为输入输连接到下一层的神经单元\n\n**2. 反向反馈**\n> 根据前向传播计算的结果，在输出单元上，可以得到输出的误差。根据输出的误差，将其反馈给产生这些误差的神经单元中，对各个神经单元的连接权重进行调整。\n\n在介绍BP之前，先声明几个符号：\n\n* ![Xj](/images/img319.png) 表示单元j的输入单元向量（Xji表示输入到j的第i个单元）。\n* ![Wj](/images/img320.png) 表示连接到j单元上的权重向量（Wji表示单元i与单元j之间的权重）。\n* ![Zj](/images/img321.png) 输入到j单元上的权重\n* Oj 表示j单元的输出（![Oj](/images/img322.png)）\n* Tj 表示j单元的目标输出（由训练集中给出）\n* Downstream(j) 表示与单元j直接相连的下一层神经单元集合\n* Outputs 表示最后一层单元上的输出\n\n由于神经网络的训练过程是针对每个训练集个体的输入进行参数调整，所以这里只需要将训练集看成一个样本简化即可。这里把误差用E进行简单表示。下面介绍参数调整过程。\n\n首先，对于每一个输出单元j，我们希望计算输入权重Wji的![delta(E)/delta(Wij)](/images/img323.png)。\n\n![Wji](/images/img324.png)\n\n由于无论输入到上j上的需要更新的权重是多少，![deltaZj](/images/img325.png)总是一样的，我们把它标记为![deltaj](/images/img326.png)。\n\n考虑 ![j](/images/img327.png)，我们可以知道：\n\n![E](/images/img328.png)\n\n对于所有的输出单元k，当k不等于j时，输出单元都与Wji想独立，所以我们可以把加和符号去掉，简单的用j上的E进行表示。\n\n![deltaj](/images/img330.png)\n\n于是：\n\n![deltaWji](/images/img331.png)\n\n现在考虑当j是hidden layer的单元时。我们首先观察得出以下两个重要的性质：\n1. 对于每一个属于Downstream(j)的单元k，Zk是关于Zj的函数。\n2. 同一层中除了j之外的其他所有单元l对最终错误的贡献独立于Wji\n\n同样，对于每一个hidden layer上的单元j，我们希望计算权重Wji的![delta(E)/delta(Wij)](/images/img323.png)。\n注意到Wji影响Zj进而影响Oj进而影响![Zk](/images/img333.png)进而影响到了E，所以我们可以得出：\n\n![deltaE/deltaWji](/images/img334.png)\n\n跟上面一样，我们可以把除了上式中Xji意外的项表示为![deltaJ](/images/img326.png)。带入得：\n\n![deltaJ](/images/img338.png)\n\n因此可得：\n\n![deltaJ](/images/img339.png)\n\n*<center>上式左边的k是j</center>*\n\n\n---\n\n## 算法的正式描述\n1. 创建一个包含Ni和输入单元，Nh个hidden单元，No个输出单元的神经网络.\n2. 初始化各个权重Wji\n3. 直到满足终止condition：\n\n> 对于每一个训练样本：\n>> 根据输入计算输出\n\n>> 对于每一个输出单元k，计算\n\n![deltaK](/images/img342.png)\n\n>> 对于每一个hidden layer的单元h，计算：\n\n![deltah](/images/img343.png)\n\n>> 根据下面公式进行更新：\n\n![Wji](/images/img344.png)\n\n一体化公式见下图：\n\n![BP](/images/img_bp.png)\n\n","slug":"The-Back-Propagation-Algorithm-Neural-Network","published":1,"date":"2013-09-07T16:00:00.000Z","updated":"2017-03-05T15:25:23.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapyq0001phv996qzh3c8","content":"<p>原始文章见<a href=\"http://www.speech.sri.com/people/anand/771/html/node37.html\" target=\"_blank\" rel=\"external\">这里</a></p>\n<p>Back-Propagation NN(BP，反向传播神经网络)是一种简单的含隐层(hidden layer)的神经网络，主要由两步完成对数据的训练：</p>\n<p><strong>1. 前向传播</strong></p>\n<blockquote>\n<p>前向传播主要是计算在当前的权值参数下，各个神经单元的输出。每个神经单元的输出是上一个神经单元的输出与连接边上权值的线性组合，即输入向量与权值向量的内积。而神经单元的输出则是对输入经过非线性变化的结果，通常采用sigmoid函数进行非线性变换。<br>每一层上各个神经单元的输出都作为输入输连接到下一层的神经单元</p>\n</blockquote>\n<p><strong>2. 反向反馈</strong></p>\n<blockquote>\n<p>根据前向传播计算的结果，在输出单元上，可以得到输出的误差。根据输出的误差，将其反馈给产生这些误差的神经单元中，对各个神经单元的连接权重进行调整。</p>\n</blockquote>\n<p>在介绍BP之前，先声明几个符号：</p>\n<ul>\n<li><img src=\"/images/img319.png\" alt=\"Xj\"> 表示单元j的输入单元向量（Xji表示输入到j的第i个单元）。</li>\n<li><img src=\"/images/img320.png\" alt=\"Wj\"> 表示连接到j单元上的权重向量（Wji表示单元i与单元j之间的权重）。</li>\n<li><img src=\"/images/img321.png\" alt=\"Zj\"> 输入到j单元上的权重</li>\n<li>Oj 表示j单元的输出（<img src=\"/images/img322.png\" alt=\"Oj\">）</li>\n<li>Tj 表示j单元的目标输出（由训练集中给出）</li>\n<li>Downstream(j) 表示与单元j直接相连的下一层神经单元集合</li>\n<li>Outputs 表示最后一层单元上的输出</li>\n</ul>\n<p>由于神经网络的训练过程是针对每个训练集个体的输入进行参数调整，所以这里只需要将训练集看成一个样本简化即可。这里把误差用E进行简单表示。下面介绍参数调整过程。</p>\n<p>首先，对于每一个输出单元j，我们希望计算输入权重Wji的<img src=\"/images/img323.png\" alt=\"delta(E)/delta(Wij)\">。</p>\n<p><img src=\"/images/img324.png\" alt=\"Wji\"></p>\n<p>由于无论输入到上j上的需要更新的权重是多少，<img src=\"/images/img325.png\" alt=\"deltaZj\">总是一样的，我们把它标记为<img src=\"/images/img326.png\" alt=\"deltaj\">。</p>\n<p>考虑 <img src=\"/images/img327.png\" alt=\"j\">，我们可以知道：</p>\n<p><img src=\"/images/img328.png\" alt=\"E\"></p>\n<p>对于所有的输出单元k，当k不等于j时，输出单元都与Wji想独立，所以我们可以把加和符号去掉，简单的用j上的E进行表示。</p>\n<p><img src=\"/images/img330.png\" alt=\"deltaj\"></p>\n<p>于是：</p>\n<p><img src=\"/images/img331.png\" alt=\"deltaWji\"></p>\n<p>现在考虑当j是hidden layer的单元时。我们首先观察得出以下两个重要的性质：</p>\n<ol>\n<li>对于每一个属于Downstream(j)的单元k，Zk是关于Zj的函数。</li>\n<li>同一层中除了j之外的其他所有单元l对最终错误的贡献独立于Wji</li>\n</ol>\n<p>同样，对于每一个hidden layer上的单元j，我们希望计算权重Wji的<img src=\"/images/img323.png\" alt=\"delta(E)/delta(Wij)\">。<br>注意到Wji影响Zj进而影响Oj进而影响<img src=\"/images/img333.png\" alt=\"Zk\">进而影响到了E，所以我们可以得出：</p>\n<p><img src=\"/images/img334.png\" alt=\"deltaE/deltaWji\"></p>\n<p>跟上面一样，我们可以把除了上式中Xji意外的项表示为<img src=\"/images/img326.png\" alt=\"deltaJ\">。带入得：</p>\n<p><img src=\"/images/img338.png\" alt=\"deltaJ\"></p>\n<p>因此可得：</p>\n<p><img src=\"/images/img339.png\" alt=\"deltaJ\"></p>\n<p><em><center>上式左边的k是j</center></em></p>\n<hr>\n<h2 id=\"算法的正式描述\"><a href=\"#算法的正式描述\" class=\"headerlink\" title=\"算法的正式描述\"></a>算法的正式描述</h2><ol>\n<li>创建一个包含Ni和输入单元，Nh个hidden单元，No个输出单元的神经网络.</li>\n<li>初始化各个权重Wji</li>\n<li>直到满足终止condition：</li>\n</ol>\n<blockquote>\n<p>对于每一个训练样本：</p>\n<blockquote>\n<p>根据输入计算输出</p>\n<p>对于每一个输出单元k，计算</p>\n</blockquote>\n</blockquote>\n<p><img src=\"/images/img342.png\" alt=\"deltaK\"></p>\n<blockquote>\n<blockquote>\n<p>对于每一个hidden layer的单元h，计算：</p>\n</blockquote>\n</blockquote>\n<p><img src=\"/images/img343.png\" alt=\"deltah\"></p>\n<blockquote>\n<blockquote>\n<p>根据下面公式进行更新：</p>\n</blockquote>\n</blockquote>\n<p><img src=\"/images/img344.png\" alt=\"Wji\"></p>\n<p>一体化公式见下图：</p>\n<p><img src=\"/images/img_bp.png\" alt=\"BP\"></p>\n","excerpt":"","more":"<p>原始文章见<a href=\"http://www.speech.sri.com/people/anand/771/html/node37.html\">这里</a></p>\n<p>Back-Propagation NN(BP，反向传播神经网络)是一种简单的含隐层(hidden layer)的神经网络，主要由两步完成对数据的训练：</p>\n<p><strong>1. 前向传播</strong></p>\n<blockquote>\n<p>前向传播主要是计算在当前的权值参数下，各个神经单元的输出。每个神经单元的输出是上一个神经单元的输出与连接边上权值的线性组合，即输入向量与权值向量的内积。而神经单元的输出则是对输入经过非线性变化的结果，通常采用sigmoid函数进行非线性变换。<br>每一层上各个神经单元的输出都作为输入输连接到下一层的神经单元</p>\n</blockquote>\n<p><strong>2. 反向反馈</strong></p>\n<blockquote>\n<p>根据前向传播计算的结果，在输出单元上，可以得到输出的误差。根据输出的误差，将其反馈给产生这些误差的神经单元中，对各个神经单元的连接权重进行调整。</p>\n</blockquote>\n<p>在介绍BP之前，先声明几个符号：</p>\n<ul>\n<li><img src=\"/images/img319.png\" alt=\"Xj\"> 表示单元j的输入单元向量（Xji表示输入到j的第i个单元）。</li>\n<li><img src=\"/images/img320.png\" alt=\"Wj\"> 表示连接到j单元上的权重向量（Wji表示单元i与单元j之间的权重）。</li>\n<li><img src=\"/images/img321.png\" alt=\"Zj\"> 输入到j单元上的权重</li>\n<li>Oj 表示j单元的输出（<img src=\"/images/img322.png\" alt=\"Oj\">）</li>\n<li>Tj 表示j单元的目标输出（由训练集中给出）</li>\n<li>Downstream(j) 表示与单元j直接相连的下一层神经单元集合</li>\n<li>Outputs 表示最后一层单元上的输出</li>\n</ul>\n<p>由于神经网络的训练过程是针对每个训练集个体的输入进行参数调整，所以这里只需要将训练集看成一个样本简化即可。这里把误差用E进行简单表示。下面介绍参数调整过程。</p>\n<p>首先，对于每一个输出单元j，我们希望计算输入权重Wji的<img src=\"/images/img323.png\" alt=\"delta(E)/delta(Wij)\">。</p>\n<p><img src=\"/images/img324.png\" alt=\"Wji\"></p>\n<p>由于无论输入到上j上的需要更新的权重是多少，<img src=\"/images/img325.png\" alt=\"deltaZj\">总是一样的，我们把它标记为<img src=\"/images/img326.png\" alt=\"deltaj\">。</p>\n<p>考虑 <img src=\"/images/img327.png\" alt=\"j\">，我们可以知道：</p>\n<p><img src=\"/images/img328.png\" alt=\"E\"></p>\n<p>对于所有的输出单元k，当k不等于j时，输出单元都与Wji想独立，所以我们可以把加和符号去掉，简单的用j上的E进行表示。</p>\n<p><img src=\"/images/img330.png\" alt=\"deltaj\"></p>\n<p>于是：</p>\n<p><img src=\"/images/img331.png\" alt=\"deltaWji\"></p>\n<p>现在考虑当j是hidden layer的单元时。我们首先观察得出以下两个重要的性质：</p>\n<ol>\n<li>对于每一个属于Downstream(j)的单元k，Zk是关于Zj的函数。</li>\n<li>同一层中除了j之外的其他所有单元l对最终错误的贡献独立于Wji</li>\n</ol>\n<p>同样，对于每一个hidden layer上的单元j，我们希望计算权重Wji的<img src=\"/images/img323.png\" alt=\"delta(E)/delta(Wij)\">。<br>注意到Wji影响Zj进而影响Oj进而影响<img src=\"/images/img333.png\" alt=\"Zk\">进而影响到了E，所以我们可以得出：</p>\n<p><img src=\"/images/img334.png\" alt=\"deltaE/deltaWji\"></p>\n<p>跟上面一样，我们可以把除了上式中Xji意外的项表示为<img src=\"/images/img326.png\" alt=\"deltaJ\">。带入得：</p>\n<p><img src=\"/images/img338.png\" alt=\"deltaJ\"></p>\n<p>因此可得：</p>\n<p><img src=\"/images/img339.png\" alt=\"deltaJ\"></p>\n<p><em><center>上式左边的k是j</center></em></p>\n<hr>\n<h2 id=\"算法的正式描述\"><a href=\"#算法的正式描述\" class=\"headerlink\" title=\"算法的正式描述\"></a>算法的正式描述</h2><ol>\n<li>创建一个包含Ni和输入单元，Nh个hidden单元，No个输出单元的神经网络.</li>\n<li>初始化各个权重Wji</li>\n<li>直到满足终止condition：</li>\n</ol>\n<blockquote>\n<p>对于每一个训练样本：</p>\n<blockquote>\n<p>根据输入计算输出</p>\n<p>对于每一个输出单元k，计算</p>\n</blockquote>\n</blockquote>\n<p><img src=\"/images/img342.png\" alt=\"deltaK\"></p>\n<blockquote>\n<blockquote>\n<p>对于每一个hidden layer的单元h，计算：</p>\n</blockquote>\n</blockquote>\n<p><img src=\"/images/img343.png\" alt=\"deltah\"></p>\n<blockquote>\n<blockquote>\n<p>根据下面公式进行更新：</p>\n</blockquote>\n</blockquote>\n<p><img src=\"/images/img344.png\" alt=\"Wji\"></p>\n<p>一体化公式见下图：</p>\n<p><img src=\"/images/img_bp.png\" alt=\"BP\"></p>\n"},{"layout":"post","title":"Restricted Boltzmann Machine","_content":"\n**受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)**是由Hinton和Sejnowski于1986年提出的一种生成式随机神经网络(generative stochastic neural network)。由于deep learning的基本网络结构DBN可以用RBM堆叠而成，所以这里先介绍RBM。\n\nRBM是一个能量模型，当一个事物到达稳定状态时，它的能量是最少的。所以一旦知道模型的能量函数，就能够将模型问题转化为函数优化问题。\n\nRBM网络如下图所示：\n\n![rbm](/images/rbm.png)\n\n可以看出，RBM网络主要有两层，输入层（也叫可视层）和隐含层（也叫特征提取层）。为了简单起见，在本文中，将网络中的所有神经元都看成是2值的(0, 1)。首先给出该模型的能量方程：\n\n![energy](/images/rbm_energy.png)                   (1)\n\n这里vi, hj分别表示可视层和隐含层单元的二值数值，ai, bj表示他们的bias，wij是两者连接边的权重。\n\n通过能量函数，网络为每个可视层向量和隐含层向量对分配一个联合概率：\n\n![join_prob](/images/rbm_join_prob.png)             (2)\n\nZ是归一化因子，也叫partition function：\n\n![partition](/images/rbm_partition.png)             (3)\n\n根据公式(2)，可以得出可视层的边缘概率为：\n\n![marg_v](/images/rbm_marg_v.png)                   (4)\n\n由于上面的v是真实的training data，所以我们希望它的值能尽可能的大。从上式可以看出，为了到达这一点，可以调整wij, ai, bj, 以到达降低当前输入向量的energy(E), 提高其它向量的energy。通过以上分析，我们得到了优化目标函数就是P(v)。对其的log求导可以得到：\n\n![deriv](/images/rbm_deriv.png)                      (5)\n\n其中，<>表示的是均值。```<vihj>data```表示vi*hj在训练数据的均值。```<vihj>model```表示vi*hj在模型上的均值。\n\n由此，我们可以对wij参数矩阵进行跟新：\n\n![update](/images/rbm_updateW.png)                   (6)\n\n其中epsilon是学习率。由于每一层的单元不会与本层单元发生连接，所以单元之间是独立的。对于给定的训练数据向量，可以根据一定的概率得到隐含层的二值概率：\n\n![prob_h](/images/rbm_prob_h.png)                    (7)\n\n这里sigma表示sigmoid激活函数: sigm(x)=1/(1+exp(-x))。\n\n同理，当给定隐含层的输入向量时，也可以得到可视层向量的二值概率：\n\n![prob_c](/images/rbm_prob_v.png)                    (8)\n\n根据公式(7)，我们可以很容易的得出```<vihj>data```的值，但是却无法直接得到```<vihj>model```的值。原因是即使在二值网络模型中，model的组合情况也是2^(|V|+|H|)，|V|和|H|分别表示可视层和隐含层的单元个数。这里可以使用Gibbs采样进行估计，但是Hinton在2002年提出了一个更加快速有效的方法：CD(Contrastive Divergence)。\n\n该方法首先初始化可视层状态为一个训练数据向量，然后根据公式(7)计算隐含层单元的二值状态。一旦隐含层的二值状态被确定，又可以根据公式(8)重新构造(reconstruction)输入层二值单元。将此时网络中的二值单元当做是模型的状态。于是wij更新函数可以表示为：\n\n![update_1](/images/updateW_1.png)                   (9)\n\n重复迭代以上过程知道训练效果到达预期。就可以得到一个RBM网络。\n\n关于RBM的实现可以参考[这个](/attach/rbm.py)python代码。该程序的原网址在[这里](https://github.com/echen/restricted-boltzmann-machines/blob/master/rbm.py)。\n\n参考文献：\n\n1. [受限玻尔兹曼机(Restricted Boltzmann Machine, RBM) 简介](http://www.cnblogs.com/kemaswill/p/3203605.html)\n2. [Deep learning：十九(RBM简单理解)](http://www.cnblogs.com/tornadomeet/archive/2013/03/27/2984725.html)\n3. [Introduction to Restricted Boltzmann Machines](http://edchedch.wordpress.com/2011/07/18/introduction-to-restricted-boltzmann-machines/)\n4. [A Practical Guide to Training Restricted Boltzmann Machines](http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)\n5. [Training products of experts by minimizing contrastive divergence](http://www.cs.toronto.edu/~hinton/absps/tr00-004.pdf)\n\n","source":"_posts/2013-09-23-Restricted-Boltzmann-Machine.markdown","raw":"---\nlayout: post\ntitle: Restricted Boltzmann Machine\ntag: [neural network]\n---\n\n**受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)**是由Hinton和Sejnowski于1986年提出的一种生成式随机神经网络(generative stochastic neural network)。由于deep learning的基本网络结构DBN可以用RBM堆叠而成，所以这里先介绍RBM。\n\nRBM是一个能量模型，当一个事物到达稳定状态时，它的能量是最少的。所以一旦知道模型的能量函数，就能够将模型问题转化为函数优化问题。\n\nRBM网络如下图所示：\n\n![rbm](/images/rbm.png)\n\n可以看出，RBM网络主要有两层，输入层（也叫可视层）和隐含层（也叫特征提取层）。为了简单起见，在本文中，将网络中的所有神经元都看成是2值的(0, 1)。首先给出该模型的能量方程：\n\n![energy](/images/rbm_energy.png)                   (1)\n\n这里vi, hj分别表示可视层和隐含层单元的二值数值，ai, bj表示他们的bias，wij是两者连接边的权重。\n\n通过能量函数，网络为每个可视层向量和隐含层向量对分配一个联合概率：\n\n![join_prob](/images/rbm_join_prob.png)             (2)\n\nZ是归一化因子，也叫partition function：\n\n![partition](/images/rbm_partition.png)             (3)\n\n根据公式(2)，可以得出可视层的边缘概率为：\n\n![marg_v](/images/rbm_marg_v.png)                   (4)\n\n由于上面的v是真实的training data，所以我们希望它的值能尽可能的大。从上式可以看出，为了到达这一点，可以调整wij, ai, bj, 以到达降低当前输入向量的energy(E), 提高其它向量的energy。通过以上分析，我们得到了优化目标函数就是P(v)。对其的log求导可以得到：\n\n![deriv](/images/rbm_deriv.png)                      (5)\n\n其中，<>表示的是均值。```<vihj>data```表示vi*hj在训练数据的均值。```<vihj>model```表示vi*hj在模型上的均值。\n\n由此，我们可以对wij参数矩阵进行跟新：\n\n![update](/images/rbm_updateW.png)                   (6)\n\n其中epsilon是学习率。由于每一层的单元不会与本层单元发生连接，所以单元之间是独立的。对于给定的训练数据向量，可以根据一定的概率得到隐含层的二值概率：\n\n![prob_h](/images/rbm_prob_h.png)                    (7)\n\n这里sigma表示sigmoid激活函数: sigm(x)=1/(1+exp(-x))。\n\n同理，当给定隐含层的输入向量时，也可以得到可视层向量的二值概率：\n\n![prob_c](/images/rbm_prob_v.png)                    (8)\n\n根据公式(7)，我们可以很容易的得出```<vihj>data```的值，但是却无法直接得到```<vihj>model```的值。原因是即使在二值网络模型中，model的组合情况也是2^(|V|+|H|)，|V|和|H|分别表示可视层和隐含层的单元个数。这里可以使用Gibbs采样进行估计，但是Hinton在2002年提出了一个更加快速有效的方法：CD(Contrastive Divergence)。\n\n该方法首先初始化可视层状态为一个训练数据向量，然后根据公式(7)计算隐含层单元的二值状态。一旦隐含层的二值状态被确定，又可以根据公式(8)重新构造(reconstruction)输入层二值单元。将此时网络中的二值单元当做是模型的状态。于是wij更新函数可以表示为：\n\n![update_1](/images/updateW_1.png)                   (9)\n\n重复迭代以上过程知道训练效果到达预期。就可以得到一个RBM网络。\n\n关于RBM的实现可以参考[这个](/attach/rbm.py)python代码。该程序的原网址在[这里](https://github.com/echen/restricted-boltzmann-machines/blob/master/rbm.py)。\n\n参考文献：\n\n1. [受限玻尔兹曼机(Restricted Boltzmann Machine, RBM) 简介](http://www.cnblogs.com/kemaswill/p/3203605.html)\n2. [Deep learning：十九(RBM简单理解)](http://www.cnblogs.com/tornadomeet/archive/2013/03/27/2984725.html)\n3. [Introduction to Restricted Boltzmann Machines](http://edchedch.wordpress.com/2011/07/18/introduction-to-restricted-boltzmann-machines/)\n4. [A Practical Guide to Training Restricted Boltzmann Machines](http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)\n5. [Training products of experts by minimizing contrastive divergence](http://www.cs.toronto.edu/~hinton/absps/tr00-004.pdf)\n\n","slug":"Restricted-Boltzmann-Machine","published":1,"date":"2013-09-22T16:00:00.000Z","updated":"2017-03-05T15:25:34.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapyr0002phv98yij1t7v","content":"<p><strong>受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)</strong>是由Hinton和Sejnowski于1986年提出的一种生成式随机神经网络(generative stochastic neural network)。由于deep learning的基本网络结构DBN可以用RBM堆叠而成，所以这里先介绍RBM。</p>\n<p>RBM是一个能量模型，当一个事物到达稳定状态时，它的能量是最少的。所以一旦知道模型的能量函数，就能够将模型问题转化为函数优化问题。</p>\n<p>RBM网络如下图所示：</p>\n<p><img src=\"/images/rbm.png\" alt=\"rbm\"></p>\n<p>可以看出，RBM网络主要有两层，输入层（也叫可视层）和隐含层（也叫特征提取层）。为了简单起见，在本文中，将网络中的所有神经元都看成是2值的(0, 1)。首先给出该模型的能量方程：</p>\n<p><img src=\"/images/rbm_energy.png\" alt=\"energy\">                   (1)</p>\n<p>这里vi, hj分别表示可视层和隐含层单元的二值数值，ai, bj表示他们的bias，wij是两者连接边的权重。</p>\n<p>通过能量函数，网络为每个可视层向量和隐含层向量对分配一个联合概率：</p>\n<p><img src=\"/images/rbm_join_prob.png\" alt=\"join_prob\">             (2)</p>\n<p>Z是归一化因子，也叫partition function：</p>\n<p><img src=\"/images/rbm_partition.png\" alt=\"partition\">             (3)</p>\n<p>根据公式(2)，可以得出可视层的边缘概率为：</p>\n<p><img src=\"/images/rbm_marg_v.png\" alt=\"marg_v\">                   (4)</p>\n<p>由于上面的v是真实的training data，所以我们希望它的值能尽可能的大。从上式可以看出，为了到达这一点，可以调整wij, ai, bj, 以到达降低当前输入向量的energy(E), 提高其它向量的energy。通过以上分析，我们得到了优化目标函数就是P(v)。对其的log求导可以得到：</p>\n<p><img src=\"/images/rbm_deriv.png\" alt=\"deriv\">                      (5)</p>\n<p>其中，&lt;&gt;表示的是均值。<code>&lt;vihj&gt;data</code>表示vi<em>hj在训练数据的均值。<code>&lt;vihj&gt;model</code>表示vi</em>hj在模型上的均值。</p>\n<p>由此，我们可以对wij参数矩阵进行跟新：</p>\n<p><img src=\"/images/rbm_updateW.png\" alt=\"update\">                   (6)</p>\n<p>其中epsilon是学习率。由于每一层的单元不会与本层单元发生连接，所以单元之间是独立的。对于给定的训练数据向量，可以根据一定的概率得到隐含层的二值概率：</p>\n<p><img src=\"/images/rbm_prob_h.png\" alt=\"prob_h\">                    (7)</p>\n<p>这里sigma表示sigmoid激活函数: sigm(x)=1/(1+exp(-x))。</p>\n<p>同理，当给定隐含层的输入向量时，也可以得到可视层向量的二值概率：</p>\n<p><img src=\"/images/rbm_prob_v.png\" alt=\"prob_c\">                    (8)</p>\n<p>根据公式(7)，我们可以很容易的得出<code>&lt;vihj&gt;data</code>的值，但是却无法直接得到<code>&lt;vihj&gt;model</code>的值。原因是即使在二值网络模型中，model的组合情况也是2^(|V|+|H|)，|V|和|H|分别表示可视层和隐含层的单元个数。这里可以使用Gibbs采样进行估计，但是Hinton在2002年提出了一个更加快速有效的方法：CD(Contrastive Divergence)。</p>\n<p>该方法首先初始化可视层状态为一个训练数据向量，然后根据公式(7)计算隐含层单元的二值状态。一旦隐含层的二值状态被确定，又可以根据公式(8)重新构造(reconstruction)输入层二值单元。将此时网络中的二值单元当做是模型的状态。于是wij更新函数可以表示为：</p>\n<p><img src=\"/images/updateW_1.png\" alt=\"update_1\">                   (9)</p>\n<p>重复迭代以上过程知道训练效果到达预期。就可以得到一个RBM网络。</p>\n<p>关于RBM的实现可以参考<a href=\"/attach/rbm.py\">这个</a>python代码。该程序的原网址在<a href=\"https://github.com/echen/restricted-boltzmann-machines/blob/master/rbm.py\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>参考文献：</p>\n<ol>\n<li><a href=\"http://www.cnblogs.com/kemaswill/p/3203605.html\" target=\"_blank\" rel=\"external\">受限玻尔兹曼机(Restricted Boltzmann Machine, RBM) 简介</a></li>\n<li><a href=\"http://www.cnblogs.com/tornadomeet/archive/2013/03/27/2984725.html\" target=\"_blank\" rel=\"external\">Deep learning：十九(RBM简单理解)</a></li>\n<li><a href=\"http://edchedch.wordpress.com/2011/07/18/introduction-to-restricted-boltzmann-machines/\" target=\"_blank\" rel=\"external\">Introduction to Restricted Boltzmann Machines</a></li>\n<li><a href=\"http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf\" target=\"_blank\" rel=\"external\">A Practical Guide to Training Restricted Boltzmann Machines</a></li>\n<li><a href=\"http://www.cs.toronto.edu/~hinton/absps/tr00-004.pdf\" target=\"_blank\" rel=\"external\">Training products of experts by minimizing contrastive divergence</a></li>\n</ol>\n","excerpt":"","more":"<p><strong>受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)</strong>是由Hinton和Sejnowski于1986年提出的一种生成式随机神经网络(generative stochastic neural network)。由于deep learning的基本网络结构DBN可以用RBM堆叠而成，所以这里先介绍RBM。</p>\n<p>RBM是一个能量模型，当一个事物到达稳定状态时，它的能量是最少的。所以一旦知道模型的能量函数，就能够将模型问题转化为函数优化问题。</p>\n<p>RBM网络如下图所示：</p>\n<p><img src=\"/images/rbm.png\" alt=\"rbm\"></p>\n<p>可以看出，RBM网络主要有两层，输入层（也叫可视层）和隐含层（也叫特征提取层）。为了简单起见，在本文中，将网络中的所有神经元都看成是2值的(0, 1)。首先给出该模型的能量方程：</p>\n<p><img src=\"/images/rbm_energy.png\" alt=\"energy\">                   (1)</p>\n<p>这里vi, hj分别表示可视层和隐含层单元的二值数值，ai, bj表示他们的bias，wij是两者连接边的权重。</p>\n<p>通过能量函数，网络为每个可视层向量和隐含层向量对分配一个联合概率：</p>\n<p><img src=\"/images/rbm_join_prob.png\" alt=\"join_prob\">             (2)</p>\n<p>Z是归一化因子，也叫partition function：</p>\n<p><img src=\"/images/rbm_partition.png\" alt=\"partition\">             (3)</p>\n<p>根据公式(2)，可以得出可视层的边缘概率为：</p>\n<p><img src=\"/images/rbm_marg_v.png\" alt=\"marg_v\">                   (4)</p>\n<p>由于上面的v是真实的training data，所以我们希望它的值能尽可能的大。从上式可以看出，为了到达这一点，可以调整wij, ai, bj, 以到达降低当前输入向量的energy(E), 提高其它向量的energy。通过以上分析，我们得到了优化目标函数就是P(v)。对其的log求导可以得到：</p>\n<p><img src=\"/images/rbm_deriv.png\" alt=\"deriv\">                      (5)</p>\n<p>其中，&lt;&gt;表示的是均值。<code>&lt;vihj&gt;data</code>表示vi<em>hj在训练数据的均值。<code>&lt;vihj&gt;model</code>表示vi</em>hj在模型上的均值。</p>\n<p>由此，我们可以对wij参数矩阵进行跟新：</p>\n<p><img src=\"/images/rbm_updateW.png\" alt=\"update\">                   (6)</p>\n<p>其中epsilon是学习率。由于每一层的单元不会与本层单元发生连接，所以单元之间是独立的。对于给定的训练数据向量，可以根据一定的概率得到隐含层的二值概率：</p>\n<p><img src=\"/images/rbm_prob_h.png\" alt=\"prob_h\">                    (7)</p>\n<p>这里sigma表示sigmoid激活函数: sigm(x)=1/(1+exp(-x))。</p>\n<p>同理，当给定隐含层的输入向量时，也可以得到可视层向量的二值概率：</p>\n<p><img src=\"/images/rbm_prob_v.png\" alt=\"prob_c\">                    (8)</p>\n<p>根据公式(7)，我们可以很容易的得出<code>&lt;vihj&gt;data</code>的值，但是却无法直接得到<code>&lt;vihj&gt;model</code>的值。原因是即使在二值网络模型中，model的组合情况也是2^(|V|+|H|)，|V|和|H|分别表示可视层和隐含层的单元个数。这里可以使用Gibbs采样进行估计，但是Hinton在2002年提出了一个更加快速有效的方法：CD(Contrastive Divergence)。</p>\n<p>该方法首先初始化可视层状态为一个训练数据向量，然后根据公式(7)计算隐含层单元的二值状态。一旦隐含层的二值状态被确定，又可以根据公式(8)重新构造(reconstruction)输入层二值单元。将此时网络中的二值单元当做是模型的状态。于是wij更新函数可以表示为：</p>\n<p><img src=\"/images/updateW_1.png\" alt=\"update_1\">                   (9)</p>\n<p>重复迭代以上过程知道训练效果到达预期。就可以得到一个RBM网络。</p>\n<p>关于RBM的实现可以参考<a href=\"/attach/rbm.py\">这个</a>python代码。该程序的原网址在<a href=\"https://github.com/echen/restricted-boltzmann-machines/blob/master/rbm.py\">这里</a>。</p>\n<p>参考文献：</p>\n<ol>\n<li><a href=\"http://www.cnblogs.com/kemaswill/p/3203605.html\">受限玻尔兹曼机(Restricted Boltzmann Machine, RBM) 简介</a></li>\n<li><a href=\"http://www.cnblogs.com/tornadomeet/archive/2013/03/27/2984725.html\">Deep learning：十九(RBM简单理解)</a></li>\n<li><a href=\"http://edchedch.wordpress.com/2011/07/18/introduction-to-restricted-boltzmann-machines/\">Introduction to Restricted Boltzmann Machines</a></li>\n<li><a href=\"http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf\">A Practical Guide to Training Restricted Boltzmann Machines</a></li>\n<li><a href=\"http://www.cs.toronto.edu/~hinton/absps/tr00-004.pdf\">Training products of experts by minimizing contrastive divergence</a></li>\n</ol>\n"},{"layout":"post","title":"first page","_content":"\nHi, It's My first github page.\n\nMy Name is **ChenLingpen**.\n\nFrom [Beijing University Of Posts And Telecommunications](http://www.bupt.edu.cn/).\n\nGitHub page is great!\n\n**Thanks!**\n","source":"_posts/2013-09-03-first-page.markdown","raw":"---\nlayout: post\ntitle: first page\ntag: others\n---\n\nHi, It's My first github page.\n\nMy Name is **ChenLingpen**.\n\nFrom [Beijing University Of Posts And Telecommunications](http://www.bupt.edu.cn/).\n\nGitHub page is great!\n\n**Thanks!**\n","slug":"first-page","published":1,"date":"2013-09-02T16:00:00.000Z","updated":"2017-03-05T15:21:15.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapyt0004phv9wd74tp2c","content":"<p>Hi, It’s My first github page.</p>\n<p>My Name is <strong>ChenLingpen</strong>.</p>\n<p>From <a href=\"http://www.bupt.edu.cn/\" target=\"_blank\" rel=\"external\">Beijing University Of Posts And Telecommunications</a>.</p>\n<p>GitHub page is great!</p>\n<p><strong>Thanks!</strong></p>\n","excerpt":"","more":"<p>Hi, It’s My first github page.</p>\n<p>My Name is <strong>ChenLingpen</strong>.</p>\n<p>From <a href=\"http://www.bupt.edu.cn/\">Beijing University Of Posts And Telecommunications</a>.</p>\n<p>GitHub page is great!</p>\n<p><strong>Thanks!</strong></p>\n"},{"layout":"post","title":"Convolutional Neural Network","_content":"\n**Convolutional Neural Network(CNN, 卷积神经网络)**是一种特殊的MLP（多层神经网络）。它的思想主要来自于生物学。1968年Hubel和Wiesel在基于猫眼的研究发现，在视皮层存在一些复杂的神经元细胞，它们对小块的子空间十分敏感，于是提出了接收野(receptive field)的概念。这层过滤器是对整体视图空间的基于空间的过滤，所以更加适合有着较强局部关联的图片特征。对卷积神经网络最成功的例子就是LeCun的LeNet5。\n\n---\n\n卷积神经网络是一个为了感知二维形状而特殊设计的多层神经网络。这种网络结构对平移，旋转，缩放等具有高度不变性(invariance)。这种网络主要有两个特征：\n\n**1. 稀疏连接(Sparse Connection)**\n\n卷积神经网络针对局部接收野的特性，强制使用局部连接而非以往全连接的方式构建网络，从而是整个网络能够更好的提取局部特征。如下图所示，m层的神经单元只与m-1层的局部单元有连接，而这些连接具有空间上连续的特性，这能更好的帮助我们理解图像的局部特性。\n\n![sparse_connection](/images/cnn_sparse.png)\n\n图中m层单元接收m-1层的3个局部单元的输入，所以它的接受域宽是3，m+1层相对m层也是3。但是m+1层相对于m-1层的域宽是5。这样的层堆叠起来后，会是的过滤器逐渐覆盖到全局。\n\n**2. 权值共享(Shared Weight)**\n\n在卷积神经网络中，每个过滤器(filter)Wi通过权值共享机制来覆盖整个可视域。效果如下图所示：\n\n![shared_weight](/images/cnn_share.png)\n\n为什么需要权值共享呢？权值共享有几个好处：1, 重复单元的特征提取将不受到到绝对空间位置的限制。一旦图片的相对位置信息被提取，那么他在原图中的绝对位置就不再那么重要。2, 权值共享可以让我们更加有效的进行特征提取，因为它极大的减少了我们需要学习的变量个数。通过对神经网络规模的控制，CNN可以很好的泛化到现实中的视觉问题，这种泛化能力可能也主要来自于网络本身的两个主要特性，现在比较能够接受这一现象的原因是稀疏连接和权值共享是视觉问题的一个很好的先验知识，它使得我们的模型有了比其他深层模型更好的泛化。\n\n---\n\n完整的卷积神经网络是一个多层神经网络，每层有多个二维平面组成，每个平面由多个独立的神经元组成。网络主要由两种不同的神经元组成，分别记作S-元和C-元。S-元聚合成S-面，S-面聚合成S-层，用Us标记。C-层也是如此。网络中只有一个输入层，中间的层由S-层和C-层串联而成。\n\n输入层是第一层，它是一个二维图像的输入。Us层被称为特征提取层，每个神经元与前一层的局部野相连接，并提取该局部的特征，Us层的每一个S-面内部的所有神经元共享突触权值，从而保持该层提取特征的invariance。Uc是特征映射层，每一个S-面都紧跟着一个C-面进行局部平均的子抽样，这种设计使得网络模型在识别图片时有了较高的畸变容忍能力。\n子抽样层可以采用max-pooling方式进行抽样，这是一种非线性的下抽样方式。max-pooling可以将输入的二维平面分割成为无重叠的各个矩阵区域，对于每个子区域其输出值是该区域中的最大值。\n子抽样的引入主要有一下两个方面：1，它能够有效的减少计算量。2，它提供了一种平移不变性的方式(这一点的解释暂时不是很懂)。\n\n下图是LeNet5的网络模型：\n\n![lenet5](/images/cnn_lenet5.jpg)\n\n从图中可以看出，输入层是一个32\\*32的图像输入，然后网络按卷积和子抽样交替进行。首选卷积层由8个特征映射组成，每个特征映射指定5\\*5的接受域，从而得到8个S-面组成的S层，每个面28\\*28。接着进行一次子抽样，子抽样后的每个神经元拥有2\\*2的接受域。迭代卷积和子抽样后，形成20个特征映射，每个特征映射由5\\*5的单元组成，第五个隐藏层由120个神经元组成，每个神经元指定5\\*5的接受域，最后120个神经元与输出层进行全连接。图中有将近100,000个突触连接，但是只需要训练2600个参数，这极大的提高了模型的泛化能力。模型本身的参数学习可以通过[反向传播](./The-Back-Propagation-Algorithm-Neural-Network.html)进行学习。\n\n---\n\n参考文献：\n\n1. [deep learning tutorial) 简介](http://deeplearning.net/tutorial/lenet.html)\n2. [卷积神经网络（CNN）](http://ibillxia.github.io/blog/2013/04/06/Convolutional-Neural-Networks/)\n3. [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n","source":"_posts/2013-10-04-Convolutional-Neural-Network.markdown","raw":"---\nlayout: post\ntitle: Convolutional Neural Network\ntag: [neural network]\n---\n\n**Convolutional Neural Network(CNN, 卷积神经网络)**是一种特殊的MLP（多层神经网络）。它的思想主要来自于生物学。1968年Hubel和Wiesel在基于猫眼的研究发现，在视皮层存在一些复杂的神经元细胞，它们对小块的子空间十分敏感，于是提出了接收野(receptive field)的概念。这层过滤器是对整体视图空间的基于空间的过滤，所以更加适合有着较强局部关联的图片特征。对卷积神经网络最成功的例子就是LeCun的LeNet5。\n\n---\n\n卷积神经网络是一个为了感知二维形状而特殊设计的多层神经网络。这种网络结构对平移，旋转，缩放等具有高度不变性(invariance)。这种网络主要有两个特征：\n\n**1. 稀疏连接(Sparse Connection)**\n\n卷积神经网络针对局部接收野的特性，强制使用局部连接而非以往全连接的方式构建网络，从而是整个网络能够更好的提取局部特征。如下图所示，m层的神经单元只与m-1层的局部单元有连接，而这些连接具有空间上连续的特性，这能更好的帮助我们理解图像的局部特性。\n\n![sparse_connection](/images/cnn_sparse.png)\n\n图中m层单元接收m-1层的3个局部单元的输入，所以它的接受域宽是3，m+1层相对m层也是3。但是m+1层相对于m-1层的域宽是5。这样的层堆叠起来后，会是的过滤器逐渐覆盖到全局。\n\n**2. 权值共享(Shared Weight)**\n\n在卷积神经网络中，每个过滤器(filter)Wi通过权值共享机制来覆盖整个可视域。效果如下图所示：\n\n![shared_weight](/images/cnn_share.png)\n\n为什么需要权值共享呢？权值共享有几个好处：1, 重复单元的特征提取将不受到到绝对空间位置的限制。一旦图片的相对位置信息被提取，那么他在原图中的绝对位置就不再那么重要。2, 权值共享可以让我们更加有效的进行特征提取，因为它极大的减少了我们需要学习的变量个数。通过对神经网络规模的控制，CNN可以很好的泛化到现实中的视觉问题，这种泛化能力可能也主要来自于网络本身的两个主要特性，现在比较能够接受这一现象的原因是稀疏连接和权值共享是视觉问题的一个很好的先验知识，它使得我们的模型有了比其他深层模型更好的泛化。\n\n---\n\n完整的卷积神经网络是一个多层神经网络，每层有多个二维平面组成，每个平面由多个独立的神经元组成。网络主要由两种不同的神经元组成，分别记作S-元和C-元。S-元聚合成S-面，S-面聚合成S-层，用Us标记。C-层也是如此。网络中只有一个输入层，中间的层由S-层和C-层串联而成。\n\n输入层是第一层，它是一个二维图像的输入。Us层被称为特征提取层，每个神经元与前一层的局部野相连接，并提取该局部的特征，Us层的每一个S-面内部的所有神经元共享突触权值，从而保持该层提取特征的invariance。Uc是特征映射层，每一个S-面都紧跟着一个C-面进行局部平均的子抽样，这种设计使得网络模型在识别图片时有了较高的畸变容忍能力。\n子抽样层可以采用max-pooling方式进行抽样，这是一种非线性的下抽样方式。max-pooling可以将输入的二维平面分割成为无重叠的各个矩阵区域，对于每个子区域其输出值是该区域中的最大值。\n子抽样的引入主要有一下两个方面：1，它能够有效的减少计算量。2，它提供了一种平移不变性的方式(这一点的解释暂时不是很懂)。\n\n下图是LeNet5的网络模型：\n\n![lenet5](/images/cnn_lenet5.jpg)\n\n从图中可以看出，输入层是一个32\\*32的图像输入，然后网络按卷积和子抽样交替进行。首选卷积层由8个特征映射组成，每个特征映射指定5\\*5的接受域，从而得到8个S-面组成的S层，每个面28\\*28。接着进行一次子抽样，子抽样后的每个神经元拥有2\\*2的接受域。迭代卷积和子抽样后，形成20个特征映射，每个特征映射由5\\*5的单元组成，第五个隐藏层由120个神经元组成，每个神经元指定5\\*5的接受域，最后120个神经元与输出层进行全连接。图中有将近100,000个突触连接，但是只需要训练2600个参数，这极大的提高了模型的泛化能力。模型本身的参数学习可以通过[反向传播](./The-Back-Propagation-Algorithm-Neural-Network.html)进行学习。\n\n---\n\n参考文献：\n\n1. [deep learning tutorial) 简介](http://deeplearning.net/tutorial/lenet.html)\n2. [卷积神经网络（CNN）](http://ibillxia.github.io/blog/2013/04/06/Convolutional-Neural-Networks/)\n3. [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n","slug":"Convolutional-Neural-Network","published":1,"date":"2013-10-03T16:00:00.000Z","updated":"2017-03-05T15:25:49.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapyu0005phv9j4ggygxi","content":"<p><strong>Convolutional Neural Network(CNN, 卷积神经网络)</strong>是一种特殊的MLP（多层神经网络）。它的思想主要来自于生物学。1968年Hubel和Wiesel在基于猫眼的研究发现，在视皮层存在一些复杂的神经元细胞，它们对小块的子空间十分敏感，于是提出了接收野(receptive field)的概念。这层过滤器是对整体视图空间的基于空间的过滤，所以更加适合有着较强局部关联的图片特征。对卷积神经网络最成功的例子就是LeCun的LeNet5。</p>\n<hr>\n<p>卷积神经网络是一个为了感知二维形状而特殊设计的多层神经网络。这种网络结构对平移，旋转，缩放等具有高度不变性(invariance)。这种网络主要有两个特征：</p>\n<p><strong>1. 稀疏连接(Sparse Connection)</strong></p>\n<p>卷积神经网络针对局部接收野的特性，强制使用局部连接而非以往全连接的方式构建网络，从而是整个网络能够更好的提取局部特征。如下图所示，m层的神经单元只与m-1层的局部单元有连接，而这些连接具有空间上连续的特性，这能更好的帮助我们理解图像的局部特性。</p>\n<p><img src=\"/images/cnn_sparse.png\" alt=\"sparse_connection\"></p>\n<p>图中m层单元接收m-1层的3个局部单元的输入，所以它的接受域宽是3，m+1层相对m层也是3。但是m+1层相对于m-1层的域宽是5。这样的层堆叠起来后，会是的过滤器逐渐覆盖到全局。</p>\n<p><strong>2. 权值共享(Shared Weight)</strong></p>\n<p>在卷积神经网络中，每个过滤器(filter)Wi通过权值共享机制来覆盖整个可视域。效果如下图所示：</p>\n<p><img src=\"/images/cnn_share.png\" alt=\"shared_weight\"></p>\n<p>为什么需要权值共享呢？权值共享有几个好处：1, 重复单元的特征提取将不受到到绝对空间位置的限制。一旦图片的相对位置信息被提取，那么他在原图中的绝对位置就不再那么重要。2, 权值共享可以让我们更加有效的进行特征提取，因为它极大的减少了我们需要学习的变量个数。通过对神经网络规模的控制，CNN可以很好的泛化到现实中的视觉问题，这种泛化能力可能也主要来自于网络本身的两个主要特性，现在比较能够接受这一现象的原因是稀疏连接和权值共享是视觉问题的一个很好的先验知识，它使得我们的模型有了比其他深层模型更好的泛化。</p>\n<hr>\n<p>完整的卷积神经网络是一个多层神经网络，每层有多个二维平面组成，每个平面由多个独立的神经元组成。网络主要由两种不同的神经元组成，分别记作S-元和C-元。S-元聚合成S-面，S-面聚合成S-层，用Us标记。C-层也是如此。网络中只有一个输入层，中间的层由S-层和C-层串联而成。</p>\n<p>输入层是第一层，它是一个二维图像的输入。Us层被称为特征提取层，每个神经元与前一层的局部野相连接，并提取该局部的特征，Us层的每一个S-面内部的所有神经元共享突触权值，从而保持该层提取特征的invariance。Uc是特征映射层，每一个S-面都紧跟着一个C-面进行局部平均的子抽样，这种设计使得网络模型在识别图片时有了较高的畸变容忍能力。<br>子抽样层可以采用max-pooling方式进行抽样，这是一种非线性的下抽样方式。max-pooling可以将输入的二维平面分割成为无重叠的各个矩阵区域，对于每个子区域其输出值是该区域中的最大值。<br>子抽样的引入主要有一下两个方面：1，它能够有效的减少计算量。2，它提供了一种平移不变性的方式(这一点的解释暂时不是很懂)。</p>\n<p>下图是LeNet5的网络模型：</p>\n<p><img src=\"/images/cnn_lenet5.jpg\" alt=\"lenet5\"></p>\n<p>从图中可以看出，输入层是一个32*32的图像输入，然后网络按卷积和子抽样交替进行。首选卷积层由8个特征映射组成，每个特征映射指定5*5的接受域，从而得到8个S-面组成的S层，每个面28*28。接着进行一次子抽样，子抽样后的每个神经元拥有2*2的接受域。迭代卷积和子抽样后，形成20个特征映射，每个特征映射由5*5的单元组成，第五个隐藏层由120个神经元组成，每个神经元指定5*5的接受域，最后120个神经元与输出层进行全连接。图中有将近100,000个突触连接，但是只需要训练2600个参数，这极大的提高了模型的泛化能力。模型本身的参数学习可以通过<a href=\"./The-Back-Propagation-Algorithm-Neural-Network.html\">反向传播</a>进行学习。</p>\n<hr>\n<p>参考文献：</p>\n<ol>\n<li><a href=\"http://deeplearning.net/tutorial/lenet.html\" target=\"_blank\" rel=\"external\">deep learning tutorial) 简介</a></li>\n<li><a href=\"http://ibillxia.github.io/blog/2013/04/06/Convolutional-Neural-Networks/\" target=\"_blank\" rel=\"external\">卷积神经网络（CNN）</a></li>\n<li><a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\" target=\"_blank\" rel=\"external\">Gradient-Based Learning Applied to Document Recognition</a></li>\n</ol>\n","excerpt":"","more":"<p><strong>Convolutional Neural Network(CNN, 卷积神经网络)</strong>是一种特殊的MLP（多层神经网络）。它的思想主要来自于生物学。1968年Hubel和Wiesel在基于猫眼的研究发现，在视皮层存在一些复杂的神经元细胞，它们对小块的子空间十分敏感，于是提出了接收野(receptive field)的概念。这层过滤器是对整体视图空间的基于空间的过滤，所以更加适合有着较强局部关联的图片特征。对卷积神经网络最成功的例子就是LeCun的LeNet5。</p>\n<hr>\n<p>卷积神经网络是一个为了感知二维形状而特殊设计的多层神经网络。这种网络结构对平移，旋转，缩放等具有高度不变性(invariance)。这种网络主要有两个特征：</p>\n<p><strong>1. 稀疏连接(Sparse Connection)</strong></p>\n<p>卷积神经网络针对局部接收野的特性，强制使用局部连接而非以往全连接的方式构建网络，从而是整个网络能够更好的提取局部特征。如下图所示，m层的神经单元只与m-1层的局部单元有连接，而这些连接具有空间上连续的特性，这能更好的帮助我们理解图像的局部特性。</p>\n<p><img src=\"/images/cnn_sparse.png\" alt=\"sparse_connection\"></p>\n<p>图中m层单元接收m-1层的3个局部单元的输入，所以它的接受域宽是3，m+1层相对m层也是3。但是m+1层相对于m-1层的域宽是5。这样的层堆叠起来后，会是的过滤器逐渐覆盖到全局。</p>\n<p><strong>2. 权值共享(Shared Weight)</strong></p>\n<p>在卷积神经网络中，每个过滤器(filter)Wi通过权值共享机制来覆盖整个可视域。效果如下图所示：</p>\n<p><img src=\"/images/cnn_share.png\" alt=\"shared_weight\"></p>\n<p>为什么需要权值共享呢？权值共享有几个好处：1, 重复单元的特征提取将不受到到绝对空间位置的限制。一旦图片的相对位置信息被提取，那么他在原图中的绝对位置就不再那么重要。2, 权值共享可以让我们更加有效的进行特征提取，因为它极大的减少了我们需要学习的变量个数。通过对神经网络规模的控制，CNN可以很好的泛化到现实中的视觉问题，这种泛化能力可能也主要来自于网络本身的两个主要特性，现在比较能够接受这一现象的原因是稀疏连接和权值共享是视觉问题的一个很好的先验知识，它使得我们的模型有了比其他深层模型更好的泛化。</p>\n<hr>\n<p>完整的卷积神经网络是一个多层神经网络，每层有多个二维平面组成，每个平面由多个独立的神经元组成。网络主要由两种不同的神经元组成，分别记作S-元和C-元。S-元聚合成S-面，S-面聚合成S-层，用Us标记。C-层也是如此。网络中只有一个输入层，中间的层由S-层和C-层串联而成。</p>\n<p>输入层是第一层，它是一个二维图像的输入。Us层被称为特征提取层，每个神经元与前一层的局部野相连接，并提取该局部的特征，Us层的每一个S-面内部的所有神经元共享突触权值，从而保持该层提取特征的invariance。Uc是特征映射层，每一个S-面都紧跟着一个C-面进行局部平均的子抽样，这种设计使得网络模型在识别图片时有了较高的畸变容忍能力。<br>子抽样层可以采用max-pooling方式进行抽样，这是一种非线性的下抽样方式。max-pooling可以将输入的二维平面分割成为无重叠的各个矩阵区域，对于每个子区域其输出值是该区域中的最大值。<br>子抽样的引入主要有一下两个方面：1，它能够有效的减少计算量。2，它提供了一种平移不变性的方式(这一点的解释暂时不是很懂)。</p>\n<p>下图是LeNet5的网络模型：</p>\n<p><img src=\"/images/cnn_lenet5.jpg\" alt=\"lenet5\"></p>\n<p>从图中可以看出，输入层是一个32*32的图像输入，然后网络按卷积和子抽样交替进行。首选卷积层由8个特征映射组成，每个特征映射指定5*5的接受域，从而得到8个S-面组成的S层，每个面28*28。接着进行一次子抽样，子抽样后的每个神经元拥有2*2的接受域。迭代卷积和子抽样后，形成20个特征映射，每个特征映射由5*5的单元组成，第五个隐藏层由120个神经元组成，每个神经元指定5*5的接受域，最后120个神经元与输出层进行全连接。图中有将近100,000个突触连接，但是只需要训练2600个参数，这极大的提高了模型的泛化能力。模型本身的参数学习可以通过<a href=\"./The-Back-Propagation-Algorithm-Neural-Network.html\">反向传播</a>进行学习。</p>\n<hr>\n<p>参考文献：</p>\n<ol>\n<li><a href=\"http://deeplearning.net/tutorial/lenet.html\">deep learning tutorial) 简介</a></li>\n<li><a href=\"http://ibillxia.github.io/blog/2013/04/06/Convolutional-Neural-Networks/\">卷积神经网络（CNN）</a></li>\n<li><a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\">Gradient-Based Learning Applied to Document Recognition</a></li>\n</ol>\n"},{"layout":"post","title":"Connect nodes at same level","_content":"\n> 本题来源于 [GeeksforGeeks](http://www.geeksforgeeks.org/connect-nodes-at-same-level/)\n\n# 题目描述：\n> 二叉树有一个节点叫做nextRight，希望将他指向同级右侧邻接节点。\n\n> Write a function to connect all the adjacent nodes at the same level in a binary tree. Structure of the given Binary Tree node is like following. \nInitially, all the nextRight pointers point to garbage values. Your function should set these pointers to point next right for each node.   \n\n```\nstruct node{\n\tint data;\n    struct node* left;\n    struct node* right;\n\tstruct node* nextRight;  \n}\n```\n\n## 思路一：\n> 使用queue进行遍历，并记录节点的level。然后直接往后指就好了。\n\n## 思路二：\n> 思路一需要有额外的存储空间，可以用递归的思路精细的构造。  \n我们可以层次化的构造，将上面一行处理完，在处理下面一行的时候，用上面一行进行引导，记录当前行L的当前节点（初始为当前行的第一个节点），然后将其孩子进行nextRight的处理。处理的过程是记录下该行(L+1)已经有nextRight，然后当前行(L)去引导这个点向前进。具体看代码。\n\n```\n#include <iostream>\n\nusing namespace std;\n\nclass node\n{\npublic:\n\tint data;\n\tclass node *left;\n\tclass node *right;\n\tclass node *nextRight;\n};\n\nnode* newnode(int data) {\n\tnode* n = new node;\n\tn->data=data;\n\tn->left=NULL;\n\tn->right=NULL;\n\tn->nextRight=NULL;\n\treturn n;\n}\nvoid solution(node* root);\nvoid printAllRight(node* first);\nint main() {\n\tnode *root = newnode(1);\n\troot->left = newnode(2);\n    root->right = newnode(3);\n\troot->left->left = newnode(4);\n\troot->left->right = newnode(5);\n\troot->right->right=newnode(6);\n\troot->right->right->left=newnode(7);\n\troot->right->right->right=newnode(8);\n\tsolution(root);\n\tprintAllRight(root);\n\tprintAllRight(root->left);\n\tprintAllRight(root->left->left);\n\tprintAllRight(root->right->right->left);\n}\n\nvoid solution(node* root) {\n\tnode* first = root;\n\tnode* nextLevelFirst = NULL;//指向下一层第一个节点\n\tnode* nextLevelLast = NULL;//指向下一层最后一个有nextRight的节点\n\twhile(first){\n\t\tnode* current = first;\n\t\twhile(current){\n\t\t\tif(current->left){\n\t\t\t\tif(!nextLevelFirst){\n\t\t\t\t\tnextLevelFirst=current->left;\n\t\t\t\t}\n\t\t\t\tif(nextLevelLast){\n\t\t\t\t\tnextLevelLast->nextRight=current->left;\n\t\t\t\t}\n\t\t\t\tnextLevelLast=current->left;\n\t\t\t\tif(current->right){\n\t\t\t\t\tnextLevelLast->nextRight=current->right;\n\t\t\t\t\tnextLevelLast=current->right;\n\t\t\t\t}\n\t\t\t} else if(current->right){\n\t\t\t\tif(!nextLevelFirst){\n\t\t\t\t\tnextLevelFirst=current->right;\n\t\t\t\t}\n\t\t\t\tif(nextLevelLast){\n\t\t\t\t\tnextLevelLast->nextRight=current->right;\n\t\t\t\t}\n\t\t\t\tnextLevelLast=current->right;\n\t\t\t}\n\t\t\tcurrent = current->nextRight;\n\t\t}\n\t\tfirst=nextLevelFirst;\n\t\tnextLevelFirst=NULL;\n\t\tnextLevelLast=NULL;\n\t}\n}\n\n\nvoid printAllRight(node* first) {\n\twhile(first){\n\t\tcout<<first->data<<\"---\";\n\t\tfirst = first->nextRight;\n\t}\n\tcout<<\"NULL\"<<endl;\n}\n```\n\n","source":"_posts/2015-01-08-connect-nodes-at-same-level.markdown","raw":"---\nlayout: post\ntitle: Connect nodes at same level\ncategory: algorithm\ntag: [algorithm]\n---\n\n> 本题来源于 [GeeksforGeeks](http://www.geeksforgeeks.org/connect-nodes-at-same-level/)\n\n# 题目描述：\n> 二叉树有一个节点叫做nextRight，希望将他指向同级右侧邻接节点。\n\n> Write a function to connect all the adjacent nodes at the same level in a binary tree. Structure of the given Binary Tree node is like following. \nInitially, all the nextRight pointers point to garbage values. Your function should set these pointers to point next right for each node.   \n\n```\nstruct node{\n\tint data;\n    struct node* left;\n    struct node* right;\n\tstruct node* nextRight;  \n}\n```\n\n## 思路一：\n> 使用queue进行遍历，并记录节点的level。然后直接往后指就好了。\n\n## 思路二：\n> 思路一需要有额外的存储空间，可以用递归的思路精细的构造。  \n我们可以层次化的构造，将上面一行处理完，在处理下面一行的时候，用上面一行进行引导，记录当前行L的当前节点（初始为当前行的第一个节点），然后将其孩子进行nextRight的处理。处理的过程是记录下该行(L+1)已经有nextRight，然后当前行(L)去引导这个点向前进。具体看代码。\n\n```\n#include <iostream>\n\nusing namespace std;\n\nclass node\n{\npublic:\n\tint data;\n\tclass node *left;\n\tclass node *right;\n\tclass node *nextRight;\n};\n\nnode* newnode(int data) {\n\tnode* n = new node;\n\tn->data=data;\n\tn->left=NULL;\n\tn->right=NULL;\n\tn->nextRight=NULL;\n\treturn n;\n}\nvoid solution(node* root);\nvoid printAllRight(node* first);\nint main() {\n\tnode *root = newnode(1);\n\troot->left = newnode(2);\n    root->right = newnode(3);\n\troot->left->left = newnode(4);\n\troot->left->right = newnode(5);\n\troot->right->right=newnode(6);\n\troot->right->right->left=newnode(7);\n\troot->right->right->right=newnode(8);\n\tsolution(root);\n\tprintAllRight(root);\n\tprintAllRight(root->left);\n\tprintAllRight(root->left->left);\n\tprintAllRight(root->right->right->left);\n}\n\nvoid solution(node* root) {\n\tnode* first = root;\n\tnode* nextLevelFirst = NULL;//指向下一层第一个节点\n\tnode* nextLevelLast = NULL;//指向下一层最后一个有nextRight的节点\n\twhile(first){\n\t\tnode* current = first;\n\t\twhile(current){\n\t\t\tif(current->left){\n\t\t\t\tif(!nextLevelFirst){\n\t\t\t\t\tnextLevelFirst=current->left;\n\t\t\t\t}\n\t\t\t\tif(nextLevelLast){\n\t\t\t\t\tnextLevelLast->nextRight=current->left;\n\t\t\t\t}\n\t\t\t\tnextLevelLast=current->left;\n\t\t\t\tif(current->right){\n\t\t\t\t\tnextLevelLast->nextRight=current->right;\n\t\t\t\t\tnextLevelLast=current->right;\n\t\t\t\t}\n\t\t\t} else if(current->right){\n\t\t\t\tif(!nextLevelFirst){\n\t\t\t\t\tnextLevelFirst=current->right;\n\t\t\t\t}\n\t\t\t\tif(nextLevelLast){\n\t\t\t\t\tnextLevelLast->nextRight=current->right;\n\t\t\t\t}\n\t\t\t\tnextLevelLast=current->right;\n\t\t\t}\n\t\t\tcurrent = current->nextRight;\n\t\t}\n\t\tfirst=nextLevelFirst;\n\t\tnextLevelFirst=NULL;\n\t\tnextLevelLast=NULL;\n\t}\n}\n\n\nvoid printAllRight(node* first) {\n\twhile(first){\n\t\tcout<<first->data<<\"---\";\n\t\tfirst = first->nextRight;\n\t}\n\tcout<<\"NULL\"<<endl;\n}\n```\n\n","slug":"connect-nodes-at-same-level","published":1,"date":"2015-01-07T16:00:00.000Z","updated":"2017-03-06T13:48:53.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapyv0006phv9cqz5o31i","content":"<blockquote>\n<p>本题来源于 <a href=\"http://www.geeksforgeeks.org/connect-nodes-at-same-level/\" target=\"_blank\" rel=\"external\">GeeksforGeeks</a></p>\n</blockquote>\n<h1 id=\"题目描述：\"><a href=\"#题目描述：\" class=\"headerlink\" title=\"题目描述：\"></a>题目描述：</h1><blockquote>\n<p>二叉树有一个节点叫做nextRight，希望将他指向同级右侧邻接节点。</p>\n<p>Write a function to connect all the adjacent nodes at the same level in a binary tree. Structure of the given Binary Tree node is like following.<br>Initially, all the nextRight pointers point to garbage values. Your function should set these pointers to point next right for each node.   </p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">struct node&#123;</div><div class=\"line\">\tint data;</div><div class=\"line\">    struct node* left;</div><div class=\"line\">    struct node* right;</div><div class=\"line\">\tstruct node* nextRight;  </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"思路一：\"><a href=\"#思路一：\" class=\"headerlink\" title=\"思路一：\"></a>思路一：</h2><blockquote>\n<p>使用queue进行遍历，并记录节点的level。然后直接往后指就好了。</p>\n</blockquote>\n<h2 id=\"思路二：\"><a href=\"#思路二：\" class=\"headerlink\" title=\"思路二：\"></a>思路二：</h2><blockquote>\n<p>思路一需要有额外的存储空间，可以用递归的思路精细的构造。<br>我们可以层次化的构造，将上面一行处理完，在处理下面一行的时候，用上面一行进行引导，记录当前行L的当前节点（初始为当前行的第一个节点），然后将其孩子进行nextRight的处理。处理的过程是记录下该行(L+1)已经有nextRight，然后当前行(L)去引导这个点向前进。具体看代码。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\"></div><div class=\"line\">class node</div><div class=\"line\">&#123;</div><div class=\"line\">public:</div><div class=\"line\">\tint data;</div><div class=\"line\">\tclass node *left;</div><div class=\"line\">\tclass node *right;</div><div class=\"line\">\tclass node *nextRight;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">node* newnode(int data) &#123;</div><div class=\"line\">\tnode* n = new node;</div><div class=\"line\">\tn-&gt;data=data;</div><div class=\"line\">\tn-&gt;left=NULL;</div><div class=\"line\">\tn-&gt;right=NULL;</div><div class=\"line\">\tn-&gt;nextRight=NULL;</div><div class=\"line\">\treturn n;</div><div class=\"line\">&#125;</div><div class=\"line\">void solution(node* root);</div><div class=\"line\">void printAllRight(node* first);</div><div class=\"line\">int main() &#123;</div><div class=\"line\">\tnode *root = newnode(1);</div><div class=\"line\">\troot-&gt;left = newnode(2);</div><div class=\"line\">    root-&gt;right = newnode(3);</div><div class=\"line\">\troot-&gt;left-&gt;left = newnode(4);</div><div class=\"line\">\troot-&gt;left-&gt;right = newnode(5);</div><div class=\"line\">\troot-&gt;right-&gt;right=newnode(6);</div><div class=\"line\">\troot-&gt;right-&gt;right-&gt;left=newnode(7);</div><div class=\"line\">\troot-&gt;right-&gt;right-&gt;right=newnode(8);</div><div class=\"line\">\tsolution(root);</div><div class=\"line\">\tprintAllRight(root);</div><div class=\"line\">\tprintAllRight(root-&gt;left);</div><div class=\"line\">\tprintAllRight(root-&gt;left-&gt;left);</div><div class=\"line\">\tprintAllRight(root-&gt;right-&gt;right-&gt;left);</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void solution(node* root) &#123;</div><div class=\"line\">\tnode* first = root;</div><div class=\"line\">\tnode* nextLevelFirst = NULL;//指向下一层第一个节点</div><div class=\"line\">\tnode* nextLevelLast = NULL;//指向下一层最后一个有nextRight的节点</div><div class=\"line\">\twhile(first)&#123;</div><div class=\"line\">\t\tnode* current = first;</div><div class=\"line\">\t\twhile(current)&#123;</div><div class=\"line\">\t\t\tif(current-&gt;left)&#123;</div><div class=\"line\">\t\t\t\tif(!nextLevelFirst)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelFirst=current-&gt;left;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tif(nextLevelLast)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelLast-&gt;nextRight=current-&gt;left;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tnextLevelLast=current-&gt;left;</div><div class=\"line\">\t\t\t\tif(current-&gt;right)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelLast-&gt;nextRight=current-&gt;right;</div><div class=\"line\">\t\t\t\t\tnextLevelLast=current-&gt;right;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t&#125; else if(current-&gt;right)&#123;</div><div class=\"line\">\t\t\t\tif(!nextLevelFirst)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelFirst=current-&gt;right;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tif(nextLevelLast)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelLast-&gt;nextRight=current-&gt;right;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tnextLevelLast=current-&gt;right;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t\tcurrent = current-&gt;nextRight;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\tfirst=nextLevelFirst;</div><div class=\"line\">\t\tnextLevelFirst=NULL;</div><div class=\"line\">\t\tnextLevelLast=NULL;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">void printAllRight(node* first) &#123;</div><div class=\"line\">\twhile(first)&#123;</div><div class=\"line\">\t\tcout&lt;&lt;first-&gt;data&lt;&lt;&quot;---&quot;;</div><div class=\"line\">\t\tfirst = first-&gt;nextRight;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tcout&lt;&lt;&quot;NULL&quot;&lt;&lt;endl;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<blockquote>\n<p>本题来源于 <a href=\"http://www.geeksforgeeks.org/connect-nodes-at-same-level/\">GeeksforGeeks</a></p>\n</blockquote>\n<h1 id=\"题目描述：\"><a href=\"#题目描述：\" class=\"headerlink\" title=\"题目描述：\"></a>题目描述：</h1><blockquote>\n<p>二叉树有一个节点叫做nextRight，希望将他指向同级右侧邻接节点。</p>\n<p>Write a function to connect all the adjacent nodes at the same level in a binary tree. Structure of the given Binary Tree node is like following.<br>Initially, all the nextRight pointers point to garbage values. Your function should set these pointers to point next right for each node.   </p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">struct node&#123;</div><div class=\"line\">\tint data;</div><div class=\"line\">    struct node* left;</div><div class=\"line\">    struct node* right;</div><div class=\"line\">\tstruct node* nextRight;  </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"思路一：\"><a href=\"#思路一：\" class=\"headerlink\" title=\"思路一：\"></a>思路一：</h2><blockquote>\n<p>使用queue进行遍历，并记录节点的level。然后直接往后指就好了。</p>\n</blockquote>\n<h2 id=\"思路二：\"><a href=\"#思路二：\" class=\"headerlink\" title=\"思路二：\"></a>思路二：</h2><blockquote>\n<p>思路一需要有额外的存储空间，可以用递归的思路精细的构造。<br>我们可以层次化的构造，将上面一行处理完，在处理下面一行的时候，用上面一行进行引导，记录当前行L的当前节点（初始为当前行的第一个节点），然后将其孩子进行nextRight的处理。处理的过程是记录下该行(L+1)已经有nextRight，然后当前行(L)去引导这个点向前进。具体看代码。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\"></div><div class=\"line\">class node</div><div class=\"line\">&#123;</div><div class=\"line\">public:</div><div class=\"line\">\tint data;</div><div class=\"line\">\tclass node *left;</div><div class=\"line\">\tclass node *right;</div><div class=\"line\">\tclass node *nextRight;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">node* newnode(int data) &#123;</div><div class=\"line\">\tnode* n = new node;</div><div class=\"line\">\tn-&gt;data=data;</div><div class=\"line\">\tn-&gt;left=NULL;</div><div class=\"line\">\tn-&gt;right=NULL;</div><div class=\"line\">\tn-&gt;nextRight=NULL;</div><div class=\"line\">\treturn n;</div><div class=\"line\">&#125;</div><div class=\"line\">void solution(node* root);</div><div class=\"line\">void printAllRight(node* first);</div><div class=\"line\">int main() &#123;</div><div class=\"line\">\tnode *root = newnode(1);</div><div class=\"line\">\troot-&gt;left = newnode(2);</div><div class=\"line\">    root-&gt;right = newnode(3);</div><div class=\"line\">\troot-&gt;left-&gt;left = newnode(4);</div><div class=\"line\">\troot-&gt;left-&gt;right = newnode(5);</div><div class=\"line\">\troot-&gt;right-&gt;right=newnode(6);</div><div class=\"line\">\troot-&gt;right-&gt;right-&gt;left=newnode(7);</div><div class=\"line\">\troot-&gt;right-&gt;right-&gt;right=newnode(8);</div><div class=\"line\">\tsolution(root);</div><div class=\"line\">\tprintAllRight(root);</div><div class=\"line\">\tprintAllRight(root-&gt;left);</div><div class=\"line\">\tprintAllRight(root-&gt;left-&gt;left);</div><div class=\"line\">\tprintAllRight(root-&gt;right-&gt;right-&gt;left);</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void solution(node* root) &#123;</div><div class=\"line\">\tnode* first = root;</div><div class=\"line\">\tnode* nextLevelFirst = NULL;//指向下一层第一个节点</div><div class=\"line\">\tnode* nextLevelLast = NULL;//指向下一层最后一个有nextRight的节点</div><div class=\"line\">\twhile(first)&#123;</div><div class=\"line\">\t\tnode* current = first;</div><div class=\"line\">\t\twhile(current)&#123;</div><div class=\"line\">\t\t\tif(current-&gt;left)&#123;</div><div class=\"line\">\t\t\t\tif(!nextLevelFirst)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelFirst=current-&gt;left;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tif(nextLevelLast)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelLast-&gt;nextRight=current-&gt;left;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tnextLevelLast=current-&gt;left;</div><div class=\"line\">\t\t\t\tif(current-&gt;right)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelLast-&gt;nextRight=current-&gt;right;</div><div class=\"line\">\t\t\t\t\tnextLevelLast=current-&gt;right;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t&#125; else if(current-&gt;right)&#123;</div><div class=\"line\">\t\t\t\tif(!nextLevelFirst)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelFirst=current-&gt;right;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tif(nextLevelLast)&#123;</div><div class=\"line\">\t\t\t\t\tnextLevelLast-&gt;nextRight=current-&gt;right;</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tnextLevelLast=current-&gt;right;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t\tcurrent = current-&gt;nextRight;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t\tfirst=nextLevelFirst;</div><div class=\"line\">\t\tnextLevelFirst=NULL;</div><div class=\"line\">\t\tnextLevelLast=NULL;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">void printAllRight(node* first) &#123;</div><div class=\"line\">\twhile(first)&#123;</div><div class=\"line\">\t\tcout&lt;&lt;first-&gt;data&lt;&lt;&quot;---&quot;;</div><div class=\"line\">\t\tfirst = first-&gt;nextRight;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tcout&lt;&lt;&quot;NULL&quot;&lt;&lt;endl;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Sort an array according to the order defined by another array","_content":"\n> 本题来源于 [GeeksforGeeks](http://www.geeksforgeeks.org/sort-array-according-order-defined-another-array/)\n\n\n# 题目描述：\n> 给出arr1 arr2两个数组，arr2确定了arr1中的数字的顺序大小，如果arr1中有没有存在arr2的数，则是自然顺序大小。目标是对arr1进行排序。\n\n> Given two arrays A1[] and A2[], sort A1 in such a way that the relative order among the elements will be same as those are in A2. For the elements not present in A2, append them at last in sorted order.  \nInput:  \nA1[] = {2, 1, 2, 5, 7, 1, 9, 3, 6, 8, 8}  \nA2[] = {2, 1, 8, 3}  \nOutput:   \nA1[] = {2, 2, 1, 1, 8, 8, 3, 5, 6, 7, 9}  \nThe code should handle all cases like number of elements in A2[] may be more or less compared to A1[]. A2[] may have some elements which may not be there in A1[] and vice versa is also possible.\n\n## 思路一：\n> 先对arr1进行排序，然后遍历arr2，在排序后的arr1中二分查找元素并加入到结果数组中，并标记已经访问过的点。剩余点再进行遍历放到结果数组中。\n\n## 思路二：\n> 使用二叉平衡查找树对arr1进行建树（相同数字标记个数），然后遍历arr2进行查找，并标记已经获取过的点。最后前缀搜索拿出没有访问过的点。\n\n## 思路三：\n> 使用Hash对arr1进行计数hash，用arr2去hash中查找，并移除。对剩余数进行排序。\n\n## 思路四：\n> 自定义比较函数，然后进行排序。\n\n\n下面实现了思路四\n\n```\n#include <iostream>\n#include <map>\n#include <algorithm>\n\nusing namespace std;\nvoid solution4(int arr1[], int m, int arr2[], int n);\nint main(){\n\tint arr1[] = {2, 1, 2, 5, 7, 1, 9, 3, 6, 8, 8};\n\tint arr2[] = {2, 1, 8, 3};\n\tsolution4(arr1, 11, arr2, 4);\n\treturn 0;\n}\n\nmap<int, int> indMap;\n\nbool comparator(int i, int j);\nvoid printArray(int arr[], int n);\nvoid solution4(int arr1[], int m, int arr2[], int n) {\n\tfor(int i=0;i<n;i++){\n\t\tindMap[arr2[i]]=i;\n\t}\n\tsort(arr1, arr1+m, comparator);\n\tprintArray(arr1,m);\n}\n\nvoid printArray(int arr[], int n)\n{\n    for (int i=0; i<n; i++)\n    cout << arr[i] << \" \";\n\tcout << endl;\n}\n\nbool comparator(int i, int j) {\n\tmap<int,int>::iterator it1;\n\tmap<int,int>::iterator it2;\n\tit1 = indMap.find(i);\n\tit2 = indMap.find(j);\n\tif(it1 != indMap.end() && it2 != indMap.end()){\n\t\treturn it1->second < it2->second;\n\t} else if(it1 != indMap.end()){\n\t\treturn true;\n\t} else if(it2 != indMap.end()){\n\t\treturn false;\n\t} else {\n\t\treturn i<j;\n\t}\n}\n```\n\n","source":"_posts/2015-01-09-sort-array-according-order-defined-another-array.markdown","raw":"---\nlayout: post\ntitle: Sort an array according to the order defined by another array\ncategory: algorithm\ntag: [algorithm]\n---\n\n> 本题来源于 [GeeksforGeeks](http://www.geeksforgeeks.org/sort-array-according-order-defined-another-array/)\n\n\n# 题目描述：\n> 给出arr1 arr2两个数组，arr2确定了arr1中的数字的顺序大小，如果arr1中有没有存在arr2的数，则是自然顺序大小。目标是对arr1进行排序。\n\n> Given two arrays A1[] and A2[], sort A1 in such a way that the relative order among the elements will be same as those are in A2. For the elements not present in A2, append them at last in sorted order.  \nInput:  \nA1[] = {2, 1, 2, 5, 7, 1, 9, 3, 6, 8, 8}  \nA2[] = {2, 1, 8, 3}  \nOutput:   \nA1[] = {2, 2, 1, 1, 8, 8, 3, 5, 6, 7, 9}  \nThe code should handle all cases like number of elements in A2[] may be more or less compared to A1[]. A2[] may have some elements which may not be there in A1[] and vice versa is also possible.\n\n## 思路一：\n> 先对arr1进行排序，然后遍历arr2，在排序后的arr1中二分查找元素并加入到结果数组中，并标记已经访问过的点。剩余点再进行遍历放到结果数组中。\n\n## 思路二：\n> 使用二叉平衡查找树对arr1进行建树（相同数字标记个数），然后遍历arr2进行查找，并标记已经获取过的点。最后前缀搜索拿出没有访问过的点。\n\n## 思路三：\n> 使用Hash对arr1进行计数hash，用arr2去hash中查找，并移除。对剩余数进行排序。\n\n## 思路四：\n> 自定义比较函数，然后进行排序。\n\n\n下面实现了思路四\n\n```\n#include <iostream>\n#include <map>\n#include <algorithm>\n\nusing namespace std;\nvoid solution4(int arr1[], int m, int arr2[], int n);\nint main(){\n\tint arr1[] = {2, 1, 2, 5, 7, 1, 9, 3, 6, 8, 8};\n\tint arr2[] = {2, 1, 8, 3};\n\tsolution4(arr1, 11, arr2, 4);\n\treturn 0;\n}\n\nmap<int, int> indMap;\n\nbool comparator(int i, int j);\nvoid printArray(int arr[], int n);\nvoid solution4(int arr1[], int m, int arr2[], int n) {\n\tfor(int i=0;i<n;i++){\n\t\tindMap[arr2[i]]=i;\n\t}\n\tsort(arr1, arr1+m, comparator);\n\tprintArray(arr1,m);\n}\n\nvoid printArray(int arr[], int n)\n{\n    for (int i=0; i<n; i++)\n    cout << arr[i] << \" \";\n\tcout << endl;\n}\n\nbool comparator(int i, int j) {\n\tmap<int,int>::iterator it1;\n\tmap<int,int>::iterator it2;\n\tit1 = indMap.find(i);\n\tit2 = indMap.find(j);\n\tif(it1 != indMap.end() && it2 != indMap.end()){\n\t\treturn it1->second < it2->second;\n\t} else if(it1 != indMap.end()){\n\t\treturn true;\n\t} else if(it2 != indMap.end()){\n\t\treturn false;\n\t} else {\n\t\treturn i<j;\n\t}\n}\n```\n\n","slug":"sort-array-according-order-defined-another-array","published":1,"date":"2015-01-08T16:00:00.000Z","updated":"2017-03-06T13:46:14.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapyy0009phv9foqgyepc","content":"<blockquote>\n<p>本题来源于 <a href=\"http://www.geeksforgeeks.org/sort-array-according-order-defined-another-array/\" target=\"_blank\" rel=\"external\">GeeksforGeeks</a></p>\n</blockquote>\n<h1 id=\"题目描述：\"><a href=\"#题目描述：\" class=\"headerlink\" title=\"题目描述：\"></a>题目描述：</h1><blockquote>\n<p>给出arr1 arr2两个数组，arr2确定了arr1中的数字的顺序大小，如果arr1中有没有存在arr2的数，则是自然顺序大小。目标是对arr1进行排序。</p>\n<p>Given two arrays A1[] and A2[], sort A1 in such a way that the relative order among the elements will be same as those are in A2. For the elements not present in A2, append them at last in sorted order.<br>Input:<br>A1[] = {2, 1, 2, 5, 7, 1, 9, 3, 6, 8, 8}<br>A2[] = {2, 1, 8, 3}<br>Output:<br>A1[] = {2, 2, 1, 1, 8, 8, 3, 5, 6, 7, 9}<br>The code should handle all cases like number of elements in A2[] may be more or less compared to A1[]. A2[] may have some elements which may not be there in A1[] and vice versa is also possible.</p>\n</blockquote>\n<h2 id=\"思路一：\"><a href=\"#思路一：\" class=\"headerlink\" title=\"思路一：\"></a>思路一：</h2><blockquote>\n<p>先对arr1进行排序，然后遍历arr2，在排序后的arr1中二分查找元素并加入到结果数组中，并标记已经访问过的点。剩余点再进行遍历放到结果数组中。</p>\n</blockquote>\n<h2 id=\"思路二：\"><a href=\"#思路二：\" class=\"headerlink\" title=\"思路二：\"></a>思路二：</h2><blockquote>\n<p>使用二叉平衡查找树对arr1进行建树（相同数字标记个数），然后遍历arr2进行查找，并标记已经获取过的点。最后前缀搜索拿出没有访问过的点。</p>\n</blockquote>\n<h2 id=\"思路三：\"><a href=\"#思路三：\" class=\"headerlink\" title=\"思路三：\"></a>思路三：</h2><blockquote>\n<p>使用Hash对arr1进行计数hash，用arr2去hash中查找，并移除。对剩余数进行排序。</p>\n</blockquote>\n<h2 id=\"思路四：\"><a href=\"#思路四：\" class=\"headerlink\" title=\"思路四：\"></a>思路四：</h2><blockquote>\n<p>自定义比较函数，然后进行排序。</p>\n</blockquote>\n<p>下面实现了思路四</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\">#include &lt;map&gt;</div><div class=\"line\">#include &lt;algorithm&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\">void solution4(int arr1[], int m, int arr2[], int n);</div><div class=\"line\">int main()&#123;</div><div class=\"line\">\tint arr1[] = &#123;2, 1, 2, 5, 7, 1, 9, 3, 6, 8, 8&#125;;</div><div class=\"line\">\tint arr2[] = &#123;2, 1, 8, 3&#125;;</div><div class=\"line\">\tsolution4(arr1, 11, arr2, 4);</div><div class=\"line\">\treturn 0;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">map&lt;int, int&gt; indMap;</div><div class=\"line\"></div><div class=\"line\">bool comparator(int i, int j);</div><div class=\"line\">void printArray(int arr[], int n);</div><div class=\"line\">void solution4(int arr1[], int m, int arr2[], int n) &#123;</div><div class=\"line\">\tfor(int i=0;i&lt;n;i++)&#123;</div><div class=\"line\">\t\tindMap[arr2[i]]=i;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tsort(arr1, arr1+m, comparator);</div><div class=\"line\">\tprintArray(arr1,m);</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void printArray(int arr[], int n)</div><div class=\"line\">&#123;</div><div class=\"line\">    for (int i=0; i&lt;n; i++)</div><div class=\"line\">    cout &lt;&lt; arr[i] &lt;&lt; &quot; &quot;;</div><div class=\"line\">\tcout &lt;&lt; endl;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">bool comparator(int i, int j) &#123;</div><div class=\"line\">\tmap&lt;int,int&gt;::iterator it1;</div><div class=\"line\">\tmap&lt;int,int&gt;::iterator it2;</div><div class=\"line\">\tit1 = indMap.find(i);</div><div class=\"line\">\tit2 = indMap.find(j);</div><div class=\"line\">\tif(it1 != indMap.end() &amp;&amp; it2 != indMap.end())&#123;</div><div class=\"line\">\t\treturn it1-&gt;second &lt; it2-&gt;second;</div><div class=\"line\">\t&#125; else if(it1 != indMap.end())&#123;</div><div class=\"line\">\t\treturn true;</div><div class=\"line\">\t&#125; else if(it2 != indMap.end())&#123;</div><div class=\"line\">\t\treturn false;</div><div class=\"line\">\t&#125; else &#123;</div><div class=\"line\">\t\treturn i&lt;j;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<blockquote>\n<p>本题来源于 <a href=\"http://www.geeksforgeeks.org/sort-array-according-order-defined-another-array/\">GeeksforGeeks</a></p>\n</blockquote>\n<h1 id=\"题目描述：\"><a href=\"#题目描述：\" class=\"headerlink\" title=\"题目描述：\"></a>题目描述：</h1><blockquote>\n<p>给出arr1 arr2两个数组，arr2确定了arr1中的数字的顺序大小，如果arr1中有没有存在arr2的数，则是自然顺序大小。目标是对arr1进行排序。</p>\n<p>Given two arrays A1[] and A2[], sort A1 in such a way that the relative order among the elements will be same as those are in A2. For the elements not present in A2, append them at last in sorted order.<br>Input:<br>A1[] = {2, 1, 2, 5, 7, 1, 9, 3, 6, 8, 8}<br>A2[] = {2, 1, 8, 3}<br>Output:<br>A1[] = {2, 2, 1, 1, 8, 8, 3, 5, 6, 7, 9}<br>The code should handle all cases like number of elements in A2[] may be more or less compared to A1[]. A2[] may have some elements which may not be there in A1[] and vice versa is also possible.</p>\n</blockquote>\n<h2 id=\"思路一：\"><a href=\"#思路一：\" class=\"headerlink\" title=\"思路一：\"></a>思路一：</h2><blockquote>\n<p>先对arr1进行排序，然后遍历arr2，在排序后的arr1中二分查找元素并加入到结果数组中，并标记已经访问过的点。剩余点再进行遍历放到结果数组中。</p>\n</blockquote>\n<h2 id=\"思路二：\"><a href=\"#思路二：\" class=\"headerlink\" title=\"思路二：\"></a>思路二：</h2><blockquote>\n<p>使用二叉平衡查找树对arr1进行建树（相同数字标记个数），然后遍历arr2进行查找，并标记已经获取过的点。最后前缀搜索拿出没有访问过的点。</p>\n</blockquote>\n<h2 id=\"思路三：\"><a href=\"#思路三：\" class=\"headerlink\" title=\"思路三：\"></a>思路三：</h2><blockquote>\n<p>使用Hash对arr1进行计数hash，用arr2去hash中查找，并移除。对剩余数进行排序。</p>\n</blockquote>\n<h2 id=\"思路四：\"><a href=\"#思路四：\" class=\"headerlink\" title=\"思路四：\"></a>思路四：</h2><blockquote>\n<p>自定义比较函数，然后进行排序。</p>\n</blockquote>\n<p>下面实现了思路四</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\">#include &lt;map&gt;</div><div class=\"line\">#include &lt;algorithm&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\">void solution4(int arr1[], int m, int arr2[], int n);</div><div class=\"line\">int main()&#123;</div><div class=\"line\">\tint arr1[] = &#123;2, 1, 2, 5, 7, 1, 9, 3, 6, 8, 8&#125;;</div><div class=\"line\">\tint arr2[] = &#123;2, 1, 8, 3&#125;;</div><div class=\"line\">\tsolution4(arr1, 11, arr2, 4);</div><div class=\"line\">\treturn 0;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">map&lt;int, int&gt; indMap;</div><div class=\"line\"></div><div class=\"line\">bool comparator(int i, int j);</div><div class=\"line\">void printArray(int arr[], int n);</div><div class=\"line\">void solution4(int arr1[], int m, int arr2[], int n) &#123;</div><div class=\"line\">\tfor(int i=0;i&lt;n;i++)&#123;</div><div class=\"line\">\t\tindMap[arr2[i]]=i;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tsort(arr1, arr1+m, comparator);</div><div class=\"line\">\tprintArray(arr1,m);</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">void printArray(int arr[], int n)</div><div class=\"line\">&#123;</div><div class=\"line\">    for (int i=0; i&lt;n; i++)</div><div class=\"line\">    cout &lt;&lt; arr[i] &lt;&lt; &quot; &quot;;</div><div class=\"line\">\tcout &lt;&lt; endl;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">bool comparator(int i, int j) &#123;</div><div class=\"line\">\tmap&lt;int,int&gt;::iterator it1;</div><div class=\"line\">\tmap&lt;int,int&gt;::iterator it2;</div><div class=\"line\">\tit1 = indMap.find(i);</div><div class=\"line\">\tit2 = indMap.find(j);</div><div class=\"line\">\tif(it1 != indMap.end() &amp;&amp; it2 != indMap.end())&#123;</div><div class=\"line\">\t\treturn it1-&gt;second &lt; it2-&gt;second;</div><div class=\"line\">\t&#125; else if(it1 != indMap.end())&#123;</div><div class=\"line\">\t\treturn true;</div><div class=\"line\">\t&#125; else if(it2 != indMap.end())&#123;</div><div class=\"line\">\t\treturn false;</div><div class=\"line\">\t&#125; else &#123;</div><div class=\"line\">\t\treturn i&lt;j;</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Search an element in a sorted and pivoted array","_content":"\n> 本题来源于 [GeeksforGeeks](http://www.geeksforgeeks.org/search-an-element-in-a-sorted-and-pivoted-array/)\n\n# 题目描述：\n\n> 给出一个排序过的数组，但是经过了一次反转，现在进行search。\n\n> An element in a sorted array can be found in O(log n) time via binary search. But suppose I rotate the sorted array at some pivot unknown to you beforehand. So for instance, 1 2 3 4 5 might become 3 4 5 1 2. Devise a way to find an element in the rotated array in O(log n) time.\n\n## 解法（无重复）：\n\n> 没有什么技巧，就是思路清晰就好。\n\n> 因为是有序，所以我们每次二分拿到中点的时候，看看哪半段是真正有序的\n\n>> 如果`arr[first]<=arr[mid]`，那么说明前半段是有序，就用前半段的两个边界点判断就可以知道target在前面还是后面；\n\n>> 否则说明后半段是有序的，那么就用后半段边界点比较就可以知道是在前面还是后面。\n\n下面是无重复的代码实现\n\n```\n#include <iostream>\n\nusing namespace std;\n\nint search(int *arr, int size, int target){\n\tint first=0, last=size;\n\twhile(first!=last){\n\t\tint mid=(first+last)/2;\n\t\tif(arr[mid]==target) return mid;\n\t\tif(arr[first]<=arr[mid]){\n\t\t\tif(arr[first]<=target && arr[mid]>target){\n\t\t\t\tlast=mid;\n\t\t\t} else {\n\t\t\t\tfirst=mid+1;\n\t\t\t}\n\t\t} else {\n\t\t\tif(target>arr[mid]&& target<=arr[last-1]){\n\t\t\t\tfirst=mid+1;\n\t\t\t} else {\n\t\t\t\tlast=mid;\n\t\t\t}\n\t\t}\n\t}\n\treturn -1;\n}\n\nint main(){\n\tint arr[] = {5,6,1,2,3,4};\n\tfor(int i=0;i<6;i++){\n\t\tcout<<search(arr,6,i+1)<<endl;\n\t}\n\treturn 0;\n}\n```\n\n## 解法（有重复）：\n\n> 当有重复时，也是依靠边界\n\n>> 分析一下，如果前半段或者后半段的两个边界有一个不同，那么就根据上面算法选择一个段。\n\n>> 如果`arr[first]==arr[mid]`，进而如果`arr[mid]!=arr[last]`，那么就只要搜索后半段就行了，因为前半段比如都是一样的数字。用反证法就可以证明：\n\n>>> 假设前半段不是都相等，那么肯定是先递增到最大值，然后从最小值开始增到`arr[mid]`那么大，后面只能增到或者等于`arr[mid]`，现在知道`arr[last]!=arr[mid]`，那么后面一定增大，那么就会导致`arr[last]>arr[mid]`，也就是`arr[last]>arr[first]`，与题意不符合，所以前半段是一样的，只需要搜索后半段就好了。\n\n>> 如果`arr[first]==arr[mid]`且`arr[mid]==arr[last]`，那么前后都有可能，那么都需要搜索。递归的话就搜两段，非递归就把前后各推进1就好了。\n\n>> 还需要考虑`arr[first]!=arr[mid]`但是`arr[mid]==arr[last]`的情况吗？需要，这时候就只需要查找前半段就好了。\n\n下面是一个非递归版本，递归版本来自[codepad.org/mqkc4I3R](http://codepad.org/mqkc4I3R) 上面有bug，没有考虑最后一种情况，我修改了一下，放到了[这里](http://codepad.org/Qljz60Fl)。\n\n有重复非递归的代码实现：\n\n```\n#include <iostream>\n\nusing namespace std;\n\nint search2(int *arr, int size, int target){\n\tint first=0, last=size;\n\twhile(first<=last){\n\t\tint mid=(first+last)/2;\n\t\tif(arr[mid]==target) return mid;\n\t\tif(arr[first]<arr[mid]){\n\t\t\tif(arr[first]<=target && arr[mid]>target){\n\t\t\t\tlast=mid;\n\t\t\t} else {\n\t\t\t\tfirst=mid+1;\n\t\t\t}\n\t\t} else if(arr[mid]<arr[last-1]) {\n\t\t\tif(target>arr[mid]&& target<=arr[last-1]){\n\t\t\t\tfirst=mid+1;\n\t\t\t} else {\n\t\t\t\tlast=mid;\n\t\t\t}\n\t\t} else if(arr[first]==arr[mid]){\n\t\t\tif(arr[mid]!=arr[last-1]){\n\t\t\t\tfirst=mid+1;\n\t\t\t}else{\n\t\t\t\tfirst++;\n                last--;\n\t\t\t}\n\t\t} else {\n\t\t\tlast=mid;\n\t\t}\n\t}\n\treturn -1;\n}\n\nint main(){\n\tint arr[] = {6,1,2,3,4,5,5,5,5,5,5,5,5};\n\tfor(int i=0;i<6;i++){\n\t\tcout<<search2(arr,13,i+1)<<endl;\n\t}\n\treturn 0;\n}\n```\n\n","source":"_posts/2015-01-12-search-an-element-in-a-sorted-and-pivoted-array.markdown","raw":"---\nlayout: post\ntitle: Search an element in a sorted and pivoted array\ncategory: algorithm\ntag: [algorithm]\n---\n\n> 本题来源于 [GeeksforGeeks](http://www.geeksforgeeks.org/search-an-element-in-a-sorted-and-pivoted-array/)\n\n# 题目描述：\n\n> 给出一个排序过的数组，但是经过了一次反转，现在进行search。\n\n> An element in a sorted array can be found in O(log n) time via binary search. But suppose I rotate the sorted array at some pivot unknown to you beforehand. So for instance, 1 2 3 4 5 might become 3 4 5 1 2. Devise a way to find an element in the rotated array in O(log n) time.\n\n## 解法（无重复）：\n\n> 没有什么技巧，就是思路清晰就好。\n\n> 因为是有序，所以我们每次二分拿到中点的时候，看看哪半段是真正有序的\n\n>> 如果`arr[first]<=arr[mid]`，那么说明前半段是有序，就用前半段的两个边界点判断就可以知道target在前面还是后面；\n\n>> 否则说明后半段是有序的，那么就用后半段边界点比较就可以知道是在前面还是后面。\n\n下面是无重复的代码实现\n\n```\n#include <iostream>\n\nusing namespace std;\n\nint search(int *arr, int size, int target){\n\tint first=0, last=size;\n\twhile(first!=last){\n\t\tint mid=(first+last)/2;\n\t\tif(arr[mid]==target) return mid;\n\t\tif(arr[first]<=arr[mid]){\n\t\t\tif(arr[first]<=target && arr[mid]>target){\n\t\t\t\tlast=mid;\n\t\t\t} else {\n\t\t\t\tfirst=mid+1;\n\t\t\t}\n\t\t} else {\n\t\t\tif(target>arr[mid]&& target<=arr[last-1]){\n\t\t\t\tfirst=mid+1;\n\t\t\t} else {\n\t\t\t\tlast=mid;\n\t\t\t}\n\t\t}\n\t}\n\treturn -1;\n}\n\nint main(){\n\tint arr[] = {5,6,1,2,3,4};\n\tfor(int i=0;i<6;i++){\n\t\tcout<<search(arr,6,i+1)<<endl;\n\t}\n\treturn 0;\n}\n```\n\n## 解法（有重复）：\n\n> 当有重复时，也是依靠边界\n\n>> 分析一下，如果前半段或者后半段的两个边界有一个不同，那么就根据上面算法选择一个段。\n\n>> 如果`arr[first]==arr[mid]`，进而如果`arr[mid]!=arr[last]`，那么就只要搜索后半段就行了，因为前半段比如都是一样的数字。用反证法就可以证明：\n\n>>> 假设前半段不是都相等，那么肯定是先递增到最大值，然后从最小值开始增到`arr[mid]`那么大，后面只能增到或者等于`arr[mid]`，现在知道`arr[last]!=arr[mid]`，那么后面一定增大，那么就会导致`arr[last]>arr[mid]`，也就是`arr[last]>arr[first]`，与题意不符合，所以前半段是一样的，只需要搜索后半段就好了。\n\n>> 如果`arr[first]==arr[mid]`且`arr[mid]==arr[last]`，那么前后都有可能，那么都需要搜索。递归的话就搜两段，非递归就把前后各推进1就好了。\n\n>> 还需要考虑`arr[first]!=arr[mid]`但是`arr[mid]==arr[last]`的情况吗？需要，这时候就只需要查找前半段就好了。\n\n下面是一个非递归版本，递归版本来自[codepad.org/mqkc4I3R](http://codepad.org/mqkc4I3R) 上面有bug，没有考虑最后一种情况，我修改了一下，放到了[这里](http://codepad.org/Qljz60Fl)。\n\n有重复非递归的代码实现：\n\n```\n#include <iostream>\n\nusing namespace std;\n\nint search2(int *arr, int size, int target){\n\tint first=0, last=size;\n\twhile(first<=last){\n\t\tint mid=(first+last)/2;\n\t\tif(arr[mid]==target) return mid;\n\t\tif(arr[first]<arr[mid]){\n\t\t\tif(arr[first]<=target && arr[mid]>target){\n\t\t\t\tlast=mid;\n\t\t\t} else {\n\t\t\t\tfirst=mid+1;\n\t\t\t}\n\t\t} else if(arr[mid]<arr[last-1]) {\n\t\t\tif(target>arr[mid]&& target<=arr[last-1]){\n\t\t\t\tfirst=mid+1;\n\t\t\t} else {\n\t\t\t\tlast=mid;\n\t\t\t}\n\t\t} else if(arr[first]==arr[mid]){\n\t\t\tif(arr[mid]!=arr[last-1]){\n\t\t\t\tfirst=mid+1;\n\t\t\t}else{\n\t\t\t\tfirst++;\n                last--;\n\t\t\t}\n\t\t} else {\n\t\t\tlast=mid;\n\t\t}\n\t}\n\treturn -1;\n}\n\nint main(){\n\tint arr[] = {6,1,2,3,4,5,5,5,5,5,5,5,5};\n\tfor(int i=0;i<6;i++){\n\t\tcout<<search2(arr,13,i+1)<<endl;\n\t}\n\treturn 0;\n}\n```\n\n","slug":"search-an-element-in-a-sorted-and-pivoted-array","published":1,"date":"2015-01-11T16:00:00.000Z","updated":"2017-03-06T13:44:28.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapz1000cphv9jwp171e7","content":"<blockquote>\n<p>本题来源于 <a href=\"http://www.geeksforgeeks.org/search-an-element-in-a-sorted-and-pivoted-array/\" target=\"_blank\" rel=\"external\">GeeksforGeeks</a></p>\n</blockquote>\n<h1 id=\"题目描述：\"><a href=\"#题目描述：\" class=\"headerlink\" title=\"题目描述：\"></a>题目描述：</h1><blockquote>\n<p>给出一个排序过的数组，但是经过了一次反转，现在进行search。</p>\n<p>An element in a sorted array can be found in O(log n) time via binary search. But suppose I rotate the sorted array at some pivot unknown to you beforehand. So for instance, 1 2 3 4 5 might become 3 4 5 1 2. Devise a way to find an element in the rotated array in O(log n) time.</p>\n</blockquote>\n<h2 id=\"解法（无重复）：\"><a href=\"#解法（无重复）：\" class=\"headerlink\" title=\"解法（无重复）：\"></a>解法（无重复）：</h2><blockquote>\n<p>没有什么技巧，就是思路清晰就好。</p>\n<p>因为是有序，所以我们每次二分拿到中点的时候，看看哪半段是真正有序的</p>\n<blockquote>\n<p>如果<code>arr[first]&lt;=arr[mid]</code>，那么说明前半段是有序，就用前半段的两个边界点判断就可以知道target在前面还是后面；</p>\n<p>否则说明后半段是有序的，那么就用后半段边界点比较就可以知道是在前面还是后面。</p>\n</blockquote>\n</blockquote>\n<p>下面是无重复的代码实现</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\"></div><div class=\"line\">int search(int *arr, int size, int target)&#123;</div><div class=\"line\">\tint first=0, last=size;</div><div class=\"line\">\twhile(first!=last)&#123;</div><div class=\"line\">\t\tint mid=(first+last)/2;</div><div class=\"line\">\t\tif(arr[mid]==target) return mid;</div><div class=\"line\">\t\tif(arr[first]&lt;=arr[mid])&#123;</div><div class=\"line\">\t\t\tif(arr[first]&lt;=target &amp;&amp; arr[mid]&gt;target)&#123;</div><div class=\"line\">\t\t\t\tlast=mid;</div><div class=\"line\">\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125; else &#123;</div><div class=\"line\">\t\t\tif(target&gt;arr[mid]&amp;&amp; target&lt;=arr[last-1])&#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\tlast=mid;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn -1;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int main()&#123;</div><div class=\"line\">\tint arr[] = &#123;5,6,1,2,3,4&#125;;</div><div class=\"line\">\tfor(int i=0;i&lt;6;i++)&#123;</div><div class=\"line\">\t\tcout&lt;&lt;search(arr,6,i+1)&lt;&lt;endl;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn 0;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"解法（有重复）：\"><a href=\"#解法（有重复）：\" class=\"headerlink\" title=\"解法（有重复）：\"></a>解法（有重复）：</h2><blockquote>\n<p>当有重复时，也是依靠边界</p>\n<blockquote>\n<p>分析一下，如果前半段或者后半段的两个边界有一个不同，那么就根据上面算法选择一个段。</p>\n<p>如果<code>arr[first]==arr[mid]</code>，进而如果<code>arr[mid]!=arr[last]</code>，那么就只要搜索后半段就行了，因为前半段比如都是一样的数字。用反证法就可以证明：</p>\n<blockquote>\n<p>假设前半段不是都相等，那么肯定是先递增到最大值，然后从最小值开始增到<code>arr[mid]</code>那么大，后面只能增到或者等于<code>arr[mid]</code>，现在知道<code>arr[last]!=arr[mid]</code>，那么后面一定增大，那么就会导致<code>arr[last]&gt;arr[mid]</code>，也就是<code>arr[last]&gt;arr[first]</code>，与题意不符合，所以前半段是一样的，只需要搜索后半段就好了。</p>\n</blockquote>\n<p>如果<code>arr[first]==arr[mid]</code>且<code>arr[mid]==arr[last]</code>，那么前后都有可能，那么都需要搜索。递归的话就搜两段，非递归就把前后各推进1就好了。</p>\n<p>还需要考虑<code>arr[first]!=arr[mid]</code>但是<code>arr[mid]==arr[last]</code>的情况吗？需要，这时候就只需要查找前半段就好了。</p>\n</blockquote>\n</blockquote>\n<p>下面是一个非递归版本，递归版本来自<a href=\"http://codepad.org/mqkc4I3R\" target=\"_blank\" rel=\"external\">codepad.org/mqkc4I3R</a> 上面有bug，没有考虑最后一种情况，我修改了一下，放到了<a href=\"http://codepad.org/Qljz60Fl\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p>有重复非递归的代码实现：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\"></div><div class=\"line\">int search2(int *arr, int size, int target)&#123;</div><div class=\"line\">\tint first=0, last=size;</div><div class=\"line\">\twhile(first&lt;=last)&#123;</div><div class=\"line\">\t\tint mid=(first+last)/2;</div><div class=\"line\">\t\tif(arr[mid]==target) return mid;</div><div class=\"line\">\t\tif(arr[first]&lt;arr[mid])&#123;</div><div class=\"line\">\t\t\tif(arr[first]&lt;=target &amp;&amp; arr[mid]&gt;target)&#123;</div><div class=\"line\">\t\t\t\tlast=mid;</div><div class=\"line\">\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125; else if(arr[mid]&lt;arr[last-1]) &#123;</div><div class=\"line\">\t\t\tif(target&gt;arr[mid]&amp;&amp; target&lt;=arr[last-1])&#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\tlast=mid;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125; else if(arr[first]==arr[mid])&#123;</div><div class=\"line\">\t\t\tif(arr[mid]!=arr[last-1])&#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125;else&#123;</div><div class=\"line\">\t\t\t\tfirst++;</div><div class=\"line\">                last--;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125; else &#123;</div><div class=\"line\">\t\t\tlast=mid;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn -1;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int main()&#123;</div><div class=\"line\">\tint arr[] = &#123;6,1,2,3,4,5,5,5,5,5,5,5,5&#125;;</div><div class=\"line\">\tfor(int i=0;i&lt;6;i++)&#123;</div><div class=\"line\">\t\tcout&lt;&lt;search2(arr,13,i+1)&lt;&lt;endl;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn 0;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<blockquote>\n<p>本题来源于 <a href=\"http://www.geeksforgeeks.org/search-an-element-in-a-sorted-and-pivoted-array/\">GeeksforGeeks</a></p>\n</blockquote>\n<h1 id=\"题目描述：\"><a href=\"#题目描述：\" class=\"headerlink\" title=\"题目描述：\"></a>题目描述：</h1><blockquote>\n<p>给出一个排序过的数组，但是经过了一次反转，现在进行search。</p>\n<p>An element in a sorted array can be found in O(log n) time via binary search. But suppose I rotate the sorted array at some pivot unknown to you beforehand. So for instance, 1 2 3 4 5 might become 3 4 5 1 2. Devise a way to find an element in the rotated array in O(log n) time.</p>\n</blockquote>\n<h2 id=\"解法（无重复）：\"><a href=\"#解法（无重复）：\" class=\"headerlink\" title=\"解法（无重复）：\"></a>解法（无重复）：</h2><blockquote>\n<p>没有什么技巧，就是思路清晰就好。</p>\n<p>因为是有序，所以我们每次二分拿到中点的时候，看看哪半段是真正有序的</p>\n<blockquote>\n<p>如果<code>arr[first]&lt;=arr[mid]</code>，那么说明前半段是有序，就用前半段的两个边界点判断就可以知道target在前面还是后面；</p>\n<p>否则说明后半段是有序的，那么就用后半段边界点比较就可以知道是在前面还是后面。</p>\n</blockquote>\n</blockquote>\n<p>下面是无重复的代码实现</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\"></div><div class=\"line\">int search(int *arr, int size, int target)&#123;</div><div class=\"line\">\tint first=0, last=size;</div><div class=\"line\">\twhile(first!=last)&#123;</div><div class=\"line\">\t\tint mid=(first+last)/2;</div><div class=\"line\">\t\tif(arr[mid]==target) return mid;</div><div class=\"line\">\t\tif(arr[first]&lt;=arr[mid])&#123;</div><div class=\"line\">\t\t\tif(arr[first]&lt;=target &amp;&amp; arr[mid]&gt;target)&#123;</div><div class=\"line\">\t\t\t\tlast=mid;</div><div class=\"line\">\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125; else &#123;</div><div class=\"line\">\t\t\tif(target&gt;arr[mid]&amp;&amp; target&lt;=arr[last-1])&#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\tlast=mid;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn -1;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int main()&#123;</div><div class=\"line\">\tint arr[] = &#123;5,6,1,2,3,4&#125;;</div><div class=\"line\">\tfor(int i=0;i&lt;6;i++)&#123;</div><div class=\"line\">\t\tcout&lt;&lt;search(arr,6,i+1)&lt;&lt;endl;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn 0;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"解法（有重复）：\"><a href=\"#解法（有重复）：\" class=\"headerlink\" title=\"解法（有重复）：\"></a>解法（有重复）：</h2><blockquote>\n<p>当有重复时，也是依靠边界</p>\n<blockquote>\n<p>分析一下，如果前半段或者后半段的两个边界有一个不同，那么就根据上面算法选择一个段。</p>\n<p>如果<code>arr[first]==arr[mid]</code>，进而如果<code>arr[mid]!=arr[last]</code>，那么就只要搜索后半段就行了，因为前半段比如都是一样的数字。用反证法就可以证明：</p>\n<blockquote>\n<p>假设前半段不是都相等，那么肯定是先递增到最大值，然后从最小值开始增到<code>arr[mid]</code>那么大，后面只能增到或者等于<code>arr[mid]</code>，现在知道<code>arr[last]!=arr[mid]</code>，那么后面一定增大，那么就会导致<code>arr[last]&gt;arr[mid]</code>，也就是<code>arr[last]&gt;arr[first]</code>，与题意不符合，所以前半段是一样的，只需要搜索后半段就好了。</p>\n</blockquote>\n<p>如果<code>arr[first]==arr[mid]</code>且<code>arr[mid]==arr[last]</code>，那么前后都有可能，那么都需要搜索。递归的话就搜两段，非递归就把前后各推进1就好了。</p>\n<p>还需要考虑<code>arr[first]!=arr[mid]</code>但是<code>arr[mid]==arr[last]</code>的情况吗？需要，这时候就只需要查找前半段就好了。</p>\n</blockquote>\n</blockquote>\n<p>下面是一个非递归版本，递归版本来自<a href=\"http://codepad.org/mqkc4I3R\">codepad.org/mqkc4I3R</a> 上面有bug，没有考虑最后一种情况，我修改了一下，放到了<a href=\"http://codepad.org/Qljz60Fl\">这里</a>。</p>\n<p>有重复非递归的代码实现：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\">#include &lt;iostream&gt;</div><div class=\"line\"></div><div class=\"line\">using namespace std;</div><div class=\"line\"></div><div class=\"line\">int search2(int *arr, int size, int target)&#123;</div><div class=\"line\">\tint first=0, last=size;</div><div class=\"line\">\twhile(first&lt;=last)&#123;</div><div class=\"line\">\t\tint mid=(first+last)/2;</div><div class=\"line\">\t\tif(arr[mid]==target) return mid;</div><div class=\"line\">\t\tif(arr[first]&lt;arr[mid])&#123;</div><div class=\"line\">\t\t\tif(arr[first]&lt;=target &amp;&amp; arr[mid]&gt;target)&#123;</div><div class=\"line\">\t\t\t\tlast=mid;</div><div class=\"line\">\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125; else if(arr[mid]&lt;arr[last-1]) &#123;</div><div class=\"line\">\t\t\tif(target&gt;arr[mid]&amp;&amp; target&lt;=arr[last-1])&#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\tlast=mid;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125; else if(arr[first]==arr[mid])&#123;</div><div class=\"line\">\t\t\tif(arr[mid]!=arr[last-1])&#123;</div><div class=\"line\">\t\t\t\tfirst=mid+1;</div><div class=\"line\">\t\t\t&#125;else&#123;</div><div class=\"line\">\t\t\t\tfirst++;</div><div class=\"line\">                last--;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125; else &#123;</div><div class=\"line\">\t\t\tlast=mid;</div><div class=\"line\">\t\t&#125;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn -1;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">int main()&#123;</div><div class=\"line\">\tint arr[] = &#123;6,1,2,3,4,5,5,5,5,5,5,5,5&#125;;</div><div class=\"line\">\tfor(int i=0;i&lt;6;i++)&#123;</div><div class=\"line\">\t\tcout&lt;&lt;search2(arr,13,i+1)&lt;&lt;endl;</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn 0;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Distributed Systems Course 6.824 lab 2","_content":"\n> 实验要求在[这里](http://nil.csail.mit.edu/6.824/2015/labs/lab-2.html)\n\n- 本实验分为两部分，首先是实现一个viewservie，控制server视图，使在某一时刻，最多只有一个primary的server提供服务，如果有空闲server，纪录到backup中，一旦primary的server出现异常，backup就会被选为primary继续提供服务。其次是在此基础上实现一个kv存储服务。只有primary的server直接面向client提供Get/Put/Append服务。\n\n# Part A: The Viewservice\n\n这部分主要是控制viewservice的逻辑，使之能过确定一个primary和backup。能成为primary有两种情况，一是viewservice启动时第一个注册的server，或者之前是一个backup且viewservice判断当前primary无效。\nviewservice控制view的版本，在一下情况下，view的版本会更新：\n\n1. 一段时间内没有收到p/b的ping\n2. p/b中有一个重启了（重启后发送的view version为0，表示重启）。\n3. primary为空且存在一个backup server。\n\n但是view变更存在一个前提条件，就是当前的view版本已经被primary认可，即当前版本被primary重新ping过。\n\n# Part B: The primary/backup key/value service\n\n这部分需要在viewservice基础上完成一个kv store service，主要的思想是\n\n1. 只有primary server提供服务。\n2. 在Put/Append操作时，需要同步到backup\n3. 因为Append本身不满足at-most-once语义，需要在server端加以控制，具体就是纪录下已经操作成功的append操作（由于课程说明，只纪录最近一次即可。）\n4. 要处理各种异常情况，如果backup变化，需要从primary完全同步到backup(尝试多次)。如果primary/backup有一个出现错误，client应该知道这种错误并重新发起请求，这时候需要先更新view，重新获取primary。\n\n\n总的来说，还是挺麻烦的，这部分实验花了挺多时间，主要是在p/b之间的数据同步上，虽然最后给出test case都过了，但是肯定还是会有一些情况没有考虑。","source":"_posts/2015-11-28-Distributed-Systems-course-6.824-lab2.markdown","raw":"---\nlayout: post\ntitle: Distributed Systems Course 6.824 lab 2\ncategory: [Distributed System]\n---\n\n> 实验要求在[这里](http://nil.csail.mit.edu/6.824/2015/labs/lab-2.html)\n\n- 本实验分为两部分，首先是实现一个viewservie，控制server视图，使在某一时刻，最多只有一个primary的server提供服务，如果有空闲server，纪录到backup中，一旦primary的server出现异常，backup就会被选为primary继续提供服务。其次是在此基础上实现一个kv存储服务。只有primary的server直接面向client提供Get/Put/Append服务。\n\n# Part A: The Viewservice\n\n这部分主要是控制viewservice的逻辑，使之能过确定一个primary和backup。能成为primary有两种情况，一是viewservice启动时第一个注册的server，或者之前是一个backup且viewservice判断当前primary无效。\nviewservice控制view的版本，在一下情况下，view的版本会更新：\n\n1. 一段时间内没有收到p/b的ping\n2. p/b中有一个重启了（重启后发送的view version为0，表示重启）。\n3. primary为空且存在一个backup server。\n\n但是view变更存在一个前提条件，就是当前的view版本已经被primary认可，即当前版本被primary重新ping过。\n\n# Part B: The primary/backup key/value service\n\n这部分需要在viewservice基础上完成一个kv store service，主要的思想是\n\n1. 只有primary server提供服务。\n2. 在Put/Append操作时，需要同步到backup\n3. 因为Append本身不满足at-most-once语义，需要在server端加以控制，具体就是纪录下已经操作成功的append操作（由于课程说明，只纪录最近一次即可。）\n4. 要处理各种异常情况，如果backup变化，需要从primary完全同步到backup(尝试多次)。如果primary/backup有一个出现错误，client应该知道这种错误并重新发起请求，这时候需要先更新view，重新获取primary。\n\n\n总的来说，还是挺麻烦的，这部分实验花了挺多时间，主要是在p/b之间的数据同步上，虽然最后给出test case都过了，但是肯定还是会有一些情况没有考虑。","slug":"Distributed-Systems-course-6.824-lab2","published":1,"date":"2015-11-27T16:00:00.000Z","updated":"2017-03-05T15:27:05.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapz2000fphv9dbr2neym","content":"<blockquote>\n<p>实验要求在<a href=\"http://nil.csail.mit.edu/6.824/2015/labs/lab-2.html\" target=\"_blank\" rel=\"external\">这里</a></p>\n</blockquote>\n<ul>\n<li>本实验分为两部分，首先是实现一个viewservie，控制server视图，使在某一时刻，最多只有一个primary的server提供服务，如果有空闲server，纪录到backup中，一旦primary的server出现异常，backup就会被选为primary继续提供服务。其次是在此基础上实现一个kv存储服务。只有primary的server直接面向client提供Get/Put/Append服务。</li>\n</ul>\n<h1 id=\"Part-A-The-Viewservice\"><a href=\"#Part-A-The-Viewservice\" class=\"headerlink\" title=\"Part A: The Viewservice\"></a>Part A: The Viewservice</h1><p>这部分主要是控制viewservice的逻辑，使之能过确定一个primary和backup。能成为primary有两种情况，一是viewservice启动时第一个注册的server，或者之前是一个backup且viewservice判断当前primary无效。<br>viewservice控制view的版本，在一下情况下，view的版本会更新：</p>\n<ol>\n<li>一段时间内没有收到p/b的ping</li>\n<li>p/b中有一个重启了（重启后发送的view version为0，表示重启）。</li>\n<li>primary为空且存在一个backup server。</li>\n</ol>\n<p>但是view变更存在一个前提条件，就是当前的view版本已经被primary认可，即当前版本被primary重新ping过。</p>\n<h1 id=\"Part-B-The-primary-backup-key-value-service\"><a href=\"#Part-B-The-primary-backup-key-value-service\" class=\"headerlink\" title=\"Part B: The primary/backup key/value service\"></a>Part B: The primary/backup key/value service</h1><p>这部分需要在viewservice基础上完成一个kv store service，主要的思想是</p>\n<ol>\n<li>只有primary server提供服务。</li>\n<li>在Put/Append操作时，需要同步到backup</li>\n<li>因为Append本身不满足at-most-once语义，需要在server端加以控制，具体就是纪录下已经操作成功的append操作（由于课程说明，只纪录最近一次即可。）</li>\n<li>要处理各种异常情况，如果backup变化，需要从primary完全同步到backup(尝试多次)。如果primary/backup有一个出现错误，client应该知道这种错误并重新发起请求，这时候需要先更新view，重新获取primary。</li>\n</ol>\n<p>总的来说，还是挺麻烦的，这部分实验花了挺多时间，主要是在p/b之间的数据同步上，虽然最后给出test case都过了，但是肯定还是会有一些情况没有考虑。</p>\n","excerpt":"","more":"<blockquote>\n<p>实验要求在<a href=\"http://nil.csail.mit.edu/6.824/2015/labs/lab-2.html\">这里</a></p>\n</blockquote>\n<ul>\n<li>本实验分为两部分，首先是实现一个viewservie，控制server视图，使在某一时刻，最多只有一个primary的server提供服务，如果有空闲server，纪录到backup中，一旦primary的server出现异常，backup就会被选为primary继续提供服务。其次是在此基础上实现一个kv存储服务。只有primary的server直接面向client提供Get/Put/Append服务。</li>\n</ul>\n<h1 id=\"Part-A-The-Viewservice\"><a href=\"#Part-A-The-Viewservice\" class=\"headerlink\" title=\"Part A: The Viewservice\"></a>Part A: The Viewservice</h1><p>这部分主要是控制viewservice的逻辑，使之能过确定一个primary和backup。能成为primary有两种情况，一是viewservice启动时第一个注册的server，或者之前是一个backup且viewservice判断当前primary无效。<br>viewservice控制view的版本，在一下情况下，view的版本会更新：</p>\n<ol>\n<li>一段时间内没有收到p/b的ping</li>\n<li>p/b中有一个重启了（重启后发送的view version为0，表示重启）。</li>\n<li>primary为空且存在一个backup server。</li>\n</ol>\n<p>但是view变更存在一个前提条件，就是当前的view版本已经被primary认可，即当前版本被primary重新ping过。</p>\n<h1 id=\"Part-B-The-primary-backup-key-value-service\"><a href=\"#Part-B-The-primary-backup-key-value-service\" class=\"headerlink\" title=\"Part B: The primary/backup key/value service\"></a>Part B: The primary/backup key/value service</h1><p>这部分需要在viewservice基础上完成一个kv store service，主要的思想是</p>\n<ol>\n<li>只有primary server提供服务。</li>\n<li>在Put/Append操作时，需要同步到backup</li>\n<li>因为Append本身不满足at-most-once语义，需要在server端加以控制，具体就是纪录下已经操作成功的append操作（由于课程说明，只纪录最近一次即可。）</li>\n<li>要处理各种异常情况，如果backup变化，需要从primary完全同步到backup(尝试多次)。如果primary/backup有一个出现错误，client应该知道这种错误并重新发起请求，这时候需要先更新view，重新获取primary。</li>\n</ol>\n<p>总的来说，还是挺麻烦的，这部分实验花了挺多时间，主要是在p/b之间的数据同步上，虽然最后给出test case都过了，但是肯定还是会有一些情况没有考虑。</p>\n"},{"layout":"post","title":"Kubelet Introduction","category":null,"_content":"\n> kubernetes(k8s)是一个开源的分布式容器集群管理系统，用户对容器进行部署，扩展和管理。\n\nkubelet是k8s中重要的工作模块。每个kubernetes集群的实际工作节点上都需要运行这个一个进程(agent)来进行实际作业（pod/container）的运行，类似于NodeManager在Yarn集群中的地位。在kunernetes架构下，pod是作业运行的最小单元。PodSpec描述一个Pod作业的具体信息，kubelet的主要作用就是通过一定的机制（如从apiserver）拿到这些PodSpec在本地对PodSpec中描述的container信息进行执行，并保证PodSpec中描述的container信息与实际运行的container一致，并对这些pod/container状态信息实时上报到apiserver。\n\n> apiserver 是k8s中的重要组件，apiserver代理了其他组件（kubelet, scheduler, controller等）对资源的读写操作，目前以rest接口的形式提供。apiserver提供了对单个资源(pod/deployment等)的增删改查，对一类资源的list/watch等功能。\n\nkubelet的核心代码在pkg/kubelet下，由于其涉及到的模块很多，所以下面又有多个子包分别负责不同的事物处理。另外还有例如volume管理的代码在外部支持。主要的工作组件如图所示：\n\n![kubelet](/images/kubelet.png)\n\n> 在kubelet启动之后，会有一个主循环从各个渠道（具体下面阐述）获取Pod的状态更新。将这个Pod的更新通知到PodWorkers，由PodWorkers去完成对Pod的管理。\n\n# 组件介绍\n\nkubelet包的主要包括以下几个重要组件：\n\n## PLEG\n\nPLEG(Program Logic Event Generator), 即由程序逻辑事件生成器。在kubelet中，由PLEG组件对本机上运行的pod/container状态进行周期性的检查，并根据状态的变化(转移)生成container的相应事件交给kubelet相关组件处理（如图）。\n\n![pleg1](/images/pleg-container-events.png)\n\n例如，在周期性的检查中可以发现一个在上次还处于ContainerCreate的container现在已经是ContainerRunning了，就会发出一个ContainerStarted事件放到pleg的channel中供下文中提到的PodWorkers处理，根据这个状态变化，podWorkers会重新检查当前pod下的container是否正如PodSpec中定义的一样运行。\n\n在周期性检查中，PLEG组件还会通过containerRuntime提供的接口去获取本地Pod下container的运行状态进行缓存(放在podCache中)，podWorkers的操作会用到cache中的container状态去往apiserver更新pod状态。这个的好处是如果同一个pod同时有多个状态变化请求，可以直接从cache中拿到container状态而不用每次都调用containerRuntime接口。\n\n## StatusManager\n\nStatusManager, 负责管理Pod的状态信息。其主要工作是将本地的Pod状态的更新信息同步到apiserver上。主要体现在SetPodStatus/SetContainerReadiness/TerminatePod三个方法，分别是设置Pod的状态，container的Ready状态以及删除apiserver上的Pod。其中SetContainerReadiness方法被ProbeManager的readinessProbe调用。SetPodStatus在pod被reject或者进行podWorker sync的时候调用，将本地的pod状态更新到apiserver。TerminatePod在kubelet不断获取pod的更新时如果发现Pod已经终止且可以删除(DeletionTimestamp)，则会调用Delete接口删除apiserver的Pod。\n\n## PodManager\n\nPodManager维护了apiserver上的Pod的本地映射。所有调度到本kubelet的pod都可以在这里找到。此外，对于staticPod，会在apiserver上创建对应的mirrotPod，PodManager还维护了这部分的信息映射。\n\n## ProbeManager\n\nProbeManager负责对pod中container定义的ReadinessProbe和LivenessProbe进行处理，即对container进行用户自定义的健康检查。ProbeManager对每个container的ReadinessProbe和LivenessProbe都创建一个worker，在自己的goroutine中执行probe。对于不同的probe，分别会将结果放到readinessManager/livenessManager中。对于readiness类型的probe，probeManager会不断从这个manager中得到结果并调用statusManager的SetContainerReadiness接口更新pod状态到apiserver。对于liveness的probe，在kubelet的周期循环中会得到livenessProbe的结果重新触发Pod的同步，不健康的container会根据重启策略进行重启或者将状态置为failed。\n\n此外，ProbeManager中提供了 UpdatePodStatus 方法，用于在podworkers sync时设置Pod中containerStatus的Ready字段。\n\n## PodWorkers\n\nPodWorkers在之前已经提到过，负责对Pod的更新作出处理。PodWorker实际相当于一个Pod处理的中转站，所有Pod的本地同步处理都经过它发起，由它控制*相同Pod在一个goroutine中串行处理*。处理时会拿到Pod最新的运行时状态进行处理。主要调用kubelet的syncPod函数，由该函数完成实际的pod管理。这部分具体另起文章详细介绍。\n\n## ContainerRuntime\n\nContainerRuntime是管理运行时态Pod(container)的重要组件，即操作底层的runtime来执行用户定义的podSpec。例如docker_tool包下面的runtime属于docker。ContainerRuntime本身是一个接口定义，定义了实现这个接口的具体底层需要完成的功能，根据底层来具体选择这个Runtime（docker/rkt）。目前kubelet还在实现CRI形式进行管理。Runtime接口实现了对runtime的管理，常用的接口包括GetPods, KillPod, GetPodStatus(获取pod的container的状态), DeleteContainer. 最主要的一个接口是SyncPod，在podWorker调用syncPod时调用。SyncPod负责创建container，设置网络，设置cgroup参数，维护实际运行状态与PodSpec一致性等。这部分具体实现(docker)另起文章详细介绍。\n\n## EvictManager\n\n这个组件主要用于维护kubelet节点的稳定性，主要利用cAdvisor监控机器运行状态，Mem/Disk等。如果调度到本地的Pod运行可能影响节点的稳定性，就会将这个Pod进行Evict操作，killPod并将其状态置为Failed。\n\n## cAdvisor\n\nTODO\n\n## VolumeManager\n\nTODO\n\n## Network plugin\n\nTODO\n\n# 工作流程\n\nkubelet启动后需要向apiserver主动注册节点。scheduler发现节点后可以将pod调度到该节点上。\nkubelet会watch apiserver中那些pod.NodeName = this.NodeName的pod，放到PodUpdates的chan中给kubelet进行处理。其实除了从apiserver获取pod资源，还可以从本地文件或者自定义的http endpoint中得到pod，这些渠道获取的Pod被称为static pod，会在apiserver创建对应的pod称为mirror pod。\n\nkubelet的工作从syncLoop发起，syncLoop主要获取构造几个channel，一个是从apiserver监听的pod变化的事件（包括创建，更新，删除），一个是syncTicker，负责每秒发送一个tick出发一些更新（下面会讲到），一个是housekeepingTicker，每15s触发一次，进行housekeeping的操作，最后一个是由pleg生成的channel，这里会生成一些container变更的事件给主程序进行处理。\n构造完后将这几个channel交给syncLoopIteration处理，每次select出一个channel进行事件处理。\n\n1. 如果有从apiserver来的pod，则调用HandlePodXXX来进行事件处理，\n2. 如果从pleg有container的事件且不是container移除的事件，则调用HandlePodSyncs来重新同步pod的container的状态信息。另外如果container的事件是ContainerDied的话，还会触发会pod中container的cleanup操作，使得一个pod的退出的container数不超过一定值。\n3. 如果有来自livenessManager的关于container的livenessProbe的失败结果，也调用HandlePodSyncs接口。\n4. 如果收到来自housekeeping的事件（每15秒一次），则调用HandlePodCleanups进行一些已经移除的pod的清理工作\n5. 如果收到来自syncCh的事件（每秒一次），则拿到需要重新同步的pod，需要同步的pod主要从workQueue的chan中获取，由podWorkers在同步了pod之后放入workQueue中一定事件后从workQueue的chan中拿出。调用HandlePodSyncs。\n\nHandlePodXXX方法基本都是调用dispatchWork，在这个函数中调用podWorkers的UpdatePod函数对pod进行实际的处理（调用kubelet.syncPod方法）。另外HandlePodAdditions和HandlePodRemoves还会在probeManager注册/注销containerProbe。\n\n\npodWorkers给每个pod创建一个goroutine执行kubelet的syncPod函数，首先根据现在的podStatus生成apiPodStatus，然后调用statusManager的SetPodStatus方法将status更新到apiserver。创建相关的pod目录，将volume挂载到本地，从apiserver获取pull secret，然后到最重要的一步，调用containerRuntime的SyncPod方法，这里调用的docker_tool下面的dockerManager的SyncPod方法。把sync的结果保存到reasonCache中。\n\npodWorkers处理之后会将pod放入到workQueue中供后续syncCh拿出重新同步状态，使得Pod的containers始终遵循pod的spec内容。\n\n---\n\n一个Pod的执行流程大体如上所诉。总结来说，从pod被调度器调度到kubelet节点开始，kubelet watch到该pod，将pod放到kubelet的循环中处理。首先将其放入probeManager对readiness/liveness进行定期probe。然后放入podWorker中，在podWorker中调用kubelet.syncPod，将最新的pod status同步到apiserver，设置本地目录，mount相关的volume，获取image的pull secret，然后调用containerRuntime的SyncPod（在SyncPod中拉去image，启动container）。然后将pod放入到workQueue中。等到pod在workQueue中到达一个时间点，或者Pod/Container有变化，重新通过kubelet主循环放到podWorker中重新处理，重新生成podStatus，重新调用SyncPod等。\n\n\n\n## 其他\n\n除了以上这些跟Pod处理直接相关的模块外，kubelet还有一些其他的模块。例如evict模块负责对调度到本地的Pod进行审查，决定是否需要拒绝这个Pod。containerGC和imageGC负责定期清理本地退出的container和image。cadvisor模块监控本地资源的运行使用情况。OOM负责为container的OOMAdjust打分，控制资源的使用。网络模块负责设置Pod的网络模式。此外，kubelet本身也起了一个http server，通过接口可以获取到本地Pod/Container的一些信息。\n\n# Issue\n\n目前，kubelet有一些重要的特性在进行需要关注，例如多卡GPU的支持，Pod level cgroup的支持，kubelet CRI等。\n\n","source":"_posts/2017-01-21-kubelet.markdown","raw":"---\nlayout: post\ntitle: Kubelet Introduction\ncategory:\ntag: [kubernetes, kubelet]\n---\n\n> kubernetes(k8s)是一个开源的分布式容器集群管理系统，用户对容器进行部署，扩展和管理。\n\nkubelet是k8s中重要的工作模块。每个kubernetes集群的实际工作节点上都需要运行这个一个进程(agent)来进行实际作业（pod/container）的运行，类似于NodeManager在Yarn集群中的地位。在kunernetes架构下，pod是作业运行的最小单元。PodSpec描述一个Pod作业的具体信息，kubelet的主要作用就是通过一定的机制（如从apiserver）拿到这些PodSpec在本地对PodSpec中描述的container信息进行执行，并保证PodSpec中描述的container信息与实际运行的container一致，并对这些pod/container状态信息实时上报到apiserver。\n\n> apiserver 是k8s中的重要组件，apiserver代理了其他组件（kubelet, scheduler, controller等）对资源的读写操作，目前以rest接口的形式提供。apiserver提供了对单个资源(pod/deployment等)的增删改查，对一类资源的list/watch等功能。\n\nkubelet的核心代码在pkg/kubelet下，由于其涉及到的模块很多，所以下面又有多个子包分别负责不同的事物处理。另外还有例如volume管理的代码在外部支持。主要的工作组件如图所示：\n\n![kubelet](/images/kubelet.png)\n\n> 在kubelet启动之后，会有一个主循环从各个渠道（具体下面阐述）获取Pod的状态更新。将这个Pod的更新通知到PodWorkers，由PodWorkers去完成对Pod的管理。\n\n# 组件介绍\n\nkubelet包的主要包括以下几个重要组件：\n\n## PLEG\n\nPLEG(Program Logic Event Generator), 即由程序逻辑事件生成器。在kubelet中，由PLEG组件对本机上运行的pod/container状态进行周期性的检查，并根据状态的变化(转移)生成container的相应事件交给kubelet相关组件处理（如图）。\n\n![pleg1](/images/pleg-container-events.png)\n\n例如，在周期性的检查中可以发现一个在上次还处于ContainerCreate的container现在已经是ContainerRunning了，就会发出一个ContainerStarted事件放到pleg的channel中供下文中提到的PodWorkers处理，根据这个状态变化，podWorkers会重新检查当前pod下的container是否正如PodSpec中定义的一样运行。\n\n在周期性检查中，PLEG组件还会通过containerRuntime提供的接口去获取本地Pod下container的运行状态进行缓存(放在podCache中)，podWorkers的操作会用到cache中的container状态去往apiserver更新pod状态。这个的好处是如果同一个pod同时有多个状态变化请求，可以直接从cache中拿到container状态而不用每次都调用containerRuntime接口。\n\n## StatusManager\n\nStatusManager, 负责管理Pod的状态信息。其主要工作是将本地的Pod状态的更新信息同步到apiserver上。主要体现在SetPodStatus/SetContainerReadiness/TerminatePod三个方法，分别是设置Pod的状态，container的Ready状态以及删除apiserver上的Pod。其中SetContainerReadiness方法被ProbeManager的readinessProbe调用。SetPodStatus在pod被reject或者进行podWorker sync的时候调用，将本地的pod状态更新到apiserver。TerminatePod在kubelet不断获取pod的更新时如果发现Pod已经终止且可以删除(DeletionTimestamp)，则会调用Delete接口删除apiserver的Pod。\n\n## PodManager\n\nPodManager维护了apiserver上的Pod的本地映射。所有调度到本kubelet的pod都可以在这里找到。此外，对于staticPod，会在apiserver上创建对应的mirrotPod，PodManager还维护了这部分的信息映射。\n\n## ProbeManager\n\nProbeManager负责对pod中container定义的ReadinessProbe和LivenessProbe进行处理，即对container进行用户自定义的健康检查。ProbeManager对每个container的ReadinessProbe和LivenessProbe都创建一个worker，在自己的goroutine中执行probe。对于不同的probe，分别会将结果放到readinessManager/livenessManager中。对于readiness类型的probe，probeManager会不断从这个manager中得到结果并调用statusManager的SetContainerReadiness接口更新pod状态到apiserver。对于liveness的probe，在kubelet的周期循环中会得到livenessProbe的结果重新触发Pod的同步，不健康的container会根据重启策略进行重启或者将状态置为failed。\n\n此外，ProbeManager中提供了 UpdatePodStatus 方法，用于在podworkers sync时设置Pod中containerStatus的Ready字段。\n\n## PodWorkers\n\nPodWorkers在之前已经提到过，负责对Pod的更新作出处理。PodWorker实际相当于一个Pod处理的中转站，所有Pod的本地同步处理都经过它发起，由它控制*相同Pod在一个goroutine中串行处理*。处理时会拿到Pod最新的运行时状态进行处理。主要调用kubelet的syncPod函数，由该函数完成实际的pod管理。这部分具体另起文章详细介绍。\n\n## ContainerRuntime\n\nContainerRuntime是管理运行时态Pod(container)的重要组件，即操作底层的runtime来执行用户定义的podSpec。例如docker_tool包下面的runtime属于docker。ContainerRuntime本身是一个接口定义，定义了实现这个接口的具体底层需要完成的功能，根据底层来具体选择这个Runtime（docker/rkt）。目前kubelet还在实现CRI形式进行管理。Runtime接口实现了对runtime的管理，常用的接口包括GetPods, KillPod, GetPodStatus(获取pod的container的状态), DeleteContainer. 最主要的一个接口是SyncPod，在podWorker调用syncPod时调用。SyncPod负责创建container，设置网络，设置cgroup参数，维护实际运行状态与PodSpec一致性等。这部分具体实现(docker)另起文章详细介绍。\n\n## EvictManager\n\n这个组件主要用于维护kubelet节点的稳定性，主要利用cAdvisor监控机器运行状态，Mem/Disk等。如果调度到本地的Pod运行可能影响节点的稳定性，就会将这个Pod进行Evict操作，killPod并将其状态置为Failed。\n\n## cAdvisor\n\nTODO\n\n## VolumeManager\n\nTODO\n\n## Network plugin\n\nTODO\n\n# 工作流程\n\nkubelet启动后需要向apiserver主动注册节点。scheduler发现节点后可以将pod调度到该节点上。\nkubelet会watch apiserver中那些pod.NodeName = this.NodeName的pod，放到PodUpdates的chan中给kubelet进行处理。其实除了从apiserver获取pod资源，还可以从本地文件或者自定义的http endpoint中得到pod，这些渠道获取的Pod被称为static pod，会在apiserver创建对应的pod称为mirror pod。\n\nkubelet的工作从syncLoop发起，syncLoop主要获取构造几个channel，一个是从apiserver监听的pod变化的事件（包括创建，更新，删除），一个是syncTicker，负责每秒发送一个tick出发一些更新（下面会讲到），一个是housekeepingTicker，每15s触发一次，进行housekeeping的操作，最后一个是由pleg生成的channel，这里会生成一些container变更的事件给主程序进行处理。\n构造完后将这几个channel交给syncLoopIteration处理，每次select出一个channel进行事件处理。\n\n1. 如果有从apiserver来的pod，则调用HandlePodXXX来进行事件处理，\n2. 如果从pleg有container的事件且不是container移除的事件，则调用HandlePodSyncs来重新同步pod的container的状态信息。另外如果container的事件是ContainerDied的话，还会触发会pod中container的cleanup操作，使得一个pod的退出的container数不超过一定值。\n3. 如果有来自livenessManager的关于container的livenessProbe的失败结果，也调用HandlePodSyncs接口。\n4. 如果收到来自housekeeping的事件（每15秒一次），则调用HandlePodCleanups进行一些已经移除的pod的清理工作\n5. 如果收到来自syncCh的事件（每秒一次），则拿到需要重新同步的pod，需要同步的pod主要从workQueue的chan中获取，由podWorkers在同步了pod之后放入workQueue中一定事件后从workQueue的chan中拿出。调用HandlePodSyncs。\n\nHandlePodXXX方法基本都是调用dispatchWork，在这个函数中调用podWorkers的UpdatePod函数对pod进行实际的处理（调用kubelet.syncPod方法）。另外HandlePodAdditions和HandlePodRemoves还会在probeManager注册/注销containerProbe。\n\n\npodWorkers给每个pod创建一个goroutine执行kubelet的syncPod函数，首先根据现在的podStatus生成apiPodStatus，然后调用statusManager的SetPodStatus方法将status更新到apiserver。创建相关的pod目录，将volume挂载到本地，从apiserver获取pull secret，然后到最重要的一步，调用containerRuntime的SyncPod方法，这里调用的docker_tool下面的dockerManager的SyncPod方法。把sync的结果保存到reasonCache中。\n\npodWorkers处理之后会将pod放入到workQueue中供后续syncCh拿出重新同步状态，使得Pod的containers始终遵循pod的spec内容。\n\n---\n\n一个Pod的执行流程大体如上所诉。总结来说，从pod被调度器调度到kubelet节点开始，kubelet watch到该pod，将pod放到kubelet的循环中处理。首先将其放入probeManager对readiness/liveness进行定期probe。然后放入podWorker中，在podWorker中调用kubelet.syncPod，将最新的pod status同步到apiserver，设置本地目录，mount相关的volume，获取image的pull secret，然后调用containerRuntime的SyncPod（在SyncPod中拉去image，启动container）。然后将pod放入到workQueue中。等到pod在workQueue中到达一个时间点，或者Pod/Container有变化，重新通过kubelet主循环放到podWorker中重新处理，重新生成podStatus，重新调用SyncPod等。\n\n\n\n## 其他\n\n除了以上这些跟Pod处理直接相关的模块外，kubelet还有一些其他的模块。例如evict模块负责对调度到本地的Pod进行审查，决定是否需要拒绝这个Pod。containerGC和imageGC负责定期清理本地退出的container和image。cadvisor模块监控本地资源的运行使用情况。OOM负责为container的OOMAdjust打分，控制资源的使用。网络模块负责设置Pod的网络模式。此外，kubelet本身也起了一个http server，通过接口可以获取到本地Pod/Container的一些信息。\n\n# Issue\n\n目前，kubelet有一些重要的特性在进行需要关注，例如多卡GPU的支持，Pod level cgroup的支持，kubelet CRI等。\n\n","slug":"kubelet","published":1,"date":"2017-01-20T16:00:00.000Z","updated":"2017-03-05T15:28:33.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapz3000gphv9qaydz238","content":"<blockquote>\n<p>kubernetes(k8s)是一个开源的分布式容器集群管理系统，用户对容器进行部署，扩展和管理。</p>\n</blockquote>\n<p>kubelet是k8s中重要的工作模块。每个kubernetes集群的实际工作节点上都需要运行这个一个进程(agent)来进行实际作业（pod/container）的运行，类似于NodeManager在Yarn集群中的地位。在kunernetes架构下，pod是作业运行的最小单元。PodSpec描述一个Pod作业的具体信息，kubelet的主要作用就是通过一定的机制（如从apiserver）拿到这些PodSpec在本地对PodSpec中描述的container信息进行执行，并保证PodSpec中描述的container信息与实际运行的container一致，并对这些pod/container状态信息实时上报到apiserver。</p>\n<blockquote>\n<p>apiserver 是k8s中的重要组件，apiserver代理了其他组件（kubelet, scheduler, controller等）对资源的读写操作，目前以rest接口的形式提供。apiserver提供了对单个资源(pod/deployment等)的增删改查，对一类资源的list/watch等功能。</p>\n</blockquote>\n<p>kubelet的核心代码在pkg/kubelet下，由于其涉及到的模块很多，所以下面又有多个子包分别负责不同的事物处理。另外还有例如volume管理的代码在外部支持。主要的工作组件如图所示：</p>\n<p><img src=\"/images/kubelet.png\" alt=\"kubelet\"></p>\n<blockquote>\n<p>在kubelet启动之后，会有一个主循环从各个渠道（具体下面阐述）获取Pod的状态更新。将这个Pod的更新通知到PodWorkers，由PodWorkers去完成对Pod的管理。</p>\n</blockquote>\n<h1 id=\"组件介绍\"><a href=\"#组件介绍\" class=\"headerlink\" title=\"组件介绍\"></a>组件介绍</h1><p>kubelet包的主要包括以下几个重要组件：</p>\n<h2 id=\"PLEG\"><a href=\"#PLEG\" class=\"headerlink\" title=\"PLEG\"></a>PLEG</h2><p>PLEG(Program Logic Event Generator), 即由程序逻辑事件生成器。在kubelet中，由PLEG组件对本机上运行的pod/container状态进行周期性的检查，并根据状态的变化(转移)生成container的相应事件交给kubelet相关组件处理（如图）。</p>\n<p><img src=\"/images/pleg-container-events.png\" alt=\"pleg1\"></p>\n<p>例如，在周期性的检查中可以发现一个在上次还处于ContainerCreate的container现在已经是ContainerRunning了，就会发出一个ContainerStarted事件放到pleg的channel中供下文中提到的PodWorkers处理，根据这个状态变化，podWorkers会重新检查当前pod下的container是否正如PodSpec中定义的一样运行。</p>\n<p>在周期性检查中，PLEG组件还会通过containerRuntime提供的接口去获取本地Pod下container的运行状态进行缓存(放在podCache中)，podWorkers的操作会用到cache中的container状态去往apiserver更新pod状态。这个的好处是如果同一个pod同时有多个状态变化请求，可以直接从cache中拿到container状态而不用每次都调用containerRuntime接口。</p>\n<h2 id=\"StatusManager\"><a href=\"#StatusManager\" class=\"headerlink\" title=\"StatusManager\"></a>StatusManager</h2><p>StatusManager, 负责管理Pod的状态信息。其主要工作是将本地的Pod状态的更新信息同步到apiserver上。主要体现在SetPodStatus/SetContainerReadiness/TerminatePod三个方法，分别是设置Pod的状态，container的Ready状态以及删除apiserver上的Pod。其中SetContainerReadiness方法被ProbeManager的readinessProbe调用。SetPodStatus在pod被reject或者进行podWorker sync的时候调用，将本地的pod状态更新到apiserver。TerminatePod在kubelet不断获取pod的更新时如果发现Pod已经终止且可以删除(DeletionTimestamp)，则会调用Delete接口删除apiserver的Pod。</p>\n<h2 id=\"PodManager\"><a href=\"#PodManager\" class=\"headerlink\" title=\"PodManager\"></a>PodManager</h2><p>PodManager维护了apiserver上的Pod的本地映射。所有调度到本kubelet的pod都可以在这里找到。此外，对于staticPod，会在apiserver上创建对应的mirrotPod，PodManager还维护了这部分的信息映射。</p>\n<h2 id=\"ProbeManager\"><a href=\"#ProbeManager\" class=\"headerlink\" title=\"ProbeManager\"></a>ProbeManager</h2><p>ProbeManager负责对pod中container定义的ReadinessProbe和LivenessProbe进行处理，即对container进行用户自定义的健康检查。ProbeManager对每个container的ReadinessProbe和LivenessProbe都创建一个worker，在自己的goroutine中执行probe。对于不同的probe，分别会将结果放到readinessManager/livenessManager中。对于readiness类型的probe，probeManager会不断从这个manager中得到结果并调用statusManager的SetContainerReadiness接口更新pod状态到apiserver。对于liveness的probe，在kubelet的周期循环中会得到livenessProbe的结果重新触发Pod的同步，不健康的container会根据重启策略进行重启或者将状态置为failed。</p>\n<p>此外，ProbeManager中提供了 UpdatePodStatus 方法，用于在podworkers sync时设置Pod中containerStatus的Ready字段。</p>\n<h2 id=\"PodWorkers\"><a href=\"#PodWorkers\" class=\"headerlink\" title=\"PodWorkers\"></a>PodWorkers</h2><p>PodWorkers在之前已经提到过，负责对Pod的更新作出处理。PodWorker实际相当于一个Pod处理的中转站，所有Pod的本地同步处理都经过它发起，由它控制<em>相同Pod在一个goroutine中串行处理</em>。处理时会拿到Pod最新的运行时状态进行处理。主要调用kubelet的syncPod函数，由该函数完成实际的pod管理。这部分具体另起文章详细介绍。</p>\n<h2 id=\"ContainerRuntime\"><a href=\"#ContainerRuntime\" class=\"headerlink\" title=\"ContainerRuntime\"></a>ContainerRuntime</h2><p>ContainerRuntime是管理运行时态Pod(container)的重要组件，即操作底层的runtime来执行用户定义的podSpec。例如docker_tool包下面的runtime属于docker。ContainerRuntime本身是一个接口定义，定义了实现这个接口的具体底层需要完成的功能，根据底层来具体选择这个Runtime（docker/rkt）。目前kubelet还在实现CRI形式进行管理。Runtime接口实现了对runtime的管理，常用的接口包括GetPods, KillPod, GetPodStatus(获取pod的container的状态), DeleteContainer. 最主要的一个接口是SyncPod，在podWorker调用syncPod时调用。SyncPod负责创建container，设置网络，设置cgroup参数，维护实际运行状态与PodSpec一致性等。这部分具体实现(docker)另起文章详细介绍。</p>\n<h2 id=\"EvictManager\"><a href=\"#EvictManager\" class=\"headerlink\" title=\"EvictManager\"></a>EvictManager</h2><p>这个组件主要用于维护kubelet节点的稳定性，主要利用cAdvisor监控机器运行状态，Mem/Disk等。如果调度到本地的Pod运行可能影响节点的稳定性，就会将这个Pod进行Evict操作，killPod并将其状态置为Failed。</p>\n<h2 id=\"cAdvisor\"><a href=\"#cAdvisor\" class=\"headerlink\" title=\"cAdvisor\"></a>cAdvisor</h2><p>TODO</p>\n<h2 id=\"VolumeManager\"><a href=\"#VolumeManager\" class=\"headerlink\" title=\"VolumeManager\"></a>VolumeManager</h2><p>TODO</p>\n<h2 id=\"Network-plugin\"><a href=\"#Network-plugin\" class=\"headerlink\" title=\"Network plugin\"></a>Network plugin</h2><p>TODO</p>\n<h1 id=\"工作流程\"><a href=\"#工作流程\" class=\"headerlink\" title=\"工作流程\"></a>工作流程</h1><p>kubelet启动后需要向apiserver主动注册节点。scheduler发现节点后可以将pod调度到该节点上。<br>kubelet会watch apiserver中那些pod.NodeName = this.NodeName的pod，放到PodUpdates的chan中给kubelet进行处理。其实除了从apiserver获取pod资源，还可以从本地文件或者自定义的http endpoint中得到pod，这些渠道获取的Pod被称为static pod，会在apiserver创建对应的pod称为mirror pod。</p>\n<p>kubelet的工作从syncLoop发起，syncLoop主要获取构造几个channel，一个是从apiserver监听的pod变化的事件（包括创建，更新，删除），一个是syncTicker，负责每秒发送一个tick出发一些更新（下面会讲到），一个是housekeepingTicker，每15s触发一次，进行housekeeping的操作，最后一个是由pleg生成的channel，这里会生成一些container变更的事件给主程序进行处理。<br>构造完后将这几个channel交给syncLoopIteration处理，每次select出一个channel进行事件处理。</p>\n<ol>\n<li>如果有从apiserver来的pod，则调用HandlePodXXX来进行事件处理，</li>\n<li>如果从pleg有container的事件且不是container移除的事件，则调用HandlePodSyncs来重新同步pod的container的状态信息。另外如果container的事件是ContainerDied的话，还会触发会pod中container的cleanup操作，使得一个pod的退出的container数不超过一定值。</li>\n<li>如果有来自livenessManager的关于container的livenessProbe的失败结果，也调用HandlePodSyncs接口。</li>\n<li>如果收到来自housekeeping的事件（每15秒一次），则调用HandlePodCleanups进行一些已经移除的pod的清理工作</li>\n<li>如果收到来自syncCh的事件（每秒一次），则拿到需要重新同步的pod，需要同步的pod主要从workQueue的chan中获取，由podWorkers在同步了pod之后放入workQueue中一定事件后从workQueue的chan中拿出。调用HandlePodSyncs。</li>\n</ol>\n<p>HandlePodXXX方法基本都是调用dispatchWork，在这个函数中调用podWorkers的UpdatePod函数对pod进行实际的处理（调用kubelet.syncPod方法）。另外HandlePodAdditions和HandlePodRemoves还会在probeManager注册/注销containerProbe。</p>\n<p>podWorkers给每个pod创建一个goroutine执行kubelet的syncPod函数，首先根据现在的podStatus生成apiPodStatus，然后调用statusManager的SetPodStatus方法将status更新到apiserver。创建相关的pod目录，将volume挂载到本地，从apiserver获取pull secret，然后到最重要的一步，调用containerRuntime的SyncPod方法，这里调用的docker_tool下面的dockerManager的SyncPod方法。把sync的结果保存到reasonCache中。</p>\n<p>podWorkers处理之后会将pod放入到workQueue中供后续syncCh拿出重新同步状态，使得Pod的containers始终遵循pod的spec内容。</p>\n<hr>\n<p>一个Pod的执行流程大体如上所诉。总结来说，从pod被调度器调度到kubelet节点开始，kubelet watch到该pod，将pod放到kubelet的循环中处理。首先将其放入probeManager对readiness/liveness进行定期probe。然后放入podWorker中，在podWorker中调用kubelet.syncPod，将最新的pod status同步到apiserver，设置本地目录，mount相关的volume，获取image的pull secret，然后调用containerRuntime的SyncPod（在SyncPod中拉去image，启动container）。然后将pod放入到workQueue中。等到pod在workQueue中到达一个时间点，或者Pod/Container有变化，重新通过kubelet主循环放到podWorker中重新处理，重新生成podStatus，重新调用SyncPod等。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p>除了以上这些跟Pod处理直接相关的模块外，kubelet还有一些其他的模块。例如evict模块负责对调度到本地的Pod进行审查，决定是否需要拒绝这个Pod。containerGC和imageGC负责定期清理本地退出的container和image。cadvisor模块监控本地资源的运行使用情况。OOM负责为container的OOMAdjust打分，控制资源的使用。网络模块负责设置Pod的网络模式。此外，kubelet本身也起了一个http server，通过接口可以获取到本地Pod/Container的一些信息。</p>\n<h1 id=\"Issue\"><a href=\"#Issue\" class=\"headerlink\" title=\"Issue\"></a>Issue</h1><p>目前，kubelet有一些重要的特性在进行需要关注，例如多卡GPU的支持，Pod level cgroup的支持，kubelet CRI等。</p>\n","excerpt":"","more":"<blockquote>\n<p>kubernetes(k8s)是一个开源的分布式容器集群管理系统，用户对容器进行部署，扩展和管理。</p>\n</blockquote>\n<p>kubelet是k8s中重要的工作模块。每个kubernetes集群的实际工作节点上都需要运行这个一个进程(agent)来进行实际作业（pod/container）的运行，类似于NodeManager在Yarn集群中的地位。在kunernetes架构下，pod是作业运行的最小单元。PodSpec描述一个Pod作业的具体信息，kubelet的主要作用就是通过一定的机制（如从apiserver）拿到这些PodSpec在本地对PodSpec中描述的container信息进行执行，并保证PodSpec中描述的container信息与实际运行的container一致，并对这些pod/container状态信息实时上报到apiserver。</p>\n<blockquote>\n<p>apiserver 是k8s中的重要组件，apiserver代理了其他组件（kubelet, scheduler, controller等）对资源的读写操作，目前以rest接口的形式提供。apiserver提供了对单个资源(pod/deployment等)的增删改查，对一类资源的list/watch等功能。</p>\n</blockquote>\n<p>kubelet的核心代码在pkg/kubelet下，由于其涉及到的模块很多，所以下面又有多个子包分别负责不同的事物处理。另外还有例如volume管理的代码在外部支持。主要的工作组件如图所示：</p>\n<p><img src=\"/images/kubelet.png\" alt=\"kubelet\"></p>\n<blockquote>\n<p>在kubelet启动之后，会有一个主循环从各个渠道（具体下面阐述）获取Pod的状态更新。将这个Pod的更新通知到PodWorkers，由PodWorkers去完成对Pod的管理。</p>\n</blockquote>\n<h1 id=\"组件介绍\"><a href=\"#组件介绍\" class=\"headerlink\" title=\"组件介绍\"></a>组件介绍</h1><p>kubelet包的主要包括以下几个重要组件：</p>\n<h2 id=\"PLEG\"><a href=\"#PLEG\" class=\"headerlink\" title=\"PLEG\"></a>PLEG</h2><p>PLEG(Program Logic Event Generator), 即由程序逻辑事件生成器。在kubelet中，由PLEG组件对本机上运行的pod/container状态进行周期性的检查，并根据状态的变化(转移)生成container的相应事件交给kubelet相关组件处理（如图）。</p>\n<p><img src=\"/images/pleg-container-events.png\" alt=\"pleg1\"></p>\n<p>例如，在周期性的检查中可以发现一个在上次还处于ContainerCreate的container现在已经是ContainerRunning了，就会发出一个ContainerStarted事件放到pleg的channel中供下文中提到的PodWorkers处理，根据这个状态变化，podWorkers会重新检查当前pod下的container是否正如PodSpec中定义的一样运行。</p>\n<p>在周期性检查中，PLEG组件还会通过containerRuntime提供的接口去获取本地Pod下container的运行状态进行缓存(放在podCache中)，podWorkers的操作会用到cache中的container状态去往apiserver更新pod状态。这个的好处是如果同一个pod同时有多个状态变化请求，可以直接从cache中拿到container状态而不用每次都调用containerRuntime接口。</p>\n<h2 id=\"StatusManager\"><a href=\"#StatusManager\" class=\"headerlink\" title=\"StatusManager\"></a>StatusManager</h2><p>StatusManager, 负责管理Pod的状态信息。其主要工作是将本地的Pod状态的更新信息同步到apiserver上。主要体现在SetPodStatus/SetContainerReadiness/TerminatePod三个方法，分别是设置Pod的状态，container的Ready状态以及删除apiserver上的Pod。其中SetContainerReadiness方法被ProbeManager的readinessProbe调用。SetPodStatus在pod被reject或者进行podWorker sync的时候调用，将本地的pod状态更新到apiserver。TerminatePod在kubelet不断获取pod的更新时如果发现Pod已经终止且可以删除(DeletionTimestamp)，则会调用Delete接口删除apiserver的Pod。</p>\n<h2 id=\"PodManager\"><a href=\"#PodManager\" class=\"headerlink\" title=\"PodManager\"></a>PodManager</h2><p>PodManager维护了apiserver上的Pod的本地映射。所有调度到本kubelet的pod都可以在这里找到。此外，对于staticPod，会在apiserver上创建对应的mirrotPod，PodManager还维护了这部分的信息映射。</p>\n<h2 id=\"ProbeManager\"><a href=\"#ProbeManager\" class=\"headerlink\" title=\"ProbeManager\"></a>ProbeManager</h2><p>ProbeManager负责对pod中container定义的ReadinessProbe和LivenessProbe进行处理，即对container进行用户自定义的健康检查。ProbeManager对每个container的ReadinessProbe和LivenessProbe都创建一个worker，在自己的goroutine中执行probe。对于不同的probe，分别会将结果放到readinessManager/livenessManager中。对于readiness类型的probe，probeManager会不断从这个manager中得到结果并调用statusManager的SetContainerReadiness接口更新pod状态到apiserver。对于liveness的probe，在kubelet的周期循环中会得到livenessProbe的结果重新触发Pod的同步，不健康的container会根据重启策略进行重启或者将状态置为failed。</p>\n<p>此外，ProbeManager中提供了 UpdatePodStatus 方法，用于在podworkers sync时设置Pod中containerStatus的Ready字段。</p>\n<h2 id=\"PodWorkers\"><a href=\"#PodWorkers\" class=\"headerlink\" title=\"PodWorkers\"></a>PodWorkers</h2><p>PodWorkers在之前已经提到过，负责对Pod的更新作出处理。PodWorker实际相当于一个Pod处理的中转站，所有Pod的本地同步处理都经过它发起，由它控制<em>相同Pod在一个goroutine中串行处理</em>。处理时会拿到Pod最新的运行时状态进行处理。主要调用kubelet的syncPod函数，由该函数完成实际的pod管理。这部分具体另起文章详细介绍。</p>\n<h2 id=\"ContainerRuntime\"><a href=\"#ContainerRuntime\" class=\"headerlink\" title=\"ContainerRuntime\"></a>ContainerRuntime</h2><p>ContainerRuntime是管理运行时态Pod(container)的重要组件，即操作底层的runtime来执行用户定义的podSpec。例如docker_tool包下面的runtime属于docker。ContainerRuntime本身是一个接口定义，定义了实现这个接口的具体底层需要完成的功能，根据底层来具体选择这个Runtime（docker/rkt）。目前kubelet还在实现CRI形式进行管理。Runtime接口实现了对runtime的管理，常用的接口包括GetPods, KillPod, GetPodStatus(获取pod的container的状态), DeleteContainer. 最主要的一个接口是SyncPod，在podWorker调用syncPod时调用。SyncPod负责创建container，设置网络，设置cgroup参数，维护实际运行状态与PodSpec一致性等。这部分具体实现(docker)另起文章详细介绍。</p>\n<h2 id=\"EvictManager\"><a href=\"#EvictManager\" class=\"headerlink\" title=\"EvictManager\"></a>EvictManager</h2><p>这个组件主要用于维护kubelet节点的稳定性，主要利用cAdvisor监控机器运行状态，Mem/Disk等。如果调度到本地的Pod运行可能影响节点的稳定性，就会将这个Pod进行Evict操作，killPod并将其状态置为Failed。</p>\n<h2 id=\"cAdvisor\"><a href=\"#cAdvisor\" class=\"headerlink\" title=\"cAdvisor\"></a>cAdvisor</h2><p>TODO</p>\n<h2 id=\"VolumeManager\"><a href=\"#VolumeManager\" class=\"headerlink\" title=\"VolumeManager\"></a>VolumeManager</h2><p>TODO</p>\n<h2 id=\"Network-plugin\"><a href=\"#Network-plugin\" class=\"headerlink\" title=\"Network plugin\"></a>Network plugin</h2><p>TODO</p>\n<h1 id=\"工作流程\"><a href=\"#工作流程\" class=\"headerlink\" title=\"工作流程\"></a>工作流程</h1><p>kubelet启动后需要向apiserver主动注册节点。scheduler发现节点后可以将pod调度到该节点上。<br>kubelet会watch apiserver中那些pod.NodeName = this.NodeName的pod，放到PodUpdates的chan中给kubelet进行处理。其实除了从apiserver获取pod资源，还可以从本地文件或者自定义的http endpoint中得到pod，这些渠道获取的Pod被称为static pod，会在apiserver创建对应的pod称为mirror pod。</p>\n<p>kubelet的工作从syncLoop发起，syncLoop主要获取构造几个channel，一个是从apiserver监听的pod变化的事件（包括创建，更新，删除），一个是syncTicker，负责每秒发送一个tick出发一些更新（下面会讲到），一个是housekeepingTicker，每15s触发一次，进行housekeeping的操作，最后一个是由pleg生成的channel，这里会生成一些container变更的事件给主程序进行处理。<br>构造完后将这几个channel交给syncLoopIteration处理，每次select出一个channel进行事件处理。</p>\n<ol>\n<li>如果有从apiserver来的pod，则调用HandlePodXXX来进行事件处理，</li>\n<li>如果从pleg有container的事件且不是container移除的事件，则调用HandlePodSyncs来重新同步pod的container的状态信息。另外如果container的事件是ContainerDied的话，还会触发会pod中container的cleanup操作，使得一个pod的退出的container数不超过一定值。</li>\n<li>如果有来自livenessManager的关于container的livenessProbe的失败结果，也调用HandlePodSyncs接口。</li>\n<li>如果收到来自housekeeping的事件（每15秒一次），则调用HandlePodCleanups进行一些已经移除的pod的清理工作</li>\n<li>如果收到来自syncCh的事件（每秒一次），则拿到需要重新同步的pod，需要同步的pod主要从workQueue的chan中获取，由podWorkers在同步了pod之后放入workQueue中一定事件后从workQueue的chan中拿出。调用HandlePodSyncs。</li>\n</ol>\n<p>HandlePodXXX方法基本都是调用dispatchWork，在这个函数中调用podWorkers的UpdatePod函数对pod进行实际的处理（调用kubelet.syncPod方法）。另外HandlePodAdditions和HandlePodRemoves还会在probeManager注册/注销containerProbe。</p>\n<p>podWorkers给每个pod创建一个goroutine执行kubelet的syncPod函数，首先根据现在的podStatus生成apiPodStatus，然后调用statusManager的SetPodStatus方法将status更新到apiserver。创建相关的pod目录，将volume挂载到本地，从apiserver获取pull secret，然后到最重要的一步，调用containerRuntime的SyncPod方法，这里调用的docker_tool下面的dockerManager的SyncPod方法。把sync的结果保存到reasonCache中。</p>\n<p>podWorkers处理之后会将pod放入到workQueue中供后续syncCh拿出重新同步状态，使得Pod的containers始终遵循pod的spec内容。</p>\n<hr>\n<p>一个Pod的执行流程大体如上所诉。总结来说，从pod被调度器调度到kubelet节点开始，kubelet watch到该pod，将pod放到kubelet的循环中处理。首先将其放入probeManager对readiness/liveness进行定期probe。然后放入podWorker中，在podWorker中调用kubelet.syncPod，将最新的pod status同步到apiserver，设置本地目录，mount相关的volume，获取image的pull secret，然后调用containerRuntime的SyncPod（在SyncPod中拉去image，启动container）。然后将pod放入到workQueue中。等到pod在workQueue中到达一个时间点，或者Pod/Container有变化，重新通过kubelet主循环放到podWorker中重新处理，重新生成podStatus，重新调用SyncPod等。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p>除了以上这些跟Pod处理直接相关的模块外，kubelet还有一些其他的模块。例如evict模块负责对调度到本地的Pod进行审查，决定是否需要拒绝这个Pod。containerGC和imageGC负责定期清理本地退出的container和image。cadvisor模块监控本地资源的运行使用情况。OOM负责为container的OOMAdjust打分，控制资源的使用。网络模块负责设置Pod的网络模式。此外，kubelet本身也起了一个http server，通过接口可以获取到本地Pod/Container的一些信息。</p>\n<h1 id=\"Issue\"><a href=\"#Issue\" class=\"headerlink\" title=\"Issue\"></a>Issue</h1><p>目前，kubelet有一些重要的特性在进行需要关注，例如多卡GPU的支持，Pod level cgroup的支持，kubelet CRI等。</p>\n"},{"layout":"post","title":"Traffic control","_content":"\n# 简介\n\n在linux环境下，可以利用tc命令工具对本地流量进行控制，主要通过限速（shaping），调度（scheduling）和策略（policing）进行流量的控制。\n本文主要简略介绍tc中所使用到的几个概念，并结合命令示例对流量控制进行解释。由于tc主要用于出带宽的控制，所以下文主要描述的都是对出带宽的控制，文末附加一个利用tc进行入带宽控制的示例。\n\ntc主要利用3种对象来达成对流量的控制，分别是qdisc（排队规则）, class（类别）, filter（分类器）。\n\n## qdisc\n\nqdisc可以看做是一个有规则的队列，内核如果需要网卡向外发送数据，首先需要放入队列中，然后内核从队列中取出。例如最简单的fifo队列，数据包通过这个队列会按照先进先出的顺序从队列中流出发送到网卡上。\n\nqdisc按照类别划分可以分为有类别队列和无类别队列，其中有类别队列本身附着有类属性，并会根据分类器划分到类中，类可以继续划分为新的子类，如果不在继续分类，则需要为类指定一个队列。按照层次关系形成一棵类似于树状的结构，且树的叶子类节点需要附着一个无类型的队列。\n\n常见的无类别队列有sfq(随机公平队列)，pfifo_fast，tbf（令牌桶）。\n\n* sfq\n\nsfq实现了高度的公平性，会为每个会话使用一个散列算法散列到有限的几个队列中，系统每次从每个队列中拿出流量进行发送。多个会话可能共享一个队列，sfq算法会定期更新散列算法，重新将会话放到新的队列中来达到随机的效果。\n\n```shell\n# 增加一个qdisc，父类为1:10，其自身ID为10:0，使用sfq，每10秒更换一次hash算法\ntc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10\n```\n\n* pfifo_fast\n\npfifo_fast队列可以看作是有类别队列prio的无类别（固定类别）版本，该队列规则内部已经定义了优先级且无法使用tc进行修改。\npfifo_fast内部有3个band，分别记为0，1，2。如果band0上还有数据包，则一直从这个band上取出直到没有后再去band1，以此类推。数据包是按照header中的服务类型TOS进行分配的。TOS是数据包上的一个4bit字段，具体规则如下（规则源自[lartc](http://www.lartc.org/lartc.html)）：\n\n```\nBinary Decimcal  Meaning\n-----------------------------------------\n1000   8         Minimize delay (md)\n0100   4         Maximize throughput (mt)\n0010   2         Maximize reliability (mr)\n0001   1         Minimize monetary cost (mmc)\n0000   0         Normal Service\n\n由于其实TOS的这4bit是8(0-7)位中的1-4位，所以实际值是其2倍。\n\nTOS     Bits  Means                    Linux Priority    Band\n------------------------------------------------------------\n0x0     0     Normal Service           0 Best Effort     1\n0x2     1     Minimize Monetary Cost   1 Filler          2\n0x4     2     Maximize Reliability     0 Best Effort     1\n0x6     3     mmc+mr                   0 Best Effort     1\n0x8     4     Maximize Throughput      2 Bulk            2\n0xa     5     mmc+mt                   2 Bulk            2\n0xc     6     mr+mt                    2 Bulk            2\n0xe     7     mmc+mr+mt                2 Bulk            2\n0x10    8     Minimize Delay           6 Interactive     0\n0x12    9     mmc+md                   6 Interactive     0\n0x14    10    mr+md                    6 Interactive     0\n0x16    11    mmc+mr+md                6 Interactive     0\n0x18    12    mt+md                    4 Int. Bulk       1\n0x1a    13    mmc+mt+md                4 Int. Bulk       1\n0x1c    14    mr+mt+md                 4 Int. Bulk       1\n0x1e    15    mmc+mr+mt+md             4 Int. Bulk       1\n```\n\n* tbf\n\ntbf队列利用令牌桶原理来控制出带宽，每流出一定的数据量，就需要消耗桶中的令牌，一旦令牌消耗完毕，则不会再继续发送数据。每个一段时间，会重新往桶里面添加令牌直到桶满为止。\n\n```shell\ntc qdisc add dev eth0 root tbf rate 0.5mbit \\\nburst 5kb latency 70ms peakrate 1mbit \\\nminburst 1540\n```\n\n常见的分类队列有prio和htb\n\n* prio\n\nprio队列与前面的pfifo_fast类似，高优先级的数据先发送。在创建prio时，系统默认就会创建3个类，这些类仅包含单纯的fifo队列，用户可以利用tc进行替换。\n\n* htb\n\nhtb（Hierarchical Token Bucket）分层桶令牌与无类队列tbf类似，用于流量整形。\n\n```shell\n# 速率为30kbps，且上限（ceil）为100kps，说明如果网络空闲，这个class可以向外界借用宽带，默认ceil为rate一致\ntc class add dev eth0 parent 1:2 classid 1:10 htb rate 30kbps ceil 100kbps\n```\n\nhtb可以进行优先级划分，高优先级的队列优先得到剩余宽带，同优先级之间按照rate进行按比例划分。\n\n## class\n\nclass存在于有类别队列中，class是可以包含多个子类或者一个子队列。叶子类在队列中属于最终类别，会默认包含一个fifo的qdisc。\n\n## filter\n\nfilter的作用主要是定义如何将一个qdisc(class)划分到子class中。常见的分类器有u32。可以根据ip, 端口，协议类型，mac地址等进行过滤。\n\n# 样例说明\n\n在实际使用tc命令进行流量控制时，会为每个qdisc／class分配一个id，id由 主ID:从ID 两部分组成，其中qdisc的命名以主ID进行区分，例如 10: ,别是其ID为10:0，qdisc的从ID都是0。class的ID为10:1，其中主ID需要于其父节点ID一致。\n\n## 出带宽控制\n\n下面的例子来自[Linux高级流控](http://www.ibm.com/developerworks/cn/linux/1412_xiehy_tc/)\n\n```shell\n# 创建htb，默认走1:30的类别\ntc qdisc add dev eth0 root handle 1: htb default 30\n# 为root qdisc创建1:1的类别，注意主ID为1，与parent一致\ntc class add dev eth0 parent 1: classid 1:1 htb rate 6mbit burst 15k\n# 在class 1:1下定义3个子class，注意子class的主ID与parent一致\ntc class add dev eth0 parent 1:1 classid 1:10 htb rate 5mbit burst 15k\ntc class add dev eth0 parent 1:1 classid 1:20 htb rate 3mbit ceil 6mbit burst 15k\ntc class add dev eth0 parent 1:1 classid 1:30 htb rate 1kbit ceil 6mbit burst 15k\n# 为每个叶子class定义sfq的qdisc，防止流量被某个连接占用。perturb表示几秒更换一次hash算法。\ntc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10\ntc qdisc add dev eth0 parent 1:20 handle 20: sfq perturb 10\ntc qdisc add dev eth0 parent 1:30 handle 30: sfq perturb 10\n# 添加u32过滤器, 直接把流量导向相应的类 :\nU32=\"tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32\"\n$U32 match ip dport 80 0xffff flowid 1:10\n$U32 match ip sport 25 0xffff flowid 1:20\n```\n\n另外，使用以下命令可以查看各个qdisc/class的流量情况：\n\n```shell\ntc -s -d qdisc show dev eth0\ntc -s -d class show dev eth0\n```\n\n## tc + cgroup\n\n可以利用cgroup来进行进程的流量控制。使用cgroup进行流量控制时，需要引入net_cls cgroup子模块，在net_cls.classid文件中定义好该group下进程的分类class id。并在定义filter时使用cgroup filter\n\n```shell\ntc filter add dev eth2 parent 10: protocol ip prio 10 handle 1: cgroup\n```\n\n## 入带宽控制\n\n一般使用tc进行出带宽控制，因为tc的入带宽控制从网卡拿数据时数据已经发送到本机，再进行控制显得没有太多意义。下面仅演示利用tc ingress进入入带宽控制\n\n```shell\ntc qdisc add dev eth0 handle ffff: ingress\n# 限制来子10.0.0.*来的流量\ntc filter add dev eth0 parent ffff: protocol ip prio 50 u32 match ip src 10.0.0.1/24 police rate 100kbit burst 10k drop flowid :1\n```\n\n# 其他\n\n流量测试数据可以使用 http://cachefly.cachefly.net/100mb.test 进行测试\n\n# 参考资料\n\n1. [Linux Advanced Routing & Traffic Control HOWTO](http://www.lartc.org/lartc.html)\n2. [Traffic Control HOWTO](http://www.tldp.org/HOWTO/html_single/Traffic-Control-HOWTO/)\n3. [Linux 高级流控](http://www.ibm.com/developerworks/cn/linux/1412_xiehy_tc/)\n4. [htb user guide](http://luxik.cdi.cz/~devik/qos/htb/manual/userg.htm)\n5. [tc-tbf](https://linux.die.net/man/8/tc-tbf)\n","source":"_posts/2017-02-28-traffic-control.markdown","raw":"---\nlayout: post\ntitle: Traffic control\ntag: tc\n---\n\n# 简介\n\n在linux环境下，可以利用tc命令工具对本地流量进行控制，主要通过限速（shaping），调度（scheduling）和策略（policing）进行流量的控制。\n本文主要简略介绍tc中所使用到的几个概念，并结合命令示例对流量控制进行解释。由于tc主要用于出带宽的控制，所以下文主要描述的都是对出带宽的控制，文末附加一个利用tc进行入带宽控制的示例。\n\ntc主要利用3种对象来达成对流量的控制，分别是qdisc（排队规则）, class（类别）, filter（分类器）。\n\n## qdisc\n\nqdisc可以看做是一个有规则的队列，内核如果需要网卡向外发送数据，首先需要放入队列中，然后内核从队列中取出。例如最简单的fifo队列，数据包通过这个队列会按照先进先出的顺序从队列中流出发送到网卡上。\n\nqdisc按照类别划分可以分为有类别队列和无类别队列，其中有类别队列本身附着有类属性，并会根据分类器划分到类中，类可以继续划分为新的子类，如果不在继续分类，则需要为类指定一个队列。按照层次关系形成一棵类似于树状的结构，且树的叶子类节点需要附着一个无类型的队列。\n\n常见的无类别队列有sfq(随机公平队列)，pfifo_fast，tbf（令牌桶）。\n\n* sfq\n\nsfq实现了高度的公平性，会为每个会话使用一个散列算法散列到有限的几个队列中，系统每次从每个队列中拿出流量进行发送。多个会话可能共享一个队列，sfq算法会定期更新散列算法，重新将会话放到新的队列中来达到随机的效果。\n\n```shell\n# 增加一个qdisc，父类为1:10，其自身ID为10:0，使用sfq，每10秒更换一次hash算法\ntc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10\n```\n\n* pfifo_fast\n\npfifo_fast队列可以看作是有类别队列prio的无类别（固定类别）版本，该队列规则内部已经定义了优先级且无法使用tc进行修改。\npfifo_fast内部有3个band，分别记为0，1，2。如果band0上还有数据包，则一直从这个band上取出直到没有后再去band1，以此类推。数据包是按照header中的服务类型TOS进行分配的。TOS是数据包上的一个4bit字段，具体规则如下（规则源自[lartc](http://www.lartc.org/lartc.html)）：\n\n```\nBinary Decimcal  Meaning\n-----------------------------------------\n1000   8         Minimize delay (md)\n0100   4         Maximize throughput (mt)\n0010   2         Maximize reliability (mr)\n0001   1         Minimize monetary cost (mmc)\n0000   0         Normal Service\n\n由于其实TOS的这4bit是8(0-7)位中的1-4位，所以实际值是其2倍。\n\nTOS     Bits  Means                    Linux Priority    Band\n------------------------------------------------------------\n0x0     0     Normal Service           0 Best Effort     1\n0x2     1     Minimize Monetary Cost   1 Filler          2\n0x4     2     Maximize Reliability     0 Best Effort     1\n0x6     3     mmc+mr                   0 Best Effort     1\n0x8     4     Maximize Throughput      2 Bulk            2\n0xa     5     mmc+mt                   2 Bulk            2\n0xc     6     mr+mt                    2 Bulk            2\n0xe     7     mmc+mr+mt                2 Bulk            2\n0x10    8     Minimize Delay           6 Interactive     0\n0x12    9     mmc+md                   6 Interactive     0\n0x14    10    mr+md                    6 Interactive     0\n0x16    11    mmc+mr+md                6 Interactive     0\n0x18    12    mt+md                    4 Int. Bulk       1\n0x1a    13    mmc+mt+md                4 Int. Bulk       1\n0x1c    14    mr+mt+md                 4 Int. Bulk       1\n0x1e    15    mmc+mr+mt+md             4 Int. Bulk       1\n```\n\n* tbf\n\ntbf队列利用令牌桶原理来控制出带宽，每流出一定的数据量，就需要消耗桶中的令牌，一旦令牌消耗完毕，则不会再继续发送数据。每个一段时间，会重新往桶里面添加令牌直到桶满为止。\n\n```shell\ntc qdisc add dev eth0 root tbf rate 0.5mbit \\\nburst 5kb latency 70ms peakrate 1mbit \\\nminburst 1540\n```\n\n常见的分类队列有prio和htb\n\n* prio\n\nprio队列与前面的pfifo_fast类似，高优先级的数据先发送。在创建prio时，系统默认就会创建3个类，这些类仅包含单纯的fifo队列，用户可以利用tc进行替换。\n\n* htb\n\nhtb（Hierarchical Token Bucket）分层桶令牌与无类队列tbf类似，用于流量整形。\n\n```shell\n# 速率为30kbps，且上限（ceil）为100kps，说明如果网络空闲，这个class可以向外界借用宽带，默认ceil为rate一致\ntc class add dev eth0 parent 1:2 classid 1:10 htb rate 30kbps ceil 100kbps\n```\n\nhtb可以进行优先级划分，高优先级的队列优先得到剩余宽带，同优先级之间按照rate进行按比例划分。\n\n## class\n\nclass存在于有类别队列中，class是可以包含多个子类或者一个子队列。叶子类在队列中属于最终类别，会默认包含一个fifo的qdisc。\n\n## filter\n\nfilter的作用主要是定义如何将一个qdisc(class)划分到子class中。常见的分类器有u32。可以根据ip, 端口，协议类型，mac地址等进行过滤。\n\n# 样例说明\n\n在实际使用tc命令进行流量控制时，会为每个qdisc／class分配一个id，id由 主ID:从ID 两部分组成，其中qdisc的命名以主ID进行区分，例如 10: ,别是其ID为10:0，qdisc的从ID都是0。class的ID为10:1，其中主ID需要于其父节点ID一致。\n\n## 出带宽控制\n\n下面的例子来自[Linux高级流控](http://www.ibm.com/developerworks/cn/linux/1412_xiehy_tc/)\n\n```shell\n# 创建htb，默认走1:30的类别\ntc qdisc add dev eth0 root handle 1: htb default 30\n# 为root qdisc创建1:1的类别，注意主ID为1，与parent一致\ntc class add dev eth0 parent 1: classid 1:1 htb rate 6mbit burst 15k\n# 在class 1:1下定义3个子class，注意子class的主ID与parent一致\ntc class add dev eth0 parent 1:1 classid 1:10 htb rate 5mbit burst 15k\ntc class add dev eth0 parent 1:1 classid 1:20 htb rate 3mbit ceil 6mbit burst 15k\ntc class add dev eth0 parent 1:1 classid 1:30 htb rate 1kbit ceil 6mbit burst 15k\n# 为每个叶子class定义sfq的qdisc，防止流量被某个连接占用。perturb表示几秒更换一次hash算法。\ntc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10\ntc qdisc add dev eth0 parent 1:20 handle 20: sfq perturb 10\ntc qdisc add dev eth0 parent 1:30 handle 30: sfq perturb 10\n# 添加u32过滤器, 直接把流量导向相应的类 :\nU32=\"tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32\"\n$U32 match ip dport 80 0xffff flowid 1:10\n$U32 match ip sport 25 0xffff flowid 1:20\n```\n\n另外，使用以下命令可以查看各个qdisc/class的流量情况：\n\n```shell\ntc -s -d qdisc show dev eth0\ntc -s -d class show dev eth0\n```\n\n## tc + cgroup\n\n可以利用cgroup来进行进程的流量控制。使用cgroup进行流量控制时，需要引入net_cls cgroup子模块，在net_cls.classid文件中定义好该group下进程的分类class id。并在定义filter时使用cgroup filter\n\n```shell\ntc filter add dev eth2 parent 10: protocol ip prio 10 handle 1: cgroup\n```\n\n## 入带宽控制\n\n一般使用tc进行出带宽控制，因为tc的入带宽控制从网卡拿数据时数据已经发送到本机，再进行控制显得没有太多意义。下面仅演示利用tc ingress进入入带宽控制\n\n```shell\ntc qdisc add dev eth0 handle ffff: ingress\n# 限制来子10.0.0.*来的流量\ntc filter add dev eth0 parent ffff: protocol ip prio 50 u32 match ip src 10.0.0.1/24 police rate 100kbit burst 10k drop flowid :1\n```\n\n# 其他\n\n流量测试数据可以使用 http://cachefly.cachefly.net/100mb.test 进行测试\n\n# 参考资料\n\n1. [Linux Advanced Routing & Traffic Control HOWTO](http://www.lartc.org/lartc.html)\n2. [Traffic Control HOWTO](http://www.tldp.org/HOWTO/html_single/Traffic-Control-HOWTO/)\n3. [Linux 高级流控](http://www.ibm.com/developerworks/cn/linux/1412_xiehy_tc/)\n4. [htb user guide](http://luxik.cdi.cz/~devik/qos/htb/manual/userg.htm)\n5. [tc-tbf](https://linux.die.net/man/8/tc-tbf)\n","slug":"traffic-control","published":1,"date":"2017-02-27T16:00:00.000Z","updated":"2017-03-05T15:27:11.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapz5000jphv955drme57","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>在linux环境下，可以利用tc命令工具对本地流量进行控制，主要通过限速（shaping），调度（scheduling）和策略（policing）进行流量的控制。<br>本文主要简略介绍tc中所使用到的几个概念，并结合命令示例对流量控制进行解释。由于tc主要用于出带宽的控制，所以下文主要描述的都是对出带宽的控制，文末附加一个利用tc进行入带宽控制的示例。</p>\n<p>tc主要利用3种对象来达成对流量的控制，分别是qdisc（排队规则）, class（类别）, filter（分类器）。</p>\n<h2 id=\"qdisc\"><a href=\"#qdisc\" class=\"headerlink\" title=\"qdisc\"></a>qdisc</h2><p>qdisc可以看做是一个有规则的队列，内核如果需要网卡向外发送数据，首先需要放入队列中，然后内核从队列中取出。例如最简单的fifo队列，数据包通过这个队列会按照先进先出的顺序从队列中流出发送到网卡上。</p>\n<p>qdisc按照类别划分可以分为有类别队列和无类别队列，其中有类别队列本身附着有类属性，并会根据分类器划分到类中，类可以继续划分为新的子类，如果不在继续分类，则需要为类指定一个队列。按照层次关系形成一棵类似于树状的结构，且树的叶子类节点需要附着一个无类型的队列。</p>\n<p>常见的无类别队列有sfq(随机公平队列)，pfifo_fast，tbf（令牌桶）。</p>\n<ul>\n<li>sfq</li>\n</ul>\n<p>sfq实现了高度的公平性，会为每个会话使用一个散列算法散列到有限的几个队列中，系统每次从每个队列中拿出流量进行发送。多个会话可能共享一个队列，sfq算法会定期更新散列算法，重新将会话放到新的队列中来达到随机的效果。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 增加一个qdisc，父类为1:10，其自身ID为10:0，使用sfq，每10秒更换一次hash算法</div><div class=\"line\">tc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10</div></pre></td></tr></table></figure>\n<ul>\n<li>pfifo_fast</li>\n</ul>\n<p>pfifo_fast队列可以看作是有类别队列prio的无类别（固定类别）版本，该队列规则内部已经定义了优先级且无法使用tc进行修改。<br>pfifo_fast内部有3个band，分别记为0，1，2。如果band0上还有数据包，则一直从这个band上取出直到没有后再去band1，以此类推。数据包是按照header中的服务类型TOS进行分配的。TOS是数据包上的一个4bit字段，具体规则如下（规则源自<a href=\"http://www.lartc.org/lartc.html\" target=\"_blank\" rel=\"external\">lartc</a>）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\">Binary Decimcal  Meaning</div><div class=\"line\">-----------------------------------------</div><div class=\"line\">1000   8         Minimize delay (md)</div><div class=\"line\">0100   4         Maximize throughput (mt)</div><div class=\"line\">0010   2         Maximize reliability (mr)</div><div class=\"line\">0001   1         Minimize monetary cost (mmc)</div><div class=\"line\">0000   0         Normal Service</div><div class=\"line\"></div><div class=\"line\">由于其实TOS的这4bit是8(0-7)位中的1-4位，所以实际值是其2倍。</div><div class=\"line\"></div><div class=\"line\">TOS     Bits  Means                    Linux Priority    Band</div><div class=\"line\">------------------------------------------------------------</div><div class=\"line\">0x0     0     Normal Service           0 Best Effort     1</div><div class=\"line\">0x2     1     Minimize Monetary Cost   1 Filler          2</div><div class=\"line\">0x4     2     Maximize Reliability     0 Best Effort     1</div><div class=\"line\">0x6     3     mmc+mr                   0 Best Effort     1</div><div class=\"line\">0x8     4     Maximize Throughput      2 Bulk            2</div><div class=\"line\">0xa     5     mmc+mt                   2 Bulk            2</div><div class=\"line\">0xc     6     mr+mt                    2 Bulk            2</div><div class=\"line\">0xe     7     mmc+mr+mt                2 Bulk            2</div><div class=\"line\">0x10    8     Minimize Delay           6 Interactive     0</div><div class=\"line\">0x12    9     mmc+md                   6 Interactive     0</div><div class=\"line\">0x14    10    mr+md                    6 Interactive     0</div><div class=\"line\">0x16    11    mmc+mr+md                6 Interactive     0</div><div class=\"line\">0x18    12    mt+md                    4 Int. Bulk       1</div><div class=\"line\">0x1a    13    mmc+mt+md                4 Int. Bulk       1</div><div class=\"line\">0x1c    14    mr+mt+md                 4 Int. Bulk       1</div><div class=\"line\">0x1e    15    mmc+mr+mt+md             4 Int. Bulk       1</div></pre></td></tr></table></figure>\n<ul>\n<li>tbf</li>\n</ul>\n<p>tbf队列利用令牌桶原理来控制出带宽，每流出一定的数据量，就需要消耗桶中的令牌，一旦令牌消耗完毕，则不会再继续发送数据。每个一段时间，会重新往桶里面添加令牌直到桶满为止。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc qdisc add dev eth0 root tbf rate 0.5mbit \\</div><div class=\"line\">burst 5kb latency 70ms peakrate 1mbit \\</div><div class=\"line\">minburst 1540</div></pre></td></tr></table></figure>\n<p>常见的分类队列有prio和htb</p>\n<ul>\n<li>prio</li>\n</ul>\n<p>prio队列与前面的pfifo_fast类似，高优先级的数据先发送。在创建prio时，系统默认就会创建3个类，这些类仅包含单纯的fifo队列，用户可以利用tc进行替换。</p>\n<ul>\n<li>htb</li>\n</ul>\n<p>htb（Hierarchical Token Bucket）分层桶令牌与无类队列tbf类似，用于流量整形。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 速率为30kbps，且上限（ceil）为100kps，说明如果网络空闲，这个class可以向外界借用宽带，默认ceil为rate一致</div><div class=\"line\">tc class add dev eth0 parent 1:2 classid 1:10 htb rate 30kbps ceil 100kbps</div></pre></td></tr></table></figure>\n<p>htb可以进行优先级划分，高优先级的队列优先得到剩余宽带，同优先级之间按照rate进行按比例划分。</p>\n<h2 id=\"class\"><a href=\"#class\" class=\"headerlink\" title=\"class\"></a>class</h2><p>class存在于有类别队列中，class是可以包含多个子类或者一个子队列。叶子类在队列中属于最终类别，会默认包含一个fifo的qdisc。</p>\n<h2 id=\"filter\"><a href=\"#filter\" class=\"headerlink\" title=\"filter\"></a>filter</h2><p>filter的作用主要是定义如何将一个qdisc(class)划分到子class中。常见的分类器有u32。可以根据ip, 端口，协议类型，mac地址等进行过滤。</p>\n<h1 id=\"样例说明\"><a href=\"#样例说明\" class=\"headerlink\" title=\"样例说明\"></a>样例说明</h1><p>在实际使用tc命令进行流量控制时，会为每个qdisc／class分配一个id，id由 主ID:从ID 两部分组成，其中qdisc的命名以主ID进行区分，例如 10: ,别是其ID为10:0，qdisc的从ID都是0。class的ID为10:1，其中主ID需要于其父节点ID一致。</p>\n<h2 id=\"出带宽控制\"><a href=\"#出带宽控制\" class=\"headerlink\" title=\"出带宽控制\"></a>出带宽控制</h2><p>下面的例子来自<a href=\"http://www.ibm.com/developerworks/cn/linux/1412_xiehy_tc/\" target=\"_blank\" rel=\"external\">Linux高级流控</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 创建htb，默认走1:30的类别</div><div class=\"line\">tc qdisc add dev eth0 root handle 1: htb default 30</div><div class=\"line\"># 为root qdisc创建1:1的类别，注意主ID为1，与parent一致</div><div class=\"line\">tc class add dev eth0 parent 1: classid 1:1 htb rate 6mbit burst 15k</div><div class=\"line\"># 在class 1:1下定义3个子class，注意子class的主ID与parent一致</div><div class=\"line\">tc class add dev eth0 parent 1:1 classid 1:10 htb rate 5mbit burst 15k</div><div class=\"line\">tc class add dev eth0 parent 1:1 classid 1:20 htb rate 3mbit ceil 6mbit burst 15k</div><div class=\"line\">tc class add dev eth0 parent 1:1 classid 1:30 htb rate 1kbit ceil 6mbit burst 15k</div><div class=\"line\"># 为每个叶子class定义sfq的qdisc，防止流量被某个连接占用。perturb表示几秒更换一次hash算法。</div><div class=\"line\">tc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10</div><div class=\"line\">tc qdisc add dev eth0 parent 1:20 handle 20: sfq perturb 10</div><div class=\"line\">tc qdisc add dev eth0 parent 1:30 handle 30: sfq perturb 10</div><div class=\"line\"># 添加u32过滤器, 直接把流量导向相应的类 :</div><div class=\"line\">U32=&quot;tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32&quot;</div><div class=\"line\">$U32 match ip dport 80 0xffff flowid 1:10</div><div class=\"line\">$U32 match ip sport 25 0xffff flowid 1:20</div></pre></td></tr></table></figure>\n<p>另外，使用以下命令可以查看各个qdisc/class的流量情况：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc -s -d qdisc show dev eth0</div><div class=\"line\">tc -s -d class show dev eth0</div></pre></td></tr></table></figure>\n<h2 id=\"tc-cgroup\"><a href=\"#tc-cgroup\" class=\"headerlink\" title=\"tc + cgroup\"></a>tc + cgroup</h2><p>可以利用cgroup来进行进程的流量控制。使用cgroup进行流量控制时，需要引入net_cls cgroup子模块，在net_cls.classid文件中定义好该group下进程的分类class id。并在定义filter时使用cgroup filter</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc filter add dev eth2 parent 10: protocol ip prio 10 handle 1: cgroup</div></pre></td></tr></table></figure>\n<h2 id=\"入带宽控制\"><a href=\"#入带宽控制\" class=\"headerlink\" title=\"入带宽控制\"></a>入带宽控制</h2><p>一般使用tc进行出带宽控制，因为tc的入带宽控制从网卡拿数据时数据已经发送到本机，再进行控制显得没有太多意义。下面仅演示利用tc ingress进入入带宽控制</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc qdisc add dev eth0 handle ffff: ingress</div><div class=\"line\"># 限制来子10.0.0.*来的流量</div><div class=\"line\">tc filter add dev eth0 parent ffff: protocol ip prio 50 u32 match ip src 10.0.0.1/24 police rate 100kbit burst 10k drop flowid :1</div></pre></td></tr></table></figure>\n<h1 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h1><p>流量测试数据可以使用 <a href=\"http://cachefly.cachefly.net/100mb.test\" target=\"_blank\" rel=\"external\">http://cachefly.cachefly.net/100mb.test</a> 进行测试</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ol>\n<li><a href=\"http://www.lartc.org/lartc.html\" target=\"_blank\" rel=\"external\">Linux Advanced Routing &amp; Traffic Control HOWTO</a></li>\n<li><a href=\"http://www.tldp.org/HOWTO/html_single/Traffic-Control-HOWTO/\" target=\"_blank\" rel=\"external\">Traffic Control HOWTO</a></li>\n<li><a href=\"http://www.ibm.com/developerworks/cn/linux/1412_xiehy_tc/\" target=\"_blank\" rel=\"external\">Linux 高级流控</a></li>\n<li><a href=\"http://luxik.cdi.cz/~devik/qos/htb/manual/userg.htm\" target=\"_blank\" rel=\"external\">htb user guide</a></li>\n<li><a href=\"https://linux.die.net/man/8/tc-tbf\" target=\"_blank\" rel=\"external\">tc-tbf</a></li>\n</ol>\n","excerpt":"","more":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>在linux环境下，可以利用tc命令工具对本地流量进行控制，主要通过限速（shaping），调度（scheduling）和策略（policing）进行流量的控制。<br>本文主要简略介绍tc中所使用到的几个概念，并结合命令示例对流量控制进行解释。由于tc主要用于出带宽的控制，所以下文主要描述的都是对出带宽的控制，文末附加一个利用tc进行入带宽控制的示例。</p>\n<p>tc主要利用3种对象来达成对流量的控制，分别是qdisc（排队规则）, class（类别）, filter（分类器）。</p>\n<h2 id=\"qdisc\"><a href=\"#qdisc\" class=\"headerlink\" title=\"qdisc\"></a>qdisc</h2><p>qdisc可以看做是一个有规则的队列，内核如果需要网卡向外发送数据，首先需要放入队列中，然后内核从队列中取出。例如最简单的fifo队列，数据包通过这个队列会按照先进先出的顺序从队列中流出发送到网卡上。</p>\n<p>qdisc按照类别划分可以分为有类别队列和无类别队列，其中有类别队列本身附着有类属性，并会根据分类器划分到类中，类可以继续划分为新的子类，如果不在继续分类，则需要为类指定一个队列。按照层次关系形成一棵类似于树状的结构，且树的叶子类节点需要附着一个无类型的队列。</p>\n<p>常见的无类别队列有sfq(随机公平队列)，pfifo_fast，tbf（令牌桶）。</p>\n<ul>\n<li>sfq</li>\n</ul>\n<p>sfq实现了高度的公平性，会为每个会话使用一个散列算法散列到有限的几个队列中，系统每次从每个队列中拿出流量进行发送。多个会话可能共享一个队列，sfq算法会定期更新散列算法，重新将会话放到新的队列中来达到随机的效果。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 增加一个qdisc，父类为1:10，其自身ID为10:0，使用sfq，每10秒更换一次hash算法</div><div class=\"line\">tc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10</div></pre></td></tr></table></figure>\n<ul>\n<li>pfifo_fast</li>\n</ul>\n<p>pfifo_fast队列可以看作是有类别队列prio的无类别（固定类别）版本，该队列规则内部已经定义了优先级且无法使用tc进行修改。<br>pfifo_fast内部有3个band，分别记为0，1，2。如果band0上还有数据包，则一直从这个band上取出直到没有后再去band1，以此类推。数据包是按照header中的服务类型TOS进行分配的。TOS是数据包上的一个4bit字段，具体规则如下（规则源自<a href=\"http://www.lartc.org/lartc.html\">lartc</a>）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\">Binary Decimcal  Meaning</div><div class=\"line\">-----------------------------------------</div><div class=\"line\">1000   8         Minimize delay (md)</div><div class=\"line\">0100   4         Maximize throughput (mt)</div><div class=\"line\">0010   2         Maximize reliability (mr)</div><div class=\"line\">0001   1         Minimize monetary cost (mmc)</div><div class=\"line\">0000   0         Normal Service</div><div class=\"line\"></div><div class=\"line\">由于其实TOS的这4bit是8(0-7)位中的1-4位，所以实际值是其2倍。</div><div class=\"line\"></div><div class=\"line\">TOS     Bits  Means                    Linux Priority    Band</div><div class=\"line\">------------------------------------------------------------</div><div class=\"line\">0x0     0     Normal Service           0 Best Effort     1</div><div class=\"line\">0x2     1     Minimize Monetary Cost   1 Filler          2</div><div class=\"line\">0x4     2     Maximize Reliability     0 Best Effort     1</div><div class=\"line\">0x6     3     mmc+mr                   0 Best Effort     1</div><div class=\"line\">0x8     4     Maximize Throughput      2 Bulk            2</div><div class=\"line\">0xa     5     mmc+mt                   2 Bulk            2</div><div class=\"line\">0xc     6     mr+mt                    2 Bulk            2</div><div class=\"line\">0xe     7     mmc+mr+mt                2 Bulk            2</div><div class=\"line\">0x10    8     Minimize Delay           6 Interactive     0</div><div class=\"line\">0x12    9     mmc+md                   6 Interactive     0</div><div class=\"line\">0x14    10    mr+md                    6 Interactive     0</div><div class=\"line\">0x16    11    mmc+mr+md                6 Interactive     0</div><div class=\"line\">0x18    12    mt+md                    4 Int. Bulk       1</div><div class=\"line\">0x1a    13    mmc+mt+md                4 Int. Bulk       1</div><div class=\"line\">0x1c    14    mr+mt+md                 4 Int. Bulk       1</div><div class=\"line\">0x1e    15    mmc+mr+mt+md             4 Int. Bulk       1</div></pre></td></tr></table></figure>\n<ul>\n<li>tbf</li>\n</ul>\n<p>tbf队列利用令牌桶原理来控制出带宽，每流出一定的数据量，就需要消耗桶中的令牌，一旦令牌消耗完毕，则不会再继续发送数据。每个一段时间，会重新往桶里面添加令牌直到桶满为止。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc qdisc add dev eth0 root tbf rate 0.5mbit \\</div><div class=\"line\">burst 5kb latency 70ms peakrate 1mbit \\</div><div class=\"line\">minburst 1540</div></pre></td></tr></table></figure>\n<p>常见的分类队列有prio和htb</p>\n<ul>\n<li>prio</li>\n</ul>\n<p>prio队列与前面的pfifo_fast类似，高优先级的数据先发送。在创建prio时，系统默认就会创建3个类，这些类仅包含单纯的fifo队列，用户可以利用tc进行替换。</p>\n<ul>\n<li>htb</li>\n</ul>\n<p>htb（Hierarchical Token Bucket）分层桶令牌与无类队列tbf类似，用于流量整形。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 速率为30kbps，且上限（ceil）为100kps，说明如果网络空闲，这个class可以向外界借用宽带，默认ceil为rate一致</div><div class=\"line\">tc class add dev eth0 parent 1:2 classid 1:10 htb rate 30kbps ceil 100kbps</div></pre></td></tr></table></figure>\n<p>htb可以进行优先级划分，高优先级的队列优先得到剩余宽带，同优先级之间按照rate进行按比例划分。</p>\n<h2 id=\"class\"><a href=\"#class\" class=\"headerlink\" title=\"class\"></a>class</h2><p>class存在于有类别队列中，class是可以包含多个子类或者一个子队列。叶子类在队列中属于最终类别，会默认包含一个fifo的qdisc。</p>\n<h2 id=\"filter\"><a href=\"#filter\" class=\"headerlink\" title=\"filter\"></a>filter</h2><p>filter的作用主要是定义如何将一个qdisc(class)划分到子class中。常见的分类器有u32。可以根据ip, 端口，协议类型，mac地址等进行过滤。</p>\n<h1 id=\"样例说明\"><a href=\"#样例说明\" class=\"headerlink\" title=\"样例说明\"></a>样例说明</h1><p>在实际使用tc命令进行流量控制时，会为每个qdisc／class分配一个id，id由 主ID:从ID 两部分组成，其中qdisc的命名以主ID进行区分，例如 10: ,别是其ID为10:0，qdisc的从ID都是0。class的ID为10:1，其中主ID需要于其父节点ID一致。</p>\n<h2 id=\"出带宽控制\"><a href=\"#出带宽控制\" class=\"headerlink\" title=\"出带宽控制\"></a>出带宽控制</h2><p>下面的例子来自<a href=\"http://www.ibm.com/developerworks/cn/linux/1412_xiehy_tc/\">Linux高级流控</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 创建htb，默认走1:30的类别</div><div class=\"line\">tc qdisc add dev eth0 root handle 1: htb default 30</div><div class=\"line\"># 为root qdisc创建1:1的类别，注意主ID为1，与parent一致</div><div class=\"line\">tc class add dev eth0 parent 1: classid 1:1 htb rate 6mbit burst 15k</div><div class=\"line\"># 在class 1:1下定义3个子class，注意子class的主ID与parent一致</div><div class=\"line\">tc class add dev eth0 parent 1:1 classid 1:10 htb rate 5mbit burst 15k</div><div class=\"line\">tc class add dev eth0 parent 1:1 classid 1:20 htb rate 3mbit ceil 6mbit burst 15k</div><div class=\"line\">tc class add dev eth0 parent 1:1 classid 1:30 htb rate 1kbit ceil 6mbit burst 15k</div><div class=\"line\"># 为每个叶子class定义sfq的qdisc，防止流量被某个连接占用。perturb表示几秒更换一次hash算法。</div><div class=\"line\">tc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10</div><div class=\"line\">tc qdisc add dev eth0 parent 1:20 handle 20: sfq perturb 10</div><div class=\"line\">tc qdisc add dev eth0 parent 1:30 handle 30: sfq perturb 10</div><div class=\"line\"># 添加u32过滤器, 直接把流量导向相应的类 :</div><div class=\"line\">U32=&quot;tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32&quot;</div><div class=\"line\">$U32 match ip dport 80 0xffff flowid 1:10</div><div class=\"line\">$U32 match ip sport 25 0xffff flowid 1:20</div></pre></td></tr></table></figure>\n<p>另外，使用以下命令可以查看各个qdisc/class的流量情况：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc -s -d qdisc show dev eth0</div><div class=\"line\">tc -s -d class show dev eth0</div></pre></td></tr></table></figure>\n<h2 id=\"tc-cgroup\"><a href=\"#tc-cgroup\" class=\"headerlink\" title=\"tc + cgroup\"></a>tc + cgroup</h2><p>可以利用cgroup来进行进程的流量控制。使用cgroup进行流量控制时，需要引入net_cls cgroup子模块，在net_cls.classid文件中定义好该group下进程的分类class id。并在定义filter时使用cgroup filter</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc filter add dev eth2 parent 10: protocol ip prio 10 handle 1: cgroup</div></pre></td></tr></table></figure>\n<h2 id=\"入带宽控制\"><a href=\"#入带宽控制\" class=\"headerlink\" title=\"入带宽控制\"></a>入带宽控制</h2><p>一般使用tc进行出带宽控制，因为tc的入带宽控制从网卡拿数据时数据已经发送到本机，再进行控制显得没有太多意义。下面仅演示利用tc ingress进入入带宽控制</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc qdisc add dev eth0 handle ffff: ingress</div><div class=\"line\"># 限制来子10.0.0.*来的流量</div><div class=\"line\">tc filter add dev eth0 parent ffff: protocol ip prio 50 u32 match ip src 10.0.0.1/24 police rate 100kbit burst 10k drop flowid :1</div></pre></td></tr></table></figure>\n<h1 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h1><p>流量测试数据可以使用 <a href=\"http://cachefly.cachefly.net/100mb.test\">http://cachefly.cachefly.net/100mb.test</a> 进行测试</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ol>\n<li><a href=\"http://www.lartc.org/lartc.html\">Linux Advanced Routing &amp; Traffic Control HOWTO</a></li>\n<li><a href=\"http://www.tldp.org/HOWTO/html_single/Traffic-Control-HOWTO/\">Traffic Control HOWTO</a></li>\n<li><a href=\"http://www.ibm.com/developerworks/cn/linux/1412_xiehy_tc/\">Linux 高级流控</a></li>\n<li><a href=\"http://luxik.cdi.cz/~devik/qos/htb/manual/userg.htm\">htb user guide</a></li>\n<li><a href=\"https://linux.die.net/man/8/tc-tbf\">tc-tbf</a></li>\n</ol>\n"},{"layout":"post","title":"Distributed Systems Course 6.824 lab 1","category":null,"_content":"\n\n\n> 本文开始，主要对mit的Distributed Systems课程的实验进行完成。课程网址在[这里](http://nil.csail.mit.edu/6.824/2015/index.html)\n\n- 本章是lab 1的实验\n\n# Part 1：Word Count\n\n第一部分的实验是在给定代码上实现一个wordcount程序，只需要完成 main/wc.go下面的Map和Reduce函数即可。\nMap阶段将传入的句子（value）分割成各个单词然后使用提供的KeyValue结构存储到List中，Key为单词，value为1表示单词出现的次数。\nReduce将给每个单词计数，最终得到整个文本的单词计数。\n\n运行命令为`go run wc.go master kjv12.txt sequential`, 也可以直接`sh ./test-wc.sh`运行并检验结果\n\n```\nfunc Map(value string) *list.List {\n\tf := func(c rune) bool {\n\t\treturn !unicode.IsLetter(c)\n\t}\n\twords := strings.FieldsFunc(value, f)\n\tstream := list.New()\n\tfor _, word := range words {\n\t\tstream.PushBack(mapreduce.KeyValue{Key: word, Value: \"1\"})\n\t}\n\treturn stream\n}\n\nfunc Reduce(key string, values *list.List) string {\n\tcount := 0\n\tfor e := values.Front(); e != nil; e = e.Next() {\n\t\tc, _ := strconv.Atoi(e.Value.(string))\n\t\tcount += c\n\t}\n\treturn strconv.Itoa(count)\n}\n```\n\n#  Part 2&3: Distributing MapReduce jobs & Handling worker failures\n\n第一部分只是在本地模拟MR实现，这一部分抽象成Master/Client模式运行MR程序，server端主要负责切分作业并下发以及最终结果的收集合并，client负责具体的map/reduce任务。并且，需要处理client端发生错误时的应对措施。\n\n主要实现mapreduce/master.go中的RunMaster方法，具体做法是使用select从registerChannel中得到新注册的worker，并通过rpc给它们分配任务。worker完成分配的任务后master可以继续下发新任务。如果发生错误，则从server端将这个worker排除在可以重复工作的worker外。\n任务分两个阶段，map和reduce，map任务下发完后需要先等待所有map任务全部完成后再开始进行reduce任务。\n在reduce阶段完全结束后再告知worker端结束工作。\n\n```\nfunc (mr *MapReduce) RunMaster() *list.List {\n\t// Your code here\n\tidleWorder := make(chan string)\n\tmapChan := make(chan int)\n\treduceChan := make(chan int)\n\tfor i := 0; i < mr.nMap; i++ {\n\t\tgo func(mapN int) {\n\t\t\tfor {\n\t\t\t\tvar worker string\n\t\t\t\tsuccess := false\n\t\t\t\tselect {\n\t\t\t\tcase worker = <-mr.registerChannel:\n\t\t\t\t\tmr.Workers[worker] = &WorkerInfo{address: worker}\n\t\t\t\t\tjobArgs := DoJobArgs{File: mr.file, Operation: Map, JobNumber: mapN, NumOtherPhase: mr.nReduce}\n\t\t\t\t\tvar reply DoJobReply\n\t\t\t\t\tsuccess = call(worker, \"Worker.DoJob\", jobArgs, &reply)\n\t\t\t\tcase worker = <-idleWorder:\n\t\t\t\t\tjobArgs := DoJobArgs{File: mr.file, Operation: Map, JobNumber: mapN, NumOtherPhase: mr.nReduce}\n\t\t\t\t\tvar reply DoJobReply\n\t\t\t\t\tsuccess = call(worker, \"Worker.DoJob\", jobArgs, &reply)\n\t\t\t\t}\n\t\t\t\tif success {\n\t\t\t\t\tmapChan <- mapN\n\t\t\t\t\tidleWorder <- worker\n\t\t\t\t\treturn\n\t\t\t\t} else {\n\t\t\t\t\tdelete(mr.Workers, worker)\n\t\t\t\t}\n\t\t\t}\n\t\t}(i)\n\t}\n\tfor i := 0; i < mr.nMap; i++ {\n\t\t<-mapChan\n\t}\n\tfor i := 0; i < mr.nReduce; i++ {\n\t\tgo func(reduceN int) {\n\t\t\tfor {\n\t\t\t\tvar worker string\n\t\t\t\tsuccess := false\n\t\t\t\tselect {\n\t\t\t\tcase worker = <-mr.registerChannel:\n\t\t\t\t\tmr.Workers[worker] = &WorkerInfo{address: worker}\n\t\t\t\t\tjobArgs := DoJobArgs{File: mr.file, Operation: Reduce, JobNumber: reduceN, NumOtherPhase: mr.nMap}\n\t\t\t\t\tvar reply DoJobReply\n\t\t\t\t\tsuccess = call(worker, \"Worker.DoJob\", jobArgs, &reply)\n\t\t\t\tcase worker = <-idleWorder:\n\t\t\t\t\tjobArgs := DoJobArgs{File: mr.file, Operation: Reduce, JobNumber: reduceN, NumOtherPhase: mr.nMap}\n\t\t\t\t\tvar reply DoJobReply\n\t\t\t\t\tsuccess = call(worker, \"Worker.DoJob\", jobArgs, &reply)\n\t\t\t\t}\n\t\t\t\tif success {\n\t\t\t\t\treduceChan <- reduceN\n\t\t\t\t\tidleWorder <- worker\n\t\t\t\t\treturn\n\t\t\t\t} else {\n\t\t\t\t\tdelete(mr.Workers, worker)\n\t\t\t\t}\n\t\t\t}\n\t\t}(i)\n\t}\n\tfmt.Println(\"waiting for reduce done!\")\n\tfor i := 0; i < mr.nReduce; i++ {\n\t\t<-reduceChan\n\t}\n\tfmt.Println(\"reduce done with living worker\", len(mr.Workers))\n\t// consume idle workers...\n\tfor i := 0; i < len(mr.Workers); i++ {\n\t\tfmt.Println(<-idleWorder)\n\t}\n\treturn mr.KillWorkers()\n}\n```\n\n","source":"_posts/2015-11-17-Distributed-Systems-course-6.824-lab1.markdown","raw":"---\nlayout: post\ntitle: Distributed Systems Course 6.824 lab 1\ncategory:\ntag: [Distributed System]\n---\n\n\n\n> 本文开始，主要对mit的Distributed Systems课程的实验进行完成。课程网址在[这里](http://nil.csail.mit.edu/6.824/2015/index.html)\n\n- 本章是lab 1的实验\n\n# Part 1：Word Count\n\n第一部分的实验是在给定代码上实现一个wordcount程序，只需要完成 main/wc.go下面的Map和Reduce函数即可。\nMap阶段将传入的句子（value）分割成各个单词然后使用提供的KeyValue结构存储到List中，Key为单词，value为1表示单词出现的次数。\nReduce将给每个单词计数，最终得到整个文本的单词计数。\n\n运行命令为`go run wc.go master kjv12.txt sequential`, 也可以直接`sh ./test-wc.sh`运行并检验结果\n\n```\nfunc Map(value string) *list.List {\n\tf := func(c rune) bool {\n\t\treturn !unicode.IsLetter(c)\n\t}\n\twords := strings.FieldsFunc(value, f)\n\tstream := list.New()\n\tfor _, word := range words {\n\t\tstream.PushBack(mapreduce.KeyValue{Key: word, Value: \"1\"})\n\t}\n\treturn stream\n}\n\nfunc Reduce(key string, values *list.List) string {\n\tcount := 0\n\tfor e := values.Front(); e != nil; e = e.Next() {\n\t\tc, _ := strconv.Atoi(e.Value.(string))\n\t\tcount += c\n\t}\n\treturn strconv.Itoa(count)\n}\n```\n\n#  Part 2&3: Distributing MapReduce jobs & Handling worker failures\n\n第一部分只是在本地模拟MR实现，这一部分抽象成Master/Client模式运行MR程序，server端主要负责切分作业并下发以及最终结果的收集合并，client负责具体的map/reduce任务。并且，需要处理client端发生错误时的应对措施。\n\n主要实现mapreduce/master.go中的RunMaster方法，具体做法是使用select从registerChannel中得到新注册的worker，并通过rpc给它们分配任务。worker完成分配的任务后master可以继续下发新任务。如果发生错误，则从server端将这个worker排除在可以重复工作的worker外。\n任务分两个阶段，map和reduce，map任务下发完后需要先等待所有map任务全部完成后再开始进行reduce任务。\n在reduce阶段完全结束后再告知worker端结束工作。\n\n```\nfunc (mr *MapReduce) RunMaster() *list.List {\n\t// Your code here\n\tidleWorder := make(chan string)\n\tmapChan := make(chan int)\n\treduceChan := make(chan int)\n\tfor i := 0; i < mr.nMap; i++ {\n\t\tgo func(mapN int) {\n\t\t\tfor {\n\t\t\t\tvar worker string\n\t\t\t\tsuccess := false\n\t\t\t\tselect {\n\t\t\t\tcase worker = <-mr.registerChannel:\n\t\t\t\t\tmr.Workers[worker] = &WorkerInfo{address: worker}\n\t\t\t\t\tjobArgs := DoJobArgs{File: mr.file, Operation: Map, JobNumber: mapN, NumOtherPhase: mr.nReduce}\n\t\t\t\t\tvar reply DoJobReply\n\t\t\t\t\tsuccess = call(worker, \"Worker.DoJob\", jobArgs, &reply)\n\t\t\t\tcase worker = <-idleWorder:\n\t\t\t\t\tjobArgs := DoJobArgs{File: mr.file, Operation: Map, JobNumber: mapN, NumOtherPhase: mr.nReduce}\n\t\t\t\t\tvar reply DoJobReply\n\t\t\t\t\tsuccess = call(worker, \"Worker.DoJob\", jobArgs, &reply)\n\t\t\t\t}\n\t\t\t\tif success {\n\t\t\t\t\tmapChan <- mapN\n\t\t\t\t\tidleWorder <- worker\n\t\t\t\t\treturn\n\t\t\t\t} else {\n\t\t\t\t\tdelete(mr.Workers, worker)\n\t\t\t\t}\n\t\t\t}\n\t\t}(i)\n\t}\n\tfor i := 0; i < mr.nMap; i++ {\n\t\t<-mapChan\n\t}\n\tfor i := 0; i < mr.nReduce; i++ {\n\t\tgo func(reduceN int) {\n\t\t\tfor {\n\t\t\t\tvar worker string\n\t\t\t\tsuccess := false\n\t\t\t\tselect {\n\t\t\t\tcase worker = <-mr.registerChannel:\n\t\t\t\t\tmr.Workers[worker] = &WorkerInfo{address: worker}\n\t\t\t\t\tjobArgs := DoJobArgs{File: mr.file, Operation: Reduce, JobNumber: reduceN, NumOtherPhase: mr.nMap}\n\t\t\t\t\tvar reply DoJobReply\n\t\t\t\t\tsuccess = call(worker, \"Worker.DoJob\", jobArgs, &reply)\n\t\t\t\tcase worker = <-idleWorder:\n\t\t\t\t\tjobArgs := DoJobArgs{File: mr.file, Operation: Reduce, JobNumber: reduceN, NumOtherPhase: mr.nMap}\n\t\t\t\t\tvar reply DoJobReply\n\t\t\t\t\tsuccess = call(worker, \"Worker.DoJob\", jobArgs, &reply)\n\t\t\t\t}\n\t\t\t\tif success {\n\t\t\t\t\treduceChan <- reduceN\n\t\t\t\t\tidleWorder <- worker\n\t\t\t\t\treturn\n\t\t\t\t} else {\n\t\t\t\t\tdelete(mr.Workers, worker)\n\t\t\t\t}\n\t\t\t}\n\t\t}(i)\n\t}\n\tfmt.Println(\"waiting for reduce done!\")\n\tfor i := 0; i < mr.nReduce; i++ {\n\t\t<-reduceChan\n\t}\n\tfmt.Println(\"reduce done with living worker\", len(mr.Workers))\n\t// consume idle workers...\n\tfor i := 0; i < len(mr.Workers); i++ {\n\t\tfmt.Println(<-idleWorder)\n\t}\n\treturn mr.KillWorkers()\n}\n```\n\n","slug":"Distributed-Systems-course-6.824-lab1","published":1,"date":"2015-11-16T16:00:00.000Z","updated":"2017-03-06T13:53:01.000Z","comments":1,"photos":[],"link":"","_id":"ck5asapz6000mphv9b05ktbn0","content":"<blockquote>\n<p>本文开始，主要对mit的Distributed Systems课程的实验进行完成。课程网址在<a href=\"http://nil.csail.mit.edu/6.824/2015/index.html\" target=\"_blank\" rel=\"external\">这里</a></p>\n</blockquote>\n<ul>\n<li>本章是lab 1的实验</li>\n</ul>\n<h1 id=\"Part-1：Word-Count\"><a href=\"#Part-1：Word-Count\" class=\"headerlink\" title=\"Part 1：Word Count\"></a>Part 1：Word Count</h1><p>第一部分的实验是在给定代码上实现一个wordcount程序，只需要完成 main/wc.go下面的Map和Reduce函数即可。<br>Map阶段将传入的句子（value）分割成各个单词然后使用提供的KeyValue结构存储到List中，Key为单词，value为1表示单词出现的次数。<br>Reduce将给每个单词计数，最终得到整个文本的单词计数。</p>\n<p>运行命令为<code>go run wc.go master kjv12.txt sequential</code>, 也可以直接<code>sh ./test-wc.sh</code>运行并检验结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">func Map(value string) *list.List &#123;</div><div class=\"line\">\tf := func(c rune) bool &#123;</div><div class=\"line\">\t\treturn !unicode.IsLetter(c)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\twords := strings.FieldsFunc(value, f)</div><div class=\"line\">\tstream := list.New()</div><div class=\"line\">\tfor _, word := range words &#123;</div><div class=\"line\">\t\tstream.PushBack(mapreduce.KeyValue&#123;Key: word, Value: &quot;1&quot;&#125;)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn stream</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func Reduce(key string, values *list.List) string &#123;</div><div class=\"line\">\tcount := 0</div><div class=\"line\">\tfor e := values.Front(); e != nil; e = e.Next() &#123;</div><div class=\"line\">\t\tc, _ := strconv.Atoi(e.Value.(string))</div><div class=\"line\">\t\tcount += c</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn strconv.Itoa(count)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h1 id=\"Part-2-amp-3-Distributing-MapReduce-jobs-amp-Handling-worker-failures\"><a href=\"#Part-2-amp-3-Distributing-MapReduce-jobs-amp-Handling-worker-failures\" class=\"headerlink\" title=\"Part 2&amp;3: Distributing MapReduce jobs &amp; Handling worker failures\"></a>Part 2&amp;3: Distributing MapReduce jobs &amp; Handling worker failures</h1><p>第一部分只是在本地模拟MR实现，这一部分抽象成Master/Client模式运行MR程序，server端主要负责切分作业并下发以及最终结果的收集合并，client负责具体的map/reduce任务。并且，需要处理client端发生错误时的应对措施。</p>\n<p>主要实现mapreduce/master.go中的RunMaster方法，具体做法是使用select从registerChannel中得到新注册的worker，并通过rpc给它们分配任务。worker完成分配的任务后master可以继续下发新任务。如果发生错误，则从server端将这个worker排除在可以重复工作的worker外。<br>任务分两个阶段，map和reduce，map任务下发完后需要先等待所有map任务全部完成后再开始进行reduce任务。<br>在reduce阶段完全结束后再告知worker端结束工作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div></pre></td><td class=\"code\"><pre><div class=\"line\">func (mr *MapReduce) RunMaster() *list.List &#123;</div><div class=\"line\">\t// Your code here</div><div class=\"line\">\tidleWorder := make(chan string)</div><div class=\"line\">\tmapChan := make(chan int)</div><div class=\"line\">\treduceChan := make(chan int)</div><div class=\"line\">\tfor i := 0; i &lt; mr.nMap; i++ &#123;</div><div class=\"line\">\t\tgo func(mapN int) &#123;</div><div class=\"line\">\t\t\tfor &#123;</div><div class=\"line\">\t\t\t\tvar worker string</div><div class=\"line\">\t\t\t\tsuccess := false</div><div class=\"line\">\t\t\t\tselect &#123;</div><div class=\"line\">\t\t\t\tcase worker = &lt;-mr.registerChannel:</div><div class=\"line\">\t\t\t\t\tmr.Workers[worker] = &amp;WorkerInfo&#123;address: worker&#125;</div><div class=\"line\">\t\t\t\t\tjobArgs := DoJobArgs&#123;File: mr.file, Operation: Map, JobNumber: mapN, NumOtherPhase: mr.nReduce&#125;</div><div class=\"line\">\t\t\t\t\tvar reply DoJobReply</div><div class=\"line\">\t\t\t\t\tsuccess = call(worker, &quot;Worker.DoJob&quot;, jobArgs, &amp;reply)</div><div class=\"line\">\t\t\t\tcase worker = &lt;-idleWorder:</div><div class=\"line\">\t\t\t\t\tjobArgs := DoJobArgs&#123;File: mr.file, Operation: Map, JobNumber: mapN, NumOtherPhase: mr.nReduce&#125;</div><div class=\"line\">\t\t\t\t\tvar reply DoJobReply</div><div class=\"line\">\t\t\t\t\tsuccess = call(worker, &quot;Worker.DoJob&quot;, jobArgs, &amp;reply)</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tif success &#123;</div><div class=\"line\">\t\t\t\t\tmapChan &lt;- mapN</div><div class=\"line\">\t\t\t\t\tidleWorder &lt;- worker</div><div class=\"line\">\t\t\t\t\treturn</div><div class=\"line\">\t\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\t\tdelete(mr.Workers, worker)</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;(i)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tfor i := 0; i &lt; mr.nMap; i++ &#123;</div><div class=\"line\">\t\t&lt;-mapChan</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tfor i := 0; i &lt; mr.nReduce; i++ &#123;</div><div class=\"line\">\t\tgo func(reduceN int) &#123;</div><div class=\"line\">\t\t\tfor &#123;</div><div class=\"line\">\t\t\t\tvar worker string</div><div class=\"line\">\t\t\t\tsuccess := false</div><div class=\"line\">\t\t\t\tselect &#123;</div><div class=\"line\">\t\t\t\tcase worker = &lt;-mr.registerChannel:</div><div class=\"line\">\t\t\t\t\tmr.Workers[worker] = &amp;WorkerInfo&#123;address: worker&#125;</div><div class=\"line\">\t\t\t\t\tjobArgs := DoJobArgs&#123;File: mr.file, Operation: Reduce, JobNumber: reduceN, NumOtherPhase: mr.nMap&#125;</div><div class=\"line\">\t\t\t\t\tvar reply DoJobReply</div><div class=\"line\">\t\t\t\t\tsuccess = call(worker, &quot;Worker.DoJob&quot;, jobArgs, &amp;reply)</div><div class=\"line\">\t\t\t\tcase worker = &lt;-idleWorder:</div><div class=\"line\">\t\t\t\t\tjobArgs := DoJobArgs&#123;File: mr.file, Operation: Reduce, JobNumber: reduceN, NumOtherPhase: mr.nMap&#125;</div><div class=\"line\">\t\t\t\t\tvar reply DoJobReply</div><div class=\"line\">\t\t\t\t\tsuccess = call(worker, &quot;Worker.DoJob&quot;, jobArgs, &amp;reply)</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tif success &#123;</div><div class=\"line\">\t\t\t\t\treduceChan &lt;- reduceN</div><div class=\"line\">\t\t\t\t\tidleWorder &lt;- worker</div><div class=\"line\">\t\t\t\t\treturn</div><div class=\"line\">\t\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\t\tdelete(mr.Workers, worker)</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;(i)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tfmt.Println(&quot;waiting for reduce done!&quot;)</div><div class=\"line\">\tfor i := 0; i &lt; mr.nReduce; i++ &#123;</div><div class=\"line\">\t\t&lt;-reduceChan</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tfmt.Println(&quot;reduce done with living worker&quot;, len(mr.Workers))</div><div class=\"line\">\t// consume idle workers...</div><div class=\"line\">\tfor i := 0; i &lt; len(mr.Workers); i++ &#123;</div><div class=\"line\">\t\tfmt.Println(&lt;-idleWorder)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn mr.KillWorkers()</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<blockquote>\n<p>本文开始，主要对mit的Distributed Systems课程的实验进行完成。课程网址在<a href=\"http://nil.csail.mit.edu/6.824/2015/index.html\">这里</a></p>\n</blockquote>\n<ul>\n<li>本章是lab 1的实验</li>\n</ul>\n<h1 id=\"Part-1：Word-Count\"><a href=\"#Part-1：Word-Count\" class=\"headerlink\" title=\"Part 1：Word Count\"></a>Part 1：Word Count</h1><p>第一部分的实验是在给定代码上实现一个wordcount程序，只需要完成 main/wc.go下面的Map和Reduce函数即可。<br>Map阶段将传入的句子（value）分割成各个单词然后使用提供的KeyValue结构存储到List中，Key为单词，value为1表示单词出现的次数。<br>Reduce将给每个单词计数，最终得到整个文本的单词计数。</p>\n<p>运行命令为<code>go run wc.go master kjv12.txt sequential</code>, 也可以直接<code>sh ./test-wc.sh</code>运行并检验结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">func Map(value string) *list.List &#123;</div><div class=\"line\">\tf := func(c rune) bool &#123;</div><div class=\"line\">\t\treturn !unicode.IsLetter(c)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\twords := strings.FieldsFunc(value, f)</div><div class=\"line\">\tstream := list.New()</div><div class=\"line\">\tfor _, word := range words &#123;</div><div class=\"line\">\t\tstream.PushBack(mapreduce.KeyValue&#123;Key: word, Value: &quot;1&quot;&#125;)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn stream</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func Reduce(key string, values *list.List) string &#123;</div><div class=\"line\">\tcount := 0</div><div class=\"line\">\tfor e := values.Front(); e != nil; e = e.Next() &#123;</div><div class=\"line\">\t\tc, _ := strconv.Atoi(e.Value.(string))</div><div class=\"line\">\t\tcount += c</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn strconv.Itoa(count)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h1 id=\"Part-2-amp-3-Distributing-MapReduce-jobs-amp-Handling-worker-failures\"><a href=\"#Part-2-amp-3-Distributing-MapReduce-jobs-amp-Handling-worker-failures\" class=\"headerlink\" title=\"Part 2&amp;3: Distributing MapReduce jobs &amp; Handling worker failures\"></a>Part 2&amp;3: Distributing MapReduce jobs &amp; Handling worker failures</h1><p>第一部分只是在本地模拟MR实现，这一部分抽象成Master/Client模式运行MR程序，server端主要负责切分作业并下发以及最终结果的收集合并，client负责具体的map/reduce任务。并且，需要处理client端发生错误时的应对措施。</p>\n<p>主要实现mapreduce/master.go中的RunMaster方法，具体做法是使用select从registerChannel中得到新注册的worker，并通过rpc给它们分配任务。worker完成分配的任务后master可以继续下发新任务。如果发生错误，则从server端将这个worker排除在可以重复工作的worker外。<br>任务分两个阶段，map和reduce，map任务下发完后需要先等待所有map任务全部完成后再开始进行reduce任务。<br>在reduce阶段完全结束后再告知worker端结束工作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div></pre></td><td class=\"code\"><pre><div class=\"line\">func (mr *MapReduce) RunMaster() *list.List &#123;</div><div class=\"line\">\t// Your code here</div><div class=\"line\">\tidleWorder := make(chan string)</div><div class=\"line\">\tmapChan := make(chan int)</div><div class=\"line\">\treduceChan := make(chan int)</div><div class=\"line\">\tfor i := 0; i &lt; mr.nMap; i++ &#123;</div><div class=\"line\">\t\tgo func(mapN int) &#123;</div><div class=\"line\">\t\t\tfor &#123;</div><div class=\"line\">\t\t\t\tvar worker string</div><div class=\"line\">\t\t\t\tsuccess := false</div><div class=\"line\">\t\t\t\tselect &#123;</div><div class=\"line\">\t\t\t\tcase worker = &lt;-mr.registerChannel:</div><div class=\"line\">\t\t\t\t\tmr.Workers[worker] = &amp;WorkerInfo&#123;address: worker&#125;</div><div class=\"line\">\t\t\t\t\tjobArgs := DoJobArgs&#123;File: mr.file, Operation: Map, JobNumber: mapN, NumOtherPhase: mr.nReduce&#125;</div><div class=\"line\">\t\t\t\t\tvar reply DoJobReply</div><div class=\"line\">\t\t\t\t\tsuccess = call(worker, &quot;Worker.DoJob&quot;, jobArgs, &amp;reply)</div><div class=\"line\">\t\t\t\tcase worker = &lt;-idleWorder:</div><div class=\"line\">\t\t\t\t\tjobArgs := DoJobArgs&#123;File: mr.file, Operation: Map, JobNumber: mapN, NumOtherPhase: mr.nReduce&#125;</div><div class=\"line\">\t\t\t\t\tvar reply DoJobReply</div><div class=\"line\">\t\t\t\t\tsuccess = call(worker, &quot;Worker.DoJob&quot;, jobArgs, &amp;reply)</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tif success &#123;</div><div class=\"line\">\t\t\t\t\tmapChan &lt;- mapN</div><div class=\"line\">\t\t\t\t\tidleWorder &lt;- worker</div><div class=\"line\">\t\t\t\t\treturn</div><div class=\"line\">\t\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\t\tdelete(mr.Workers, worker)</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;(i)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tfor i := 0; i &lt; mr.nMap; i++ &#123;</div><div class=\"line\">\t\t&lt;-mapChan</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tfor i := 0; i &lt; mr.nReduce; i++ &#123;</div><div class=\"line\">\t\tgo func(reduceN int) &#123;</div><div class=\"line\">\t\t\tfor &#123;</div><div class=\"line\">\t\t\t\tvar worker string</div><div class=\"line\">\t\t\t\tsuccess := false</div><div class=\"line\">\t\t\t\tselect &#123;</div><div class=\"line\">\t\t\t\tcase worker = &lt;-mr.registerChannel:</div><div class=\"line\">\t\t\t\t\tmr.Workers[worker] = &amp;WorkerInfo&#123;address: worker&#125;</div><div class=\"line\">\t\t\t\t\tjobArgs := DoJobArgs&#123;File: mr.file, Operation: Reduce, JobNumber: reduceN, NumOtherPhase: mr.nMap&#125;</div><div class=\"line\">\t\t\t\t\tvar reply DoJobReply</div><div class=\"line\">\t\t\t\t\tsuccess = call(worker, &quot;Worker.DoJob&quot;, jobArgs, &amp;reply)</div><div class=\"line\">\t\t\t\tcase worker = &lt;-idleWorder:</div><div class=\"line\">\t\t\t\t\tjobArgs := DoJobArgs&#123;File: mr.file, Operation: Reduce, JobNumber: reduceN, NumOtherPhase: mr.nMap&#125;</div><div class=\"line\">\t\t\t\t\tvar reply DoJobReply</div><div class=\"line\">\t\t\t\t\tsuccess = call(worker, &quot;Worker.DoJob&quot;, jobArgs, &amp;reply)</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t\tif success &#123;</div><div class=\"line\">\t\t\t\t\treduceChan &lt;- reduceN</div><div class=\"line\">\t\t\t\t\tidleWorder &lt;- worker</div><div class=\"line\">\t\t\t\t\treturn</div><div class=\"line\">\t\t\t\t&#125; else &#123;</div><div class=\"line\">\t\t\t\t\tdelete(mr.Workers, worker)</div><div class=\"line\">\t\t\t\t&#125;</div><div class=\"line\">\t\t\t&#125;</div><div class=\"line\">\t\t&#125;(i)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tfmt.Println(&quot;waiting for reduce done!&quot;)</div><div class=\"line\">\tfor i := 0; i &lt; mr.nReduce; i++ &#123;</div><div class=\"line\">\t\t&lt;-reduceChan</div><div class=\"line\">\t&#125;</div><div class=\"line\">\tfmt.Println(&quot;reduce done with living worker&quot;, len(mr.Workers))</div><div class=\"line\">\t// consume idle workers...</div><div class=\"line\">\tfor i := 0; i &lt; len(mr.Workers); i++ &#123;</div><div class=\"line\">\t\tfmt.Println(&lt;-idleWorder)</div><div class=\"line\">\t&#125;</div><div class=\"line\">\treturn mr.KillWorkers()</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"title":"iptables quick start","date":"2017-03-30T09:51:32.000Z","_content":"\n# 简介\n\nlinux内置了一个强大的防火墙模块，称为iptables。用户通过在用户态操作iptables规则，可以使流量在内核态进行规则的匹配过滤。\n\nMan手册中关于iptables的介绍为用于包过滤和NAT的系统工具。\n\niptables的规则可以从两个角度看。从功能上看，iptables分为多个已经定义好的table，每个table有自己的作用。从对包的操作流水线来看，iptables又是有各个CHAIN组成的。包在内核中游走的各个阶段分别会进入不同的CHAIN进行规则匹配操作。\n\niptables包含了预先定义好的5个table: filter, nat, mangle, raw, security. 比较常见的是前3个table。用户无法增加新的table\n\n1. filter: 这是默认用户在没有指定操作table时会操作的table。它包含了内置的INPUT, FORWARD, OUTPUT表。主要用于包过滤\n2. nat: 这张表的作用主要是对连接进行NAT，包括SNAT和DNAT。它包含了内置的PREROUTING, OUTPUT, POSTROUTING表。\n3. mangle: 主要用于对包内容的修改！例如进行mark！它包含了所有内置的CHAIN\n\niptables的各个table由各个CHAIN组成，内置了5个CHAIN在包游走的各个阶段使用CHAIN中的规则进行过滤操作。\n\n1. PREROUTING chain: 这个chain在包进入主机且没有在本机进行路由决策之前进行规则匹配。通常可以在这里进行DNAT, 例如访问docker容器\n2. INPUT chain: 经过本机路由决策后如果判定包是给本机的，则在包进入用户空间被进程处理之前会进过INPUT chain。\n3. FORWARD chain: 经过本机路由决策后发现需要路由到其他地方的，则进入该chain处理\n4. OUTPUT chain: 用户空间发出的包在进入内核后首先经过这个chain的处理\n5. POSTROUTING chain: 经过路由决策后需要发出去的包会经过该chain，可以在这里进行SNAT\n\n具体的流程如下图所示\n![kubelet](/images/iptables-chain.png)\n\n除了内置的5个CHAIN，用户还可以创建自己的CHAIN进行扩展。\n\n# 基本命令\n\n1. `iptables [-t table] {-A|-C|-D} chain rule-specification`\n\t-A表示在末尾append一条规则\n\t-C表示check规则存不存在\n\t-D表示删除一条规则\n2. `iptables [-t table] -I chain [rulenum] rule-specification`\n\t在第rulenum条规则前insert一条规则，默认为1，表示加在最开头\n\n3. `iptables [-t table] -R chain rulenum rule-specification`\n\treplace规则\n\n4. `iptables [-t table] -D chain rulenum`\n\tdelete一条规则\n\n5. `iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options...]`\n\t-L表示list规则\n\t-F表示清空规则\n\t-Z表示清空包计数\n\n6. `iptables [-t table] -N chain`\n\t新建一个chain\n\n7. `iptables [-t table] -X [chain]`\n\t删除用户定义的chain\n\n8. `iptables [-t table] -P chain target`\n\t设置默认的policy，target必须是ACCEPT或者DROP\n\n9. `iptables [-t table] -E old-chain-name new-chain-name`\n\t重命名chain\n\n其中：\n\n```\nrule-specification = [matches...] [target]\nmatch = -m matchname [per-match-options]\ntarget = -j targetname [per-target-options]\n\n内置的targetname有ACCEPT和DROP\n```\n\n新增规则可以跟上以下参数\n```\n[!] -p, --protocol protocol 根据协议匹配,tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh\n[!] -s, --source address[/mask][,...] 源地址匹配\n[!] -d, --destination address[/mask][,...] 目的地址匹配\n-m, --match match 根据扩展模块进行匹配，后文说明\n-j, --jump target 使用target进行处理，如ACCEPT，DROP，或者其他扩展的target如REJECT，SNAT，DNAT等。也可以进入用户自定义的chain中\n-g, --goto chain 与-j类似，区别在于如果从chain回来，则不会继续在当前chain继续往下匹配而是return到上一层\n[!] -i, --in-interface name 匹配入口网卡，如果name后面跟上+号，匹配所有前缀\n[!] -o, --out-interface name 匹配出口网卡\n[!] -f, --fragment 匹配非第一个ipv4分片\n-c, --set-counters packets bytes 设置计数\n--line-numbers 在列出规则时，可以显示rulenumber\n```\n\n以上就是iptables的基本用法了。\n核心的iptables主要进行ACCEPT和DROP的工作，如果需要使用高级的功能，需要使用iptables的扩展模块。扩展模块对规则的匹配进行了扩展（使用-m match），对匹配规则的目标作用也进行了扩展，可以进行NAT等工作。\n\n# 扩展\n\n## 匹配扩展\n\naddrtype\n\t! --src-type type\n\t! --dst-type type\n\ttype->[LOCAL, BROADCAST, BLACKHOLE, ]\n\ncgroup\n\t! --cgroup fwid\n\tfwid 是被 cgroup net-cls 设置的\n\t例子：iptables -A OUTPUT -p tcp --sport 80 -m cgroup ! --cgroup 1 -j DROP\n\nmultiport\n\t! --sports|dports|ports port[,port|port:port]\n\nset\n\t[!] --match-set setname flag[,flag]\n\t--return-nomatch\n\t匹配ip集合，这个集合可以从ipset命令看到。在calico网络中就用到了这种匹配方式\n\t例子：iptables -A FORWARD -m set --match-set test src,dst\n\nstate\n\tstate [state]\n\tstate->[INVALID,  ESTABLISHED, NEW, RELATED or UNTRACKED]\n\nstring\n\talgo [BM|KMP]\n\tfrom [offset]\n\tto [offset]\n\tstring [str]\n\thex-string [str]\n\ticase\n\ntcp\n\t! --sport|dport port[:port]\n\t! --tcp-option number\n\t! --tcp-flags mask comp  mask为需要检查的flags，comp为需要检查的flags中哪些被设置，flags有[SYN ACK FIN RST URG PSH ALL NONE]. 例如`iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST SYN`\n\t! --syn 与`--tcp-flags SYN,RST,ACK,FIN SYN`等效\n\t当指定-p tcp时使用\n\ntcpmss\n\tmss val[:val]\n\t匹配tcp的mss范围\n\ntos\n\t! tos val[/mask]\n\t! --tos symbol\n\t匹配tos字段\n\nudp\n\t--sport|dport port[:port]\n\t当指定-p udp时使用\n\n## 目标扩展\n\nCONNMARK\n\t--set-xmark value[/mask]\n\nDNAT [nat,PREROUTING,OUTPUT]\n\t--to-destination [ip][:port]\n\t修改目的ip\n\nMARK\n\t--set-xmark value[/mask]\n\t--set-mark value[/mask]\n\nMASQUERADE [nat,POSTROUTING]\n\t--to-ports port\n\t修改源ip地址, 主要用于主机ip会变化的情况。一般使用SNAT\n\nREDIRECT [nat,PREROUTING,OUTPUT]\n\t--to-ports port[-port]\n\t重定向到本机地址如127.0.0.1\n\nREJECT [INPUT, FORWARD and OUTPUT]\n\t--reject-with type\n\ttype -> [icmp-net-unreachable, icmp-host-unreachable, icmp-port-unreachable, icmp-proto-unreachable, icmp-net-prohibited, icmp-host-prohibited, or icmp-admin-prohibited]\n\t类似于DROP，但是会像请求方返回一个应答而不是不相应\n\nSNAT [nat, POSTROUTING, INPUT]\n\t--to-source [ipaddr[-ipaddr]][:port[-port]]\n\nTOS [mangle]\n\t--set-tos value[/mask]\n\t--set-tos symbol\n\t设置tos字段\n\nTRACE\n\t标记连接，之后每条匹配的rule都会被log\n\n","source":"_posts/2017-03-30-iptables-quick-start.md","raw":"---\ntitle: iptables quick start\ndate: 2017-03-30 17:51:32\ntags: [network]\n---\n\n# 简介\n\nlinux内置了一个强大的防火墙模块，称为iptables。用户通过在用户态操作iptables规则，可以使流量在内核态进行规则的匹配过滤。\n\nMan手册中关于iptables的介绍为用于包过滤和NAT的系统工具。\n\niptables的规则可以从两个角度看。从功能上看，iptables分为多个已经定义好的table，每个table有自己的作用。从对包的操作流水线来看，iptables又是有各个CHAIN组成的。包在内核中游走的各个阶段分别会进入不同的CHAIN进行规则匹配操作。\n\niptables包含了预先定义好的5个table: filter, nat, mangle, raw, security. 比较常见的是前3个table。用户无法增加新的table\n\n1. filter: 这是默认用户在没有指定操作table时会操作的table。它包含了内置的INPUT, FORWARD, OUTPUT表。主要用于包过滤\n2. nat: 这张表的作用主要是对连接进行NAT，包括SNAT和DNAT。它包含了内置的PREROUTING, OUTPUT, POSTROUTING表。\n3. mangle: 主要用于对包内容的修改！例如进行mark！它包含了所有内置的CHAIN\n\niptables的各个table由各个CHAIN组成，内置了5个CHAIN在包游走的各个阶段使用CHAIN中的规则进行过滤操作。\n\n1. PREROUTING chain: 这个chain在包进入主机且没有在本机进行路由决策之前进行规则匹配。通常可以在这里进行DNAT, 例如访问docker容器\n2. INPUT chain: 经过本机路由决策后如果判定包是给本机的，则在包进入用户空间被进程处理之前会进过INPUT chain。\n3. FORWARD chain: 经过本机路由决策后发现需要路由到其他地方的，则进入该chain处理\n4. OUTPUT chain: 用户空间发出的包在进入内核后首先经过这个chain的处理\n5. POSTROUTING chain: 经过路由决策后需要发出去的包会经过该chain，可以在这里进行SNAT\n\n具体的流程如下图所示\n![kubelet](/images/iptables-chain.png)\n\n除了内置的5个CHAIN，用户还可以创建自己的CHAIN进行扩展。\n\n# 基本命令\n\n1. `iptables [-t table] {-A|-C|-D} chain rule-specification`\n\t-A表示在末尾append一条规则\n\t-C表示check规则存不存在\n\t-D表示删除一条规则\n2. `iptables [-t table] -I chain [rulenum] rule-specification`\n\t在第rulenum条规则前insert一条规则，默认为1，表示加在最开头\n\n3. `iptables [-t table] -R chain rulenum rule-specification`\n\treplace规则\n\n4. `iptables [-t table] -D chain rulenum`\n\tdelete一条规则\n\n5. `iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options...]`\n\t-L表示list规则\n\t-F表示清空规则\n\t-Z表示清空包计数\n\n6. `iptables [-t table] -N chain`\n\t新建一个chain\n\n7. `iptables [-t table] -X [chain]`\n\t删除用户定义的chain\n\n8. `iptables [-t table] -P chain target`\n\t设置默认的policy，target必须是ACCEPT或者DROP\n\n9. `iptables [-t table] -E old-chain-name new-chain-name`\n\t重命名chain\n\n其中：\n\n```\nrule-specification = [matches...] [target]\nmatch = -m matchname [per-match-options]\ntarget = -j targetname [per-target-options]\n\n内置的targetname有ACCEPT和DROP\n```\n\n新增规则可以跟上以下参数\n```\n[!] -p, --protocol protocol 根据协议匹配,tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh\n[!] -s, --source address[/mask][,...] 源地址匹配\n[!] -d, --destination address[/mask][,...] 目的地址匹配\n-m, --match match 根据扩展模块进行匹配，后文说明\n-j, --jump target 使用target进行处理，如ACCEPT，DROP，或者其他扩展的target如REJECT，SNAT，DNAT等。也可以进入用户自定义的chain中\n-g, --goto chain 与-j类似，区别在于如果从chain回来，则不会继续在当前chain继续往下匹配而是return到上一层\n[!] -i, --in-interface name 匹配入口网卡，如果name后面跟上+号，匹配所有前缀\n[!] -o, --out-interface name 匹配出口网卡\n[!] -f, --fragment 匹配非第一个ipv4分片\n-c, --set-counters packets bytes 设置计数\n--line-numbers 在列出规则时，可以显示rulenumber\n```\n\n以上就是iptables的基本用法了。\n核心的iptables主要进行ACCEPT和DROP的工作，如果需要使用高级的功能，需要使用iptables的扩展模块。扩展模块对规则的匹配进行了扩展（使用-m match），对匹配规则的目标作用也进行了扩展，可以进行NAT等工作。\n\n# 扩展\n\n## 匹配扩展\n\naddrtype\n\t! --src-type type\n\t! --dst-type type\n\ttype->[LOCAL, BROADCAST, BLACKHOLE, ]\n\ncgroup\n\t! --cgroup fwid\n\tfwid 是被 cgroup net-cls 设置的\n\t例子：iptables -A OUTPUT -p tcp --sport 80 -m cgroup ! --cgroup 1 -j DROP\n\nmultiport\n\t! --sports|dports|ports port[,port|port:port]\n\nset\n\t[!] --match-set setname flag[,flag]\n\t--return-nomatch\n\t匹配ip集合，这个集合可以从ipset命令看到。在calico网络中就用到了这种匹配方式\n\t例子：iptables -A FORWARD -m set --match-set test src,dst\n\nstate\n\tstate [state]\n\tstate->[INVALID,  ESTABLISHED, NEW, RELATED or UNTRACKED]\n\nstring\n\talgo [BM|KMP]\n\tfrom [offset]\n\tto [offset]\n\tstring [str]\n\thex-string [str]\n\ticase\n\ntcp\n\t! --sport|dport port[:port]\n\t! --tcp-option number\n\t! --tcp-flags mask comp  mask为需要检查的flags，comp为需要检查的flags中哪些被设置，flags有[SYN ACK FIN RST URG PSH ALL NONE]. 例如`iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST SYN`\n\t! --syn 与`--tcp-flags SYN,RST,ACK,FIN SYN`等效\n\t当指定-p tcp时使用\n\ntcpmss\n\tmss val[:val]\n\t匹配tcp的mss范围\n\ntos\n\t! tos val[/mask]\n\t! --tos symbol\n\t匹配tos字段\n\nudp\n\t--sport|dport port[:port]\n\t当指定-p udp时使用\n\n## 目标扩展\n\nCONNMARK\n\t--set-xmark value[/mask]\n\nDNAT [nat,PREROUTING,OUTPUT]\n\t--to-destination [ip][:port]\n\t修改目的ip\n\nMARK\n\t--set-xmark value[/mask]\n\t--set-mark value[/mask]\n\nMASQUERADE [nat,POSTROUTING]\n\t--to-ports port\n\t修改源ip地址, 主要用于主机ip会变化的情况。一般使用SNAT\n\nREDIRECT [nat,PREROUTING,OUTPUT]\n\t--to-ports port[-port]\n\t重定向到本机地址如127.0.0.1\n\nREJECT [INPUT, FORWARD and OUTPUT]\n\t--reject-with type\n\ttype -> [icmp-net-unreachable, icmp-host-unreachable, icmp-port-unreachable, icmp-proto-unreachable, icmp-net-prohibited, icmp-host-prohibited, or icmp-admin-prohibited]\n\t类似于DROP，但是会像请求方返回一个应答而不是不相应\n\nSNAT [nat, POSTROUTING, INPUT]\n\t--to-source [ipaddr[-ipaddr]][:port[-port]]\n\nTOS [mangle]\n\t--set-tos value[/mask]\n\t--set-tos symbol\n\t设置tos字段\n\nTRACE\n\t标记连接，之后每条匹配的rule都会被log\n\n","slug":"iptables-quick-start","published":1,"updated":"2017-03-30T13:06:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asaqi20015phv9906lxl5y","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>linux内置了一个强大的防火墙模块，称为iptables。用户通过在用户态操作iptables规则，可以使流量在内核态进行规则的匹配过滤。</p>\n<p>Man手册中关于iptables的介绍为用于包过滤和NAT的系统工具。</p>\n<p>iptables的规则可以从两个角度看。从功能上看，iptables分为多个已经定义好的table，每个table有自己的作用。从对包的操作流水线来看，iptables又是有各个CHAIN组成的。包在内核中游走的各个阶段分别会进入不同的CHAIN进行规则匹配操作。</p>\n<p>iptables包含了预先定义好的5个table: filter, nat, mangle, raw, security. 比较常见的是前3个table。用户无法增加新的table</p>\n<ol>\n<li>filter: 这是默认用户在没有指定操作table时会操作的table。它包含了内置的INPUT, FORWARD, OUTPUT表。主要用于包过滤</li>\n<li>nat: 这张表的作用主要是对连接进行NAT，包括SNAT和DNAT。它包含了内置的PREROUTING, OUTPUT, POSTROUTING表。</li>\n<li>mangle: 主要用于对包内容的修改！例如进行mark！它包含了所有内置的CHAIN</li>\n</ol>\n<p>iptables的各个table由各个CHAIN组成，内置了5个CHAIN在包游走的各个阶段使用CHAIN中的规则进行过滤操作。</p>\n<ol>\n<li>PREROUTING chain: 这个chain在包进入主机且没有在本机进行路由决策之前进行规则匹配。通常可以在这里进行DNAT, 例如访问docker容器</li>\n<li>INPUT chain: 经过本机路由决策后如果判定包是给本机的，则在包进入用户空间被进程处理之前会进过INPUT chain。</li>\n<li>FORWARD chain: 经过本机路由决策后发现需要路由到其他地方的，则进入该chain处理</li>\n<li>OUTPUT chain: 用户空间发出的包在进入内核后首先经过这个chain的处理</li>\n<li>POSTROUTING chain: 经过路由决策后需要发出去的包会经过该chain，可以在这里进行SNAT</li>\n</ol>\n<p>具体的流程如下图所示<br><img src=\"/images/iptables-chain.png\" alt=\"kubelet\"></p>\n<p>除了内置的5个CHAIN，用户还可以创建自己的CHAIN进行扩展。</p>\n<h1 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h1><ol>\n<li><code>iptables [-t table] {-A|-C|-D} chain rule-specification</code><br> -A表示在末尾append一条规则<br> -C表示check规则存不存在<br> -D表示删除一条规则</li>\n<li><p><code>iptables [-t table] -I chain [rulenum] rule-specification</code><br> 在第rulenum条规则前insert一条规则，默认为1，表示加在最开头</p>\n</li>\n<li><p><code>iptables [-t table] -R chain rulenum rule-specification</code><br> replace规则</p>\n</li>\n<li><p><code>iptables [-t table] -D chain rulenum</code><br> delete一条规则</p>\n</li>\n<li><p><code>iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options...]</code><br> -L表示list规则<br> -F表示清空规则<br> -Z表示清空包计数</p>\n</li>\n<li><p><code>iptables [-t table] -N chain</code><br> 新建一个chain</p>\n</li>\n<li><p><code>iptables [-t table] -X [chain]</code><br> 删除用户定义的chain</p>\n</li>\n<li><p><code>iptables [-t table] -P chain target</code><br> 设置默认的policy，target必须是ACCEPT或者DROP</p>\n</li>\n<li><p><code>iptables [-t table] -E old-chain-name new-chain-name</code><br> 重命名chain</p>\n</li>\n</ol>\n<p>其中：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">rule-specification = [matches...] [target]</div><div class=\"line\">match = -m matchname [per-match-options]</div><div class=\"line\">target = -j targetname [per-target-options]</div><div class=\"line\"></div><div class=\"line\">内置的targetname有ACCEPT和DROP</div></pre></td></tr></table></figure>\n<p>新增规则可以跟上以下参数<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">[!] -p, --protocol protocol 根据协议匹配,tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh</div><div class=\"line\">[!] -s, --source address[/mask][,...] 源地址匹配</div><div class=\"line\">[!] -d, --destination address[/mask][,...] 目的地址匹配</div><div class=\"line\">-m, --match match 根据扩展模块进行匹配，后文说明</div><div class=\"line\">-j, --jump target 使用target进行处理，如ACCEPT，DROP，或者其他扩展的target如REJECT，SNAT，DNAT等。也可以进入用户自定义的chain中</div><div class=\"line\">-g, --goto chain 与-j类似，区别在于如果从chain回来，则不会继续在当前chain继续往下匹配而是return到上一层</div><div class=\"line\">[!] -i, --in-interface name 匹配入口网卡，如果name后面跟上+号，匹配所有前缀</div><div class=\"line\">[!] -o, --out-interface name 匹配出口网卡</div><div class=\"line\">[!] -f, --fragment 匹配非第一个ipv4分片</div><div class=\"line\">-c, --set-counters packets bytes 设置计数</div><div class=\"line\">--line-numbers 在列出规则时，可以显示rulenumber</div></pre></td></tr></table></figure></p>\n<p>以上就是iptables的基本用法了。<br>核心的iptables主要进行ACCEPT和DROP的工作，如果需要使用高级的功能，需要使用iptables的扩展模块。扩展模块对规则的匹配进行了扩展（使用-m match），对匹配规则的目标作用也进行了扩展，可以进行NAT等工作。</p>\n<h1 id=\"扩展\"><a href=\"#扩展\" class=\"headerlink\" title=\"扩展\"></a>扩展</h1><h2 id=\"匹配扩展\"><a href=\"#匹配扩展\" class=\"headerlink\" title=\"匹配扩展\"></a>匹配扩展</h2><p>addrtype<br>    ! –src-type type<br>    ! –dst-type type<br>    type-&gt;[LOCAL, BROADCAST, BLACKHOLE, ]</p>\n<p>cgroup<br>    ! –cgroup fwid<br>    fwid 是被 cgroup net-cls 设置的<br>    例子：iptables -A OUTPUT -p tcp –sport 80 -m cgroup ! –cgroup 1 -j DROP</p>\n<p>multiport<br>    ! –sports|dports|ports port[,port|port:port]</p>\n<p>set<br>    [!] –match-set setname flag[,flag]<br>    –return-nomatch<br>    匹配ip集合，这个集合可以从ipset命令看到。在calico网络中就用到了这种匹配方式<br>    例子：iptables -A FORWARD -m set –match-set test src,dst</p>\n<p>state<br>    state [state]<br>    state-&gt;[INVALID,  ESTABLISHED, NEW, RELATED or UNTRACKED]</p>\n<p>string<br>    algo [BM|KMP]<br>    from [offset]<br>    to [offset]<br>    string [str]<br>    hex-string [str]<br>    icase</p>\n<p>tcp<br>    ! –sport|dport port[:port]<br>    ! –tcp-option number<br>    ! –tcp-flags mask comp  mask为需要检查的flags，comp为需要检查的flags中哪些被设置，flags有[SYN ACK FIN RST URG PSH ALL NONE]. 例如<code>iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST SYN</code><br>    ! –syn 与<code>--tcp-flags SYN,RST,ACK,FIN SYN</code>等效<br>    当指定-p tcp时使用</p>\n<p>tcpmss<br>    mss val[:val]<br>    匹配tcp的mss范围</p>\n<p>tos<br>    ! tos val[/mask]<br>    ! –tos symbol<br>    匹配tos字段</p>\n<p>udp<br>    –sport|dport port[:port]<br>    当指定-p udp时使用</p>\n<h2 id=\"目标扩展\"><a href=\"#目标扩展\" class=\"headerlink\" title=\"目标扩展\"></a>目标扩展</h2><p>CONNMARK<br>    –set-xmark value[/mask]</p>\n<p>DNAT [nat,PREROUTING,OUTPUT]<br>    –to-destination [ip][:port]<br>    修改目的ip</p>\n<p>MARK<br>    –set-xmark value[/mask]<br>    –set-mark value[/mask]</p>\n<p>MASQUERADE [nat,POSTROUTING]<br>    –to-ports port<br>    修改源ip地址, 主要用于主机ip会变化的情况。一般使用SNAT</p>\n<p>REDIRECT [nat,PREROUTING,OUTPUT]<br>    –to-ports port[-port]<br>    重定向到本机地址如127.0.0.1</p>\n<p>REJECT [INPUT, FORWARD and OUTPUT]<br>    –reject-with type<br>    type -&gt; [icmp-net-unreachable, icmp-host-unreachable, icmp-port-unreachable, icmp-proto-unreachable, icmp-net-prohibited, icmp-host-prohibited, or icmp-admin-prohibited]<br>    类似于DROP，但是会像请求方返回一个应答而不是不相应</p>\n<p>SNAT [nat, POSTROUTING, INPUT]<br>    –to-source [ipaddr[-ipaddr]][:port[-port]]</p>\n<p>TOS [mangle]<br>    –set-tos value[/mask]<br>    –set-tos symbol<br>    设置tos字段</p>\n<p>TRACE<br>    标记连接，之后每条匹配的rule都会被log</p>\n","excerpt":"","more":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>linux内置了一个强大的防火墙模块，称为iptables。用户通过在用户态操作iptables规则，可以使流量在内核态进行规则的匹配过滤。</p>\n<p>Man手册中关于iptables的介绍为用于包过滤和NAT的系统工具。</p>\n<p>iptables的规则可以从两个角度看。从功能上看，iptables分为多个已经定义好的table，每个table有自己的作用。从对包的操作流水线来看，iptables又是有各个CHAIN组成的。包在内核中游走的各个阶段分别会进入不同的CHAIN进行规则匹配操作。</p>\n<p>iptables包含了预先定义好的5个table: filter, nat, mangle, raw, security. 比较常见的是前3个table。用户无法增加新的table</p>\n<ol>\n<li>filter: 这是默认用户在没有指定操作table时会操作的table。它包含了内置的INPUT, FORWARD, OUTPUT表。主要用于包过滤</li>\n<li>nat: 这张表的作用主要是对连接进行NAT，包括SNAT和DNAT。它包含了内置的PREROUTING, OUTPUT, POSTROUTING表。</li>\n<li>mangle: 主要用于对包内容的修改！例如进行mark！它包含了所有内置的CHAIN</li>\n</ol>\n<p>iptables的各个table由各个CHAIN组成，内置了5个CHAIN在包游走的各个阶段使用CHAIN中的规则进行过滤操作。</p>\n<ol>\n<li>PREROUTING chain: 这个chain在包进入主机且没有在本机进行路由决策之前进行规则匹配。通常可以在这里进行DNAT, 例如访问docker容器</li>\n<li>INPUT chain: 经过本机路由决策后如果判定包是给本机的，则在包进入用户空间被进程处理之前会进过INPUT chain。</li>\n<li>FORWARD chain: 经过本机路由决策后发现需要路由到其他地方的，则进入该chain处理</li>\n<li>OUTPUT chain: 用户空间发出的包在进入内核后首先经过这个chain的处理</li>\n<li>POSTROUTING chain: 经过路由决策后需要发出去的包会经过该chain，可以在这里进行SNAT</li>\n</ol>\n<p>具体的流程如下图所示<br><img src=\"/images/iptables-chain.png\" alt=\"kubelet\"></p>\n<p>除了内置的5个CHAIN，用户还可以创建自己的CHAIN进行扩展。</p>\n<h1 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h1><ol>\n<li><code>iptables [-t table] {-A|-C|-D} chain rule-specification</code><br> -A表示在末尾append一条规则<br> -C表示check规则存不存在<br> -D表示删除一条规则</li>\n<li><p><code>iptables [-t table] -I chain [rulenum] rule-specification</code><br> 在第rulenum条规则前insert一条规则，默认为1，表示加在最开头</p>\n</li>\n<li><p><code>iptables [-t table] -R chain rulenum rule-specification</code><br> replace规则</p>\n</li>\n<li><p><code>iptables [-t table] -D chain rulenum</code><br> delete一条规则</p>\n</li>\n<li><p><code>iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options...]</code><br> -L表示list规则<br> -F表示清空规则<br> -Z表示清空包计数</p>\n</li>\n<li><p><code>iptables [-t table] -N chain</code><br> 新建一个chain</p>\n</li>\n<li><p><code>iptables [-t table] -X [chain]</code><br> 删除用户定义的chain</p>\n</li>\n<li><p><code>iptables [-t table] -P chain target</code><br> 设置默认的policy，target必须是ACCEPT或者DROP</p>\n</li>\n<li><p><code>iptables [-t table] -E old-chain-name new-chain-name</code><br> 重命名chain</p>\n</li>\n</ol>\n<p>其中：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">rule-specification = [matches...] [target]</div><div class=\"line\">match = -m matchname [per-match-options]</div><div class=\"line\">target = -j targetname [per-target-options]</div><div class=\"line\"></div><div class=\"line\">内置的targetname有ACCEPT和DROP</div></pre></td></tr></table></figure>\n<p>新增规则可以跟上以下参数<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">[!] -p, --protocol protocol 根据协议匹配,tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh</div><div class=\"line\">[!] -s, --source address[/mask][,...] 源地址匹配</div><div class=\"line\">[!] -d, --destination address[/mask][,...] 目的地址匹配</div><div class=\"line\">-m, --match match 根据扩展模块进行匹配，后文说明</div><div class=\"line\">-j, --jump target 使用target进行处理，如ACCEPT，DROP，或者其他扩展的target如REJECT，SNAT，DNAT等。也可以进入用户自定义的chain中</div><div class=\"line\">-g, --goto chain 与-j类似，区别在于如果从chain回来，则不会继续在当前chain继续往下匹配而是return到上一层</div><div class=\"line\">[!] -i, --in-interface name 匹配入口网卡，如果name后面跟上+号，匹配所有前缀</div><div class=\"line\">[!] -o, --out-interface name 匹配出口网卡</div><div class=\"line\">[!] -f, --fragment 匹配非第一个ipv4分片</div><div class=\"line\">-c, --set-counters packets bytes 设置计数</div><div class=\"line\">--line-numbers 在列出规则时，可以显示rulenumber</div></pre></td></tr></table></figure></p>\n<p>以上就是iptables的基本用法了。<br>核心的iptables主要进行ACCEPT和DROP的工作，如果需要使用高级的功能，需要使用iptables的扩展模块。扩展模块对规则的匹配进行了扩展（使用-m match），对匹配规则的目标作用也进行了扩展，可以进行NAT等工作。</p>\n<h1 id=\"扩展\"><a href=\"#扩展\" class=\"headerlink\" title=\"扩展\"></a>扩展</h1><h2 id=\"匹配扩展\"><a href=\"#匹配扩展\" class=\"headerlink\" title=\"匹配扩展\"></a>匹配扩展</h2><p>addrtype<br>    ! –src-type type<br>    ! –dst-type type<br>    type-&gt;[LOCAL, BROADCAST, BLACKHOLE, ]</p>\n<p>cgroup<br>    ! –cgroup fwid<br>    fwid 是被 cgroup net-cls 设置的<br>    例子：iptables -A OUTPUT -p tcp –sport 80 -m cgroup ! –cgroup 1 -j DROP</p>\n<p>multiport<br>    ! –sports|dports|ports port[,port|port:port]</p>\n<p>set<br>    [!] –match-set setname flag[,flag]<br>    –return-nomatch<br>    匹配ip集合，这个集合可以从ipset命令看到。在calico网络中就用到了这种匹配方式<br>    例子：iptables -A FORWARD -m set –match-set test src,dst</p>\n<p>state<br>    state [state]<br>    state-&gt;[INVALID,  ESTABLISHED, NEW, RELATED or UNTRACKED]</p>\n<p>string<br>    algo [BM|KMP]<br>    from [offset]<br>    to [offset]<br>    string [str]<br>    hex-string [str]<br>    icase</p>\n<p>tcp<br>    ! –sport|dport port[:port]<br>    ! –tcp-option number<br>    ! –tcp-flags mask comp  mask为需要检查的flags，comp为需要检查的flags中哪些被设置，flags有[SYN ACK FIN RST URG PSH ALL NONE]. 例如<code>iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST SYN</code><br>    ! –syn 与<code>--tcp-flags SYN,RST,ACK,FIN SYN</code>等效<br>    当指定-p tcp时使用</p>\n<p>tcpmss<br>    mss val[:val]<br>    匹配tcp的mss范围</p>\n<p>tos<br>    ! tos val[/mask]<br>    ! –tos symbol<br>    匹配tos字段</p>\n<p>udp<br>    –sport|dport port[:port]<br>    当指定-p udp时使用</p>\n<h2 id=\"目标扩展\"><a href=\"#目标扩展\" class=\"headerlink\" title=\"目标扩展\"></a>目标扩展</h2><p>CONNMARK<br>    –set-xmark value[/mask]</p>\n<p>DNAT [nat,PREROUTING,OUTPUT]<br>    –to-destination [ip][:port]<br>    修改目的ip</p>\n<p>MARK<br>    –set-xmark value[/mask]<br>    –set-mark value[/mask]</p>\n<p>MASQUERADE [nat,POSTROUTING]<br>    –to-ports port<br>    修改源ip地址, 主要用于主机ip会变化的情况。一般使用SNAT</p>\n<p>REDIRECT [nat,PREROUTING,OUTPUT]<br>    –to-ports port[-port]<br>    重定向到本机地址如127.0.0.1</p>\n<p>REJECT [INPUT, FORWARD and OUTPUT]<br>    –reject-with type<br>    type -&gt; [icmp-net-unreachable, icmp-host-unreachable, icmp-port-unreachable, icmp-proto-unreachable, icmp-net-prohibited, icmp-host-prohibited, or icmp-admin-prohibited]<br>    类似于DROP，但是会像请求方返回一个应答而不是不相应</p>\n<p>SNAT [nat, POSTROUTING, INPUT]<br>    –to-source [ipaddr[-ipaddr]][:port[-port]]</p>\n<p>TOS [mangle]<br>    –set-tos value[/mask]<br>    –set-tos symbol<br>    设置tos字段</p>\n<p>TRACE<br>    标记连接，之后每条匹配的rule都会被log</p>\n"},{"layout":"post","title":"Golang笔记","_content":"\n1. Mac系统无法编译运行平台相关代码\n\n\t项目中引入了一个第三方包，有一个包下面的文件是 xxx_linux.go xxx_windows.go, 在Mac上无法通过编译。\n\t在编译之前加入GOOS=linux可以完成编译但是无法执行，需要在这类包中加入 xxx_(unix|darwin|unsupported).go，才可以在Mac上进行执行。\n\n2. 平台相关文件\n\n\t可以使用_(linux|unix|freebsd|unsupported)结尾表示在什么平台使用，也可以在文件的头部使用`// +build linux`著名特定平台。\n\t常见写法：\n\n\t```\n\t// +build arm64,darwin\n\t// +build !gccgo\n\t// +build darwin,!race linux,!race freebsd,!race netbsd openbsd solaris dragonfly\n\t// +build mips64 mips64le\n\t// +build !go1.2\n\t```\n\n\t详细可以查看 [go-build官网](https://golang.org/pkg/go/build/)\n\n","source":"_posts/2017-03-05-golang.markdown","raw":"---\nlayout: post\ntitle: Golang笔记\ncategory: lang\ntag: [lang, golang]\n---\n\n1. Mac系统无法编译运行平台相关代码\n\n\t项目中引入了一个第三方包，有一个包下面的文件是 xxx_linux.go xxx_windows.go, 在Mac上无法通过编译。\n\t在编译之前加入GOOS=linux可以完成编译但是无法执行，需要在这类包中加入 xxx_(unix|darwin|unsupported).go，才可以在Mac上进行执行。\n\n2. 平台相关文件\n\n\t可以使用_(linux|unix|freebsd|unsupported)结尾表示在什么平台使用，也可以在文件的头部使用`// +build linux`著名特定平台。\n\t常见写法：\n\n\t```\n\t// +build arm64,darwin\n\t// +build !gccgo\n\t// +build darwin,!race linux,!race freebsd,!race netbsd openbsd solaris dragonfly\n\t// +build mips64 mips64le\n\t// +build !go1.2\n\t```\n\n\t详细可以查看 [go-build官网](https://golang.org/pkg/go/build/)\n\n","slug":"golang","published":1,"date":"2017-03-04T16:00:00.000Z","updated":"2017-03-06T13:36:35.000Z","comments":1,"photos":[],"link":"","_id":"ck5asaqi30016phv9nr7hsyey","content":"<ol>\n<li><p>Mac系统无法编译运行平台相关代码</p>\n<p> 项目中引入了一个第三方包，有一个包下面的文件是 xxx_linux.go xxx<em>windows.go, 在Mac上无法通过编译。<br> 在编译之前加入GOOS=linux可以完成编译但是无法执行，需要在这类包中加入 xxx</em>(unix|darwin|unsupported).go，才可以在Mac上进行执行。</p>\n</li>\n<li><p>平台相关文件</p>\n<p> 可以使用_(linux|unix|freebsd|unsupported)结尾表示在什么平台使用，也可以在文件的头部使用<code>// +build linux</code>著名特定平台。<br> 常见写法：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">// +build arm64,darwin</div><div class=\"line\">// +build !gccgo</div><div class=\"line\">// +build darwin,!race linux,!race freebsd,!race netbsd openbsd solaris dragonfly</div><div class=\"line\">// +build mips64 mips64le</div><div class=\"line\">// +build !go1.2</div></pre></td></tr></table></figure>\n<p> 详细可以查看 <a href=\"https://golang.org/pkg/go/build/\" target=\"_blank\" rel=\"external\">go-build官网</a></p>\n</li>\n</ol>\n","excerpt":"","more":"<ol>\n<li><p>Mac系统无法编译运行平台相关代码</p>\n<p> 项目中引入了一个第三方包，有一个包下面的文件是 xxx_linux.go xxx<em>windows.go, 在Mac上无法通过编译。<br> 在编译之前加入GOOS=linux可以完成编译但是无法执行，需要在这类包中加入 xxx</em>(unix|darwin|unsupported).go，才可以在Mac上进行执行。</p>\n</li>\n<li><p>平台相关文件</p>\n<p> 可以使用_(linux|unix|freebsd|unsupported)结尾表示在什么平台使用，也可以在文件的头部使用<code>// +build linux</code>著名特定平台。<br> 常见写法：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">// +build arm64,darwin</div><div class=\"line\">// +build !gccgo</div><div class=\"line\">// +build darwin,!race linux,!race freebsd,!race netbsd openbsd solaris dragonfly</div><div class=\"line\">// +build mips64 mips64le</div><div class=\"line\">// +build !go1.2</div></pre></td></tr></table></figure>\n<p> 详细可以查看 <a href=\"https://golang.org/pkg/go/build/\">go-build官网</a></p>\n</li>\n</ol>\n"},{"title":"tcpdump quick start","date":"2017-03-07T11:41:31.000Z","_content":"\ntcpdump是linux上用于截获数据包的分析工具，提供了强大的包过滤和展示功能\n\ntcpdump的用法主要是`tcpdump [option] [expression]`\n\n## option\n\n-A\n以ASCII码方式展示数据包，不显示链路层header信息\n\n-c count\n指定tcpdump抓取count格数据包\n\n-e\n打印数据包的数据链路层header信息\n\n-F file\n以文件中的过滤表达式作为过滤条件\n\n-i interface\n监听网卡，使用any可以监听所有网卡。需要注意的是如果真实网络接口不能工作在'混杂'模式(promiscuous)下,则无法在'any'这个虚拟的网络接口上抓取其数据包？\n\n-l\n行缓冲输出，遇到换行符就输出\n\n-q\n简短的信息输出\n\n-r file\n从文件中读取包信息，如果file为-，则从标准输入中读取\n\n-t\n不打印时间戳\n\n-tt\n打印时间戳，秒数\n\n-ttt\n打印当前行和之前行的时间差\n\n-tttt\n打印时间戳，年月日形式\n\n-ttttt\n打印当前行和第一行的时间差\n\n-v\n当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.\n\n-vv\n产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.\n\n-vvv\n产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面,其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).\n\n-x\n打印每个包的头部数据，不打印链路层头部信息\n\n-xx\n在-x的基础上还打印了链路层的头部信息\n\n\n## expression\n\n除了以上参数，tcpdump还可以在命令最后加上包过滤表达式，之后这个表达式为True的包才会被打印。这个表达式可以用于过滤协议，ip，端口等包数据\n表达式是一个逻辑语句，可以用 and,or,not 连接。\n\n`[ip|arp|rarp|ip6] [dst|src] host host1` 目的地址/源地址是host1，可以是名字或者ip地址。没有dst/src表示源或者目的地址\n\n`ether [dst|src|host] ehost` 匹配以太网地址\n\n`[src|dst] port port1` 端口过滤\n\n`[tcp|udp] [src|dst] portrange port1-port2` 端口范围过滤\n\n`[greater|less] length` 数据包长度小于大于length\n\n`ip proto protocol` 协议过滤，如icmp6 igmp igrp udp tcp icmp等。由于udp tcp icmp在tcpdump中是关键字，需要用\\tcp来转义.\n\n`ip broadcast` 过滤广播数据\n\n`ip multicast` 过滤多播数据\n\n\n例子：\n`dst host 10.100.10.1 and (ip proto \\udp or src port 80)`\n\n`tcpdump -vvnneSs 0 -i veth_host host 192.168.84.193 and icmp`\n\n\n## 参考\n\n1. http://www.tcpdump.org/tcpdump_man.html\n\n2. http://www.tcpdump.org/manpages/pcap-filter.7.html\n","source":"_posts/2017-03-07-tcpdump-quick-start.md","raw":"---\ntitle: tcpdump quick start\ndate: 2017-03-07 19:41:31\ntags: [network, tcpdump]\n---\n\ntcpdump是linux上用于截获数据包的分析工具，提供了强大的包过滤和展示功能\n\ntcpdump的用法主要是`tcpdump [option] [expression]`\n\n## option\n\n-A\n以ASCII码方式展示数据包，不显示链路层header信息\n\n-c count\n指定tcpdump抓取count格数据包\n\n-e\n打印数据包的数据链路层header信息\n\n-F file\n以文件中的过滤表达式作为过滤条件\n\n-i interface\n监听网卡，使用any可以监听所有网卡。需要注意的是如果真实网络接口不能工作在'混杂'模式(promiscuous)下,则无法在'any'这个虚拟的网络接口上抓取其数据包？\n\n-l\n行缓冲输出，遇到换行符就输出\n\n-q\n简短的信息输出\n\n-r file\n从文件中读取包信息，如果file为-，则从标准输入中读取\n\n-t\n不打印时间戳\n\n-tt\n打印时间戳，秒数\n\n-ttt\n打印当前行和之前行的时间差\n\n-tttt\n打印时间戳，年月日形式\n\n-ttttt\n打印当前行和第一行的时间差\n\n-v\n当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.\n\n-vv\n产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.\n\n-vvv\n产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面,其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).\n\n-x\n打印每个包的头部数据，不打印链路层头部信息\n\n-xx\n在-x的基础上还打印了链路层的头部信息\n\n\n## expression\n\n除了以上参数，tcpdump还可以在命令最后加上包过滤表达式，之后这个表达式为True的包才会被打印。这个表达式可以用于过滤协议，ip，端口等包数据\n表达式是一个逻辑语句，可以用 and,or,not 连接。\n\n`[ip|arp|rarp|ip6] [dst|src] host host1` 目的地址/源地址是host1，可以是名字或者ip地址。没有dst/src表示源或者目的地址\n\n`ether [dst|src|host] ehost` 匹配以太网地址\n\n`[src|dst] port port1` 端口过滤\n\n`[tcp|udp] [src|dst] portrange port1-port2` 端口范围过滤\n\n`[greater|less] length` 数据包长度小于大于length\n\n`ip proto protocol` 协议过滤，如icmp6 igmp igrp udp tcp icmp等。由于udp tcp icmp在tcpdump中是关键字，需要用\\tcp来转义.\n\n`ip broadcast` 过滤广播数据\n\n`ip multicast` 过滤多播数据\n\n\n例子：\n`dst host 10.100.10.1 and (ip proto \\udp or src port 80)`\n\n`tcpdump -vvnneSs 0 -i veth_host host 192.168.84.193 and icmp`\n\n\n## 参考\n\n1. http://www.tcpdump.org/tcpdump_man.html\n\n2. http://www.tcpdump.org/manpages/pcap-filter.7.html\n","slug":"tcpdump-quick-start","published":1,"updated":"2017-03-16T12:47:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asaqie0018phv9kbenq27o","content":"<p>tcpdump是linux上用于截获数据包的分析工具，提供了强大的包过滤和展示功能</p>\n<p>tcpdump的用法主要是<code>tcpdump [option] [expression]</code></p>\n<h2 id=\"option\"><a href=\"#option\" class=\"headerlink\" title=\"option\"></a>option</h2><p>-A<br>以ASCII码方式展示数据包，不显示链路层header信息</p>\n<p>-c count<br>指定tcpdump抓取count格数据包</p>\n<p>-e<br>打印数据包的数据链路层header信息</p>\n<p>-F file<br>以文件中的过滤表达式作为过滤条件</p>\n<p>-i interface<br>监听网卡，使用any可以监听所有网卡。需要注意的是如果真实网络接口不能工作在’混杂’模式(promiscuous)下,则无法在’any’这个虚拟的网络接口上抓取其数据包？</p>\n<p>-l<br>行缓冲输出，遇到换行符就输出</p>\n<p>-q<br>简短的信息输出</p>\n<p>-r file<br>从文件中读取包信息，如果file为-，则从标准输入中读取</p>\n<p>-t<br>不打印时间戳</p>\n<p>-tt<br>打印时间戳，秒数</p>\n<p>-ttt<br>打印当前行和之前行的时间差</p>\n<p>-tttt<br>打印时间戳，年月日形式</p>\n<p>-ttttt<br>打印当前行和第一行的时间差</p>\n<p>-v<br>当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.</p>\n<p>-vv<br>产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.</p>\n<p>-vvv<br>产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面,其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).</p>\n<p>-x<br>打印每个包的头部数据，不打印链路层头部信息</p>\n<p>-xx<br>在-x的基础上还打印了链路层的头部信息</p>\n<h2 id=\"expression\"><a href=\"#expression\" class=\"headerlink\" title=\"expression\"></a>expression</h2><p>除了以上参数，tcpdump还可以在命令最后加上包过滤表达式，之后这个表达式为True的包才会被打印。这个表达式可以用于过滤协议，ip，端口等包数据<br>表达式是一个逻辑语句，可以用 and,or,not 连接。</p>\n<p><code>[ip|arp|rarp|ip6] [dst|src] host host1</code> 目的地址/源地址是host1，可以是名字或者ip地址。没有dst/src表示源或者目的地址</p>\n<p><code>ether [dst|src|host] ehost</code> 匹配以太网地址</p>\n<p><code>[src|dst] port port1</code> 端口过滤</p>\n<p><code>[tcp|udp] [src|dst] portrange port1-port2</code> 端口范围过滤</p>\n<p><code>[greater|less] length</code> 数据包长度小于大于length</p>\n<p><code>ip proto protocol</code> 协议过滤，如icmp6 igmp igrp udp tcp icmp等。由于udp tcp icmp在tcpdump中是关键字，需要用\\tcp来转义.</p>\n<p><code>ip broadcast</code> 过滤广播数据</p>\n<p><code>ip multicast</code> 过滤多播数据</p>\n<p>例子：<br><code>dst host 10.100.10.1 and (ip proto \\udp or src port 80)</code></p>\n<p><code>tcpdump -vvnneSs 0 -i veth_host host 192.168.84.193 and icmp</code></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ol>\n<li><p><a href=\"http://www.tcpdump.org/tcpdump_man.html\" target=\"_blank\" rel=\"external\">http://www.tcpdump.org/tcpdump_man.html</a></p>\n</li>\n<li><p><a href=\"http://www.tcpdump.org/manpages/pcap-filter.7.html\" target=\"_blank\" rel=\"external\">http://www.tcpdump.org/manpages/pcap-filter.7.html</a></p>\n</li>\n</ol>\n","excerpt":"","more":"<p>tcpdump是linux上用于截获数据包的分析工具，提供了强大的包过滤和展示功能</p>\n<p>tcpdump的用法主要是<code>tcpdump [option] [expression]</code></p>\n<h2 id=\"option\"><a href=\"#option\" class=\"headerlink\" title=\"option\"></a>option</h2><p>-A<br>以ASCII码方式展示数据包，不显示链路层header信息</p>\n<p>-c count<br>指定tcpdump抓取count格数据包</p>\n<p>-e<br>打印数据包的数据链路层header信息</p>\n<p>-F file<br>以文件中的过滤表达式作为过滤条件</p>\n<p>-i interface<br>监听网卡，使用any可以监听所有网卡。需要注意的是如果真实网络接口不能工作在’混杂’模式(promiscuous)下,则无法在’any’这个虚拟的网络接口上抓取其数据包？</p>\n<p>-l<br>行缓冲输出，遇到换行符就输出</p>\n<p>-q<br>简短的信息输出</p>\n<p>-r file<br>从文件中读取包信息，如果file为-，则从标准输入中读取</p>\n<p>-t<br>不打印时间戳</p>\n<p>-tt<br>打印时间戳，秒数</p>\n<p>-ttt<br>打印当前行和之前行的时间差</p>\n<p>-tttt<br>打印时间戳，年月日形式</p>\n<p>-ttttt<br>打印当前行和第一行的时间差</p>\n<p>-v<br>当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.</p>\n<p>-vv<br>产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.</p>\n<p>-vvv<br>产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面,其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).</p>\n<p>-x<br>打印每个包的头部数据，不打印链路层头部信息</p>\n<p>-xx<br>在-x的基础上还打印了链路层的头部信息</p>\n<h2 id=\"expression\"><a href=\"#expression\" class=\"headerlink\" title=\"expression\"></a>expression</h2><p>除了以上参数，tcpdump还可以在命令最后加上包过滤表达式，之后这个表达式为True的包才会被打印。这个表达式可以用于过滤协议，ip，端口等包数据<br>表达式是一个逻辑语句，可以用 and,or,not 连接。</p>\n<p><code>[ip|arp|rarp|ip6] [dst|src] host host1</code> 目的地址/源地址是host1，可以是名字或者ip地址。没有dst/src表示源或者目的地址</p>\n<p><code>ether [dst|src|host] ehost</code> 匹配以太网地址</p>\n<p><code>[src|dst] port port1</code> 端口过滤</p>\n<p><code>[tcp|udp] [src|dst] portrange port1-port2</code> 端口范围过滤</p>\n<p><code>[greater|less] length</code> 数据包长度小于大于length</p>\n<p><code>ip proto protocol</code> 协议过滤，如icmp6 igmp igrp udp tcp icmp等。由于udp tcp icmp在tcpdump中是关键字，需要用\\tcp来转义.</p>\n<p><code>ip broadcast</code> 过滤广播数据</p>\n<p><code>ip multicast</code> 过滤多播数据</p>\n<p>例子：<br><code>dst host 10.100.10.1 and (ip proto \\udp or src port 80)</code></p>\n<p><code>tcpdump -vvnneSs 0 -i veth_host host 192.168.84.193 and icmp</code></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ol>\n<li><p><a href=\"http://www.tcpdump.org/tcpdump_man.html\">http://www.tcpdump.org/tcpdump_man.html</a></p>\n</li>\n<li><p><a href=\"http://www.tcpdump.org/manpages/pcap-filter.7.html\">http://www.tcpdump.org/manpages/pcap-filter.7.html</a></p>\n</li>\n</ol>\n"},{"title":"calico getting start","date":"2017-03-16T12:02:16.000Z","_content":"\n# 简介\n\n[Calico](https://www.projectcalico.org/)是一个纯3层虚拟网络，可以为夸主机的容器/虚拟机等提供网络访问，同时支持IPv4和IPv6。并且可以根据策略提供访问控制能力。\n\nCalico的工作原理主要依靠linux本身提供的ip转发机制，不需要虚拟交换设备或者overlay支持。每一个主机都会将自己的路由信息告知数据中心网络中的其他主机：在小型网络中，直接通过BGP协议交换信息；在大型网络中，通过BGP route reflectors完整路由信息的交换。\n\nCalico为各个不同的云环境提供了不同的插件来使用calico网络，kubernetes和mesos通过CNI插件形式使用calico，docker使用libnetwork插件使用calico网络进行跨主机容器间通信。OpenStack使用Neutron插件使用calico。\n\n# 入门实践\n\n## 环境搭建\n\n这里根据[官网教程](http://docs.projectcalico.org/v2.0/getting-started/docker/installation/vagrant-ubuntu/)使用vagrant进行docker+calico初始环境搭建。官方文档还提供了手动环境搭建的流程，但是由于一些坑（跨主机容器不能相互访问）放弃了，后来在vagrant上解决了也懒得重新解决一遍了。\n\n搭建命令如下\n\n```shell\n# 需要在主机上有git/vagrant/virtualbox\ngit clone https://github.com/projectcalico/calico.git\ncd calico/v2.0/getting-started/docker/installation/vagrant-ubuntu\n# 初始化虚拟机环境，此命令会创建两个主机calico-01/calico-02，且在01上运行了etcd\nvagrant up\n# 验证环境\nvagrant ssh calico-01 # ssh into calico-01 host\nping 172.17.8.102 # ping calico-02 in calico-01\n# run calico/node\nsudo calico node run\n# 查看运行\ndocker ps\nexit # exit from calico-01\nvagrant ssh calico-02 # ssh into calico-02 host\nsudo calico node run\n# 查看BGP信息\nsudo calico node status\nexit\n```\n\n上诉能ping通且`sudo calico node status`能显示对端的信息说明环境搭建成功。\n\n## 测试工作\n\n安装[官方文档](http://docs.projectcalico.org/v2.0/getting-started/docker/tutorials/simple-policy)的说明，跨主机的容器通信很简单。只要给docker创建calico的network，然后创建container时设置这个network就可以。具体如下：\n\n```shell\n# 进入calico-01，创建docker网络\ndocker network create --driver calico --ipam-driver calico-ipam net1\n# 创建容器并设置网络为net1\ndocker run -d --net net1 --name workload-A busybox tail -f /etc/hosts\n# 查看容器ip地址\ndocker exec -it workload-A ip a # 查看到calixxx网络的地址为IP1\n# 进入calico-02，查看docker网络\ndocker network ls # 运行这条命令可以看到net1的网络\n# 创建容器\ndocker run -d --net net1 --name workload-B busybox tail -f /etc/hosts\n# 在calico-02的容器中ping calico-01的容器地址\ndocker exec -it workload-B ping workload-A\ndocker exec -it workload-B ping $IP1\n# 也可以直接在calico-02上ping calico-01的容器地址\nping $IP1\n```\n\n按照官方文档的说明，这里应该是能直接ping通的，但是这里就出现了上面一开始就说到的坑，并不能ping通，只有通一个主机的两个container直接可以ping。这个坑我首先在自己的azure上手动安装环境时就遇到了，同事帮忙查看了好久，看了iproute, iptables的各种信息，并用tcpdump进行抓包，但是都无法解决，认为可能是azure的问题。于是我又在自己的机器上安装使用virtualbox安装了两个虚拟机，结果还是一样。最后在Mac上直接使用vagrant也无效。这个问题直接浪费了我至少两天时间。最近同事终于发现原来是iptables会把这些包给drop掉。。。而解决这个问题的方法是需要设置calico的profile和policy对象，使得出入流量可以在两个主机之间互通。\n\n```shell\n# 配置net1网络。在docker创建net1时就创建了这个profile，这里我们更改一些属性！\ncat << EOF | calicoctl apply -f -\n- apiVersion: v1\n  kind: profile\n  metadata:\n    name: net1\n    labels:\n      role: net1\nEOF\n\n# 为net1创建policy，运行所有出入流量！\ncat << EOF | calicoctl create -f -\n- apiVersion: v1\n  kind: policy\n  metadata:\n    name: net1\n  spec:\n    order: 0\n    selector: role == 'net1'\n    ingress:\n    - action: allow\n    egress:\n    - action: allow\nEOF\n\n```\n\n通过上面的设置，终于可以愉快的跨主机通信了^_^。\n查看`ip route`可以发现，本地的ip直接走本地的calico创建的veth设备，其他主机的ip通过网卡直接路由到目标主机ip，然后交给目标主机的路由表处理。\n\n```\ndefault via 10.0.2.2 dev enp0s3\n10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15\n172.17.8.0/24 dev enp0s8  proto kernel  scope link  src 172.17.8.101\n172.18.0.0/16 dev docker0  proto kernel  scope link  src 172.18.0.1 linkdown\n# 目的地址为192.168.50.64/26的请求通过主机上的enp0s8网卡发到172.17.8.102\n192.168.50.64/26 via 172.17.8.102 dev enp0s8  proto bird\nblackhole 192.168.84.192/26  proto bird\n# 本机container直接打到对应设备上\n192.168.84.209 dev calic18c1dc57ca  scope link\n```\n\n## ipip 隧道通信\n\ncalico支持两个container之间通过ipip隧道通信。在这种模式下，calico会为我们在主机上创建tunl0设备。使用这个设备进行ip封装和拆解。\n\n在打开ipip选项之前，可以先试用`ip link`看一下机器上的设备被没有tunl0设备。通过下面步骤打开\n\n1. 执行`calicoctl config set ipip on`, 打开设置\n2. 按照[这里](http://docs.projectcalico.org/v2.0/usage/troubleshooting/faq#how-do-i-enable-ipip-and-nat-outgoing-on-an-ip-pool)的教程打开ipPool的ipip\n\n```shell\ncalicoctl get ipPool -o yaml > pool.yaml\n# 修改spec内容，设置ipip和nat-outgoing\n\n- apiVersion: v1\n  kind: ipPool\n  metadata:\n    cidr: 192.168.0.0/16\n  spec:\n    ipip:\n      enabled: true\n    nat-outgoing: true\n\ncalicoctl replace -f pool.yaml\n```\n\n通过上诉设置，就打开了calico的ipip支持。查看`ip route`可以看到和原来的不同:\n\n```\ndefault via 10.0.2.2 dev enp0s3\n10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15\n172.17.8.0/24 dev enp0s8  proto kernel  scope link  src 172.17.8.101\n172.18.0.0/16 dev docker0  proto kernel  scope link  src 172.18.0.1 linkdown\n# 注意这里使用到tunl0设备，与前面不同\n192.168.50.64/26 via 172.17.8.102 dev tunl0  proto bird onlink\nblackhole 192.168.84.192/26  proto bird\n# 本机container直接打到对应设备上\n192.168.84.208 dev cali445d36d1804  scope link\n```\n\n现在跨主机的通信通过tunl0设备而不是原来的enp0s8设备了。\n\n这样ping容器时进行`tcpdump -i tunl0 icmp`可以看到有icmp包。`tcpdump -i cali445d36d1804 icmp`可以看到流量。\n\n`tcpdump -i enp0s8 | grep ipip`同样可以看到ipip报文，内容如图所示：\n\n```\n06:35:48.321025 IP 172.17.8.102 > 172.17.8.101: IP 192.168.50.97 > 192.168.84.208: ICMP echo request, id 2304, seq 0, length 64 (ipip-proto-4)\n06:35:48.321149 IP 172.17.8.101 > 172.17.8.102: IP 192.168.84.208 > 192.168.50.97: ICMP echo reply, id 2304, seq 0, length 64 (ipip-proto-4)\n06:35:49.322821 IP 172.17.8.102 > 172.17.8.101: IP 192.168.50.97 > 192.168.84.208: ICMP echo request, id 2304, seq 1, length 64 (ipip-proto-4)\n06:35:49.322900 IP 172.17.8.101 > 172.17.8.102: IP 192.168.84.208 > 192.168.50.97: ICMP echo reply, id 2304, seq 1, length 64 (ipip-proto-4)\n```\n\n## 性能测试\n\n这里简单的测试了calico网络的性能。测试环境是MacBook上创建的两个虚拟机。calico网络使用networkstatic/iperf3进行性能测试，host之间也适用iperf3测试。测试结果如下：\n\n测试项 | 命令 | Bandwidth | Retr\n---- | --- | --- | ---\n主机网络 | `iperf3 -c 172.17.8.101 -n 10000M -O 3` | 2.25 Gbits/sec | 55672\ndocker host | `docker run --rm -it --net host networkstatic/iperf3 -c 172.17.8.101 -n 10000M -O 3` | 2.22 Gbits/sec | 55285\ncalico | `docker run --rm -it --net net1 networkstatic/iperf3 -c 192.168.84.209 -n 10000M -O 3` | 2.09 Gbits/sec | 36470\ncalico-ipip | `docker run --rm -it --net net1 networkstatic/iperf3 -c 192.168.84.208 -n 10000M -O 3` | 2.15 Gbits/sec | 4516\n\n可以看到ipip的性能还要稍微好于非ipip模式，且在ipip模式下TCP的重传较少。总体来看，对比host模式，calico的性能损失不大。\n\n对于上面的测试结果（ipip模式比非ipip模式要好）存在疑惑，因为实际上相比于非ipip模式，ipip模式下需要多经历一次ip包的封装。针对这个疑惑我在社区提了个[issue](https://github.com/projectcalico/calico/issues/621)。根据回复中的建议在iperf命令中加入了`-M 1440`设置mtu参数，结果显示非ipip模式实际是要比较好的，这比较符合常理。（注：1440是calico的tunl0的mtu值）\n\n# 自己动手\ncalico实际上就是对本机容器ip在主机上建立路由，并将这些路由通过bgp协议告知其他主机。通过路由表的信息，达到主机垮主机的容器通信。\n下面使用同事给的demo使用linux的ip命令工具来模拟calico的非ipip网络和ipip网络。\n\n1. 首先创建两个虚拟机host1(dev enp0s8:172.17.8.101)和host2(dev enp0s8:172.17.8.102)，检查是否可以相互ping通\n2. 在host1上执行以下命令创建容器网络\n\n  ```shell\n  # netns内部ip, 假设本机上所有container的网段在192.168.41.0/24\n  ip=192.168.41.2\n  ctn=ctn1\n  ip netns add $ctn\n  ip li add dev veth_host type veth peer name veth_sbx\n  ip link set dev veth_sbx netns $ctn\n  ip netns exec $ctn ip ad add $ip dev veth_sbx\n  ip netns exec $ctn ip link set dev veth_sbx up\n  ip netns exec $ctn ip route add 169.254.1.1 dev veth_sbx\n  ip netns exec $ctn ip route add default via 169.254.1.1 dev veth_sbx\n  ip netns exec $ctn ip ad\n  ip netns exec $ctn ip link set dev veth_sbx up\n  ip link set dev veth_host up\n  ip ad show veth_host\n  ip netns exec $ctn ip neigh add 169.254.1.1 dev veth_sbx lladdr `cat /sys/class/net/veth_host/address` \n  ip route add $ip dev veth_host\n  # 打开ip_forward\n  echo 1 > /proc/sys/net/ipv4/ip_forward\n  ```\n\n3. 将上诉脚本的ip地址改为192.168.42.2，在host2执行\n4. 执行以下步骤添加路由表项以达到跨主机container访问\n\n  ```\n  # 在host2执行下面命令\n  ip route add 192.168.41.0/24 via 172.17.8.101 dev enp0s8\n  # 在host1执行下面命令\n  ip route add 192.168.42.0/24 via 172.17.8.102 dev enp0s8\n  ```\n\n5. 这样就可以在主机或者容器网络空间内ping跨主机的container ip了\n\n  ```\n  # 在host1 ping host2的container\n  ip netns exec ctn1 ping 192.168.42.2\n  ```\n\n通过上诉步骤，就模拟了calico的默认网络。\n\n通过之前的描述，calico实际还支持ipip模式的跨主机通信，原理就是通过tunnel设备对原始ip报文进行封装。只需要对上述脚本做一些修改就可以：\n\n1. 在两台主机上将上诉过程中的第4步添加的路由规则去掉\n2. 在host1上执行以下脚本\n\n  ```shell\n  ipip=192.168.41.3\n  # 这个命令会生成一个tunl0设备\n  modprobe ipip\n  ip link set tunl0 up\n  ip a add $ipip brd + dev tunl0\n  # 注意这里的路由规则，前面已经提到过，使用tunl0设备！最后一个参数onlink是必须的，具体作用参考[这里](http://lartc.vger.kernel.narkive.com/XgcjFTGM/aw-onlink-option-for-ip-route)\n  ip r add 192.168.42.0/24 via 172.17.8.102 dev tunl0 proto bird onlink\n  ```\n\n3. 在host2上执行类似上诉步骤\n4. 重新进入网络空间ping跨主机container ip\n5. 可以在对端的enp0s8网卡上使用tcpdump进行截包\n\n  ```\n  tcpdump -vvnneSs 0 -i enp0s8\n\n  07:41:03.985150 08:00:27:d5:4b:b1 > 08:00:27:29:bc:de, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 63, id 55151, offset 0, flags [DF], proto IPIP (4), length 104)\n      172.17.8.101 > 172.17.8.103: (tos 0x0, ttl 63, id 16085, offset 0, flags [DF], proto ICMP (1), length 84)\n      192.168.41.2 > 192.168.43.2: ICMP echo request, id 15973, seq 30, length 64\n  07:41:03.985243 08:00:27:29:bc:de > 08:00:27:d5:4b:b1, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 63, id 32595, offset 0, flags [none], proto IPIP (4), length 104)\n      172.17.8.103 > 172.17.8.101: (tos 0x0, ttl 63, id 42711, offset 0, flags [none], proto ICMP (1), length 84)\n      192.168.43.2 > 192.168.41.2: ICMP echo reply, id 15973, seq 30, length 64\n  ```\n\nipip相对于非ipip模式会有一些性能的损失，但是好处在于ipip模式下可以进行跨网段的主机间容器通信！将上诉的脚本的两个不同网段的主机上测试可以验证这个结果。","source":"_posts/2017-03-16-calico-getting-start.md","raw":"---\ntitle: calico getting start\ndate: 2017-03-16 20:02:16\ntags: [network, calico]\n---\n\n# 简介\n\n[Calico](https://www.projectcalico.org/)是一个纯3层虚拟网络，可以为夸主机的容器/虚拟机等提供网络访问，同时支持IPv4和IPv6。并且可以根据策略提供访问控制能力。\n\nCalico的工作原理主要依靠linux本身提供的ip转发机制，不需要虚拟交换设备或者overlay支持。每一个主机都会将自己的路由信息告知数据中心网络中的其他主机：在小型网络中，直接通过BGP协议交换信息；在大型网络中，通过BGP route reflectors完整路由信息的交换。\n\nCalico为各个不同的云环境提供了不同的插件来使用calico网络，kubernetes和mesos通过CNI插件形式使用calico，docker使用libnetwork插件使用calico网络进行跨主机容器间通信。OpenStack使用Neutron插件使用calico。\n\n# 入门实践\n\n## 环境搭建\n\n这里根据[官网教程](http://docs.projectcalico.org/v2.0/getting-started/docker/installation/vagrant-ubuntu/)使用vagrant进行docker+calico初始环境搭建。官方文档还提供了手动环境搭建的流程，但是由于一些坑（跨主机容器不能相互访问）放弃了，后来在vagrant上解决了也懒得重新解决一遍了。\n\n搭建命令如下\n\n```shell\n# 需要在主机上有git/vagrant/virtualbox\ngit clone https://github.com/projectcalico/calico.git\ncd calico/v2.0/getting-started/docker/installation/vagrant-ubuntu\n# 初始化虚拟机环境，此命令会创建两个主机calico-01/calico-02，且在01上运行了etcd\nvagrant up\n# 验证环境\nvagrant ssh calico-01 # ssh into calico-01 host\nping 172.17.8.102 # ping calico-02 in calico-01\n# run calico/node\nsudo calico node run\n# 查看运行\ndocker ps\nexit # exit from calico-01\nvagrant ssh calico-02 # ssh into calico-02 host\nsudo calico node run\n# 查看BGP信息\nsudo calico node status\nexit\n```\n\n上诉能ping通且`sudo calico node status`能显示对端的信息说明环境搭建成功。\n\n## 测试工作\n\n安装[官方文档](http://docs.projectcalico.org/v2.0/getting-started/docker/tutorials/simple-policy)的说明，跨主机的容器通信很简单。只要给docker创建calico的network，然后创建container时设置这个network就可以。具体如下：\n\n```shell\n# 进入calico-01，创建docker网络\ndocker network create --driver calico --ipam-driver calico-ipam net1\n# 创建容器并设置网络为net1\ndocker run -d --net net1 --name workload-A busybox tail -f /etc/hosts\n# 查看容器ip地址\ndocker exec -it workload-A ip a # 查看到calixxx网络的地址为IP1\n# 进入calico-02，查看docker网络\ndocker network ls # 运行这条命令可以看到net1的网络\n# 创建容器\ndocker run -d --net net1 --name workload-B busybox tail -f /etc/hosts\n# 在calico-02的容器中ping calico-01的容器地址\ndocker exec -it workload-B ping workload-A\ndocker exec -it workload-B ping $IP1\n# 也可以直接在calico-02上ping calico-01的容器地址\nping $IP1\n```\n\n按照官方文档的说明，这里应该是能直接ping通的，但是这里就出现了上面一开始就说到的坑，并不能ping通，只有通一个主机的两个container直接可以ping。这个坑我首先在自己的azure上手动安装环境时就遇到了，同事帮忙查看了好久，看了iproute, iptables的各种信息，并用tcpdump进行抓包，但是都无法解决，认为可能是azure的问题。于是我又在自己的机器上安装使用virtualbox安装了两个虚拟机，结果还是一样。最后在Mac上直接使用vagrant也无效。这个问题直接浪费了我至少两天时间。最近同事终于发现原来是iptables会把这些包给drop掉。。。而解决这个问题的方法是需要设置calico的profile和policy对象，使得出入流量可以在两个主机之间互通。\n\n```shell\n# 配置net1网络。在docker创建net1时就创建了这个profile，这里我们更改一些属性！\ncat << EOF | calicoctl apply -f -\n- apiVersion: v1\n  kind: profile\n  metadata:\n    name: net1\n    labels:\n      role: net1\nEOF\n\n# 为net1创建policy，运行所有出入流量！\ncat << EOF | calicoctl create -f -\n- apiVersion: v1\n  kind: policy\n  metadata:\n    name: net1\n  spec:\n    order: 0\n    selector: role == 'net1'\n    ingress:\n    - action: allow\n    egress:\n    - action: allow\nEOF\n\n```\n\n通过上面的设置，终于可以愉快的跨主机通信了^_^。\n查看`ip route`可以发现，本地的ip直接走本地的calico创建的veth设备，其他主机的ip通过网卡直接路由到目标主机ip，然后交给目标主机的路由表处理。\n\n```\ndefault via 10.0.2.2 dev enp0s3\n10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15\n172.17.8.0/24 dev enp0s8  proto kernel  scope link  src 172.17.8.101\n172.18.0.0/16 dev docker0  proto kernel  scope link  src 172.18.0.1 linkdown\n# 目的地址为192.168.50.64/26的请求通过主机上的enp0s8网卡发到172.17.8.102\n192.168.50.64/26 via 172.17.8.102 dev enp0s8  proto bird\nblackhole 192.168.84.192/26  proto bird\n# 本机container直接打到对应设备上\n192.168.84.209 dev calic18c1dc57ca  scope link\n```\n\n## ipip 隧道通信\n\ncalico支持两个container之间通过ipip隧道通信。在这种模式下，calico会为我们在主机上创建tunl0设备。使用这个设备进行ip封装和拆解。\n\n在打开ipip选项之前，可以先试用`ip link`看一下机器上的设备被没有tunl0设备。通过下面步骤打开\n\n1. 执行`calicoctl config set ipip on`, 打开设置\n2. 按照[这里](http://docs.projectcalico.org/v2.0/usage/troubleshooting/faq#how-do-i-enable-ipip-and-nat-outgoing-on-an-ip-pool)的教程打开ipPool的ipip\n\n```shell\ncalicoctl get ipPool -o yaml > pool.yaml\n# 修改spec内容，设置ipip和nat-outgoing\n\n- apiVersion: v1\n  kind: ipPool\n  metadata:\n    cidr: 192.168.0.0/16\n  spec:\n    ipip:\n      enabled: true\n    nat-outgoing: true\n\ncalicoctl replace -f pool.yaml\n```\n\n通过上诉设置，就打开了calico的ipip支持。查看`ip route`可以看到和原来的不同:\n\n```\ndefault via 10.0.2.2 dev enp0s3\n10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15\n172.17.8.0/24 dev enp0s8  proto kernel  scope link  src 172.17.8.101\n172.18.0.0/16 dev docker0  proto kernel  scope link  src 172.18.0.1 linkdown\n# 注意这里使用到tunl0设备，与前面不同\n192.168.50.64/26 via 172.17.8.102 dev tunl0  proto bird onlink\nblackhole 192.168.84.192/26  proto bird\n# 本机container直接打到对应设备上\n192.168.84.208 dev cali445d36d1804  scope link\n```\n\n现在跨主机的通信通过tunl0设备而不是原来的enp0s8设备了。\n\n这样ping容器时进行`tcpdump -i tunl0 icmp`可以看到有icmp包。`tcpdump -i cali445d36d1804 icmp`可以看到流量。\n\n`tcpdump -i enp0s8 | grep ipip`同样可以看到ipip报文，内容如图所示：\n\n```\n06:35:48.321025 IP 172.17.8.102 > 172.17.8.101: IP 192.168.50.97 > 192.168.84.208: ICMP echo request, id 2304, seq 0, length 64 (ipip-proto-4)\n06:35:48.321149 IP 172.17.8.101 > 172.17.8.102: IP 192.168.84.208 > 192.168.50.97: ICMP echo reply, id 2304, seq 0, length 64 (ipip-proto-4)\n06:35:49.322821 IP 172.17.8.102 > 172.17.8.101: IP 192.168.50.97 > 192.168.84.208: ICMP echo request, id 2304, seq 1, length 64 (ipip-proto-4)\n06:35:49.322900 IP 172.17.8.101 > 172.17.8.102: IP 192.168.84.208 > 192.168.50.97: ICMP echo reply, id 2304, seq 1, length 64 (ipip-proto-4)\n```\n\n## 性能测试\n\n这里简单的测试了calico网络的性能。测试环境是MacBook上创建的两个虚拟机。calico网络使用networkstatic/iperf3进行性能测试，host之间也适用iperf3测试。测试结果如下：\n\n测试项 | 命令 | Bandwidth | Retr\n---- | --- | --- | ---\n主机网络 | `iperf3 -c 172.17.8.101 -n 10000M -O 3` | 2.25 Gbits/sec | 55672\ndocker host | `docker run --rm -it --net host networkstatic/iperf3 -c 172.17.8.101 -n 10000M -O 3` | 2.22 Gbits/sec | 55285\ncalico | `docker run --rm -it --net net1 networkstatic/iperf3 -c 192.168.84.209 -n 10000M -O 3` | 2.09 Gbits/sec | 36470\ncalico-ipip | `docker run --rm -it --net net1 networkstatic/iperf3 -c 192.168.84.208 -n 10000M -O 3` | 2.15 Gbits/sec | 4516\n\n可以看到ipip的性能还要稍微好于非ipip模式，且在ipip模式下TCP的重传较少。总体来看，对比host模式，calico的性能损失不大。\n\n对于上面的测试结果（ipip模式比非ipip模式要好）存在疑惑，因为实际上相比于非ipip模式，ipip模式下需要多经历一次ip包的封装。针对这个疑惑我在社区提了个[issue](https://github.com/projectcalico/calico/issues/621)。根据回复中的建议在iperf命令中加入了`-M 1440`设置mtu参数，结果显示非ipip模式实际是要比较好的，这比较符合常理。（注：1440是calico的tunl0的mtu值）\n\n# 自己动手\ncalico实际上就是对本机容器ip在主机上建立路由，并将这些路由通过bgp协议告知其他主机。通过路由表的信息，达到主机垮主机的容器通信。\n下面使用同事给的demo使用linux的ip命令工具来模拟calico的非ipip网络和ipip网络。\n\n1. 首先创建两个虚拟机host1(dev enp0s8:172.17.8.101)和host2(dev enp0s8:172.17.8.102)，检查是否可以相互ping通\n2. 在host1上执行以下命令创建容器网络\n\n  ```shell\n  # netns内部ip, 假设本机上所有container的网段在192.168.41.0/24\n  ip=192.168.41.2\n  ctn=ctn1\n  ip netns add $ctn\n  ip li add dev veth_host type veth peer name veth_sbx\n  ip link set dev veth_sbx netns $ctn\n  ip netns exec $ctn ip ad add $ip dev veth_sbx\n  ip netns exec $ctn ip link set dev veth_sbx up\n  ip netns exec $ctn ip route add 169.254.1.1 dev veth_sbx\n  ip netns exec $ctn ip route add default via 169.254.1.1 dev veth_sbx\n  ip netns exec $ctn ip ad\n  ip netns exec $ctn ip link set dev veth_sbx up\n  ip link set dev veth_host up\n  ip ad show veth_host\n  ip netns exec $ctn ip neigh add 169.254.1.1 dev veth_sbx lladdr `cat /sys/class/net/veth_host/address` \n  ip route add $ip dev veth_host\n  # 打开ip_forward\n  echo 1 > /proc/sys/net/ipv4/ip_forward\n  ```\n\n3. 将上诉脚本的ip地址改为192.168.42.2，在host2执行\n4. 执行以下步骤添加路由表项以达到跨主机container访问\n\n  ```\n  # 在host2执行下面命令\n  ip route add 192.168.41.0/24 via 172.17.8.101 dev enp0s8\n  # 在host1执行下面命令\n  ip route add 192.168.42.0/24 via 172.17.8.102 dev enp0s8\n  ```\n\n5. 这样就可以在主机或者容器网络空间内ping跨主机的container ip了\n\n  ```\n  # 在host1 ping host2的container\n  ip netns exec ctn1 ping 192.168.42.2\n  ```\n\n通过上诉步骤，就模拟了calico的默认网络。\n\n通过之前的描述，calico实际还支持ipip模式的跨主机通信，原理就是通过tunnel设备对原始ip报文进行封装。只需要对上述脚本做一些修改就可以：\n\n1. 在两台主机上将上诉过程中的第4步添加的路由规则去掉\n2. 在host1上执行以下脚本\n\n  ```shell\n  ipip=192.168.41.3\n  # 这个命令会生成一个tunl0设备\n  modprobe ipip\n  ip link set tunl0 up\n  ip a add $ipip brd + dev tunl0\n  # 注意这里的路由规则，前面已经提到过，使用tunl0设备！最后一个参数onlink是必须的，具体作用参考[这里](http://lartc.vger.kernel.narkive.com/XgcjFTGM/aw-onlink-option-for-ip-route)\n  ip r add 192.168.42.0/24 via 172.17.8.102 dev tunl0 proto bird onlink\n  ```\n\n3. 在host2上执行类似上诉步骤\n4. 重新进入网络空间ping跨主机container ip\n5. 可以在对端的enp0s8网卡上使用tcpdump进行截包\n\n  ```\n  tcpdump -vvnneSs 0 -i enp0s8\n\n  07:41:03.985150 08:00:27:d5:4b:b1 > 08:00:27:29:bc:de, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 63, id 55151, offset 0, flags [DF], proto IPIP (4), length 104)\n      172.17.8.101 > 172.17.8.103: (tos 0x0, ttl 63, id 16085, offset 0, flags [DF], proto ICMP (1), length 84)\n      192.168.41.2 > 192.168.43.2: ICMP echo request, id 15973, seq 30, length 64\n  07:41:03.985243 08:00:27:29:bc:de > 08:00:27:d5:4b:b1, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 63, id 32595, offset 0, flags [none], proto IPIP (4), length 104)\n      172.17.8.103 > 172.17.8.101: (tos 0x0, ttl 63, id 42711, offset 0, flags [none], proto ICMP (1), length 84)\n      192.168.43.2 > 192.168.41.2: ICMP echo reply, id 15973, seq 30, length 64\n  ```\n\nipip相对于非ipip模式会有一些性能的损失，但是好处在于ipip模式下可以进行跨网段的主机间容器通信！将上诉的脚本的两个不同网段的主机上测试可以验证这个结果。","slug":"calico-getting-start","published":1,"updated":"2017-03-22T02:25:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asaqig001aphv9asr4865j","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p><a href=\"https://www.projectcalico.org/\" target=\"_blank\" rel=\"external\">Calico</a>是一个纯3层虚拟网络，可以为夸主机的容器/虚拟机等提供网络访问，同时支持IPv4和IPv6。并且可以根据策略提供访问控制能力。</p>\n<p>Calico的工作原理主要依靠linux本身提供的ip转发机制，不需要虚拟交换设备或者overlay支持。每一个主机都会将自己的路由信息告知数据中心网络中的其他主机：在小型网络中，直接通过BGP协议交换信息；在大型网络中，通过BGP route reflectors完整路由信息的交换。</p>\n<p>Calico为各个不同的云环境提供了不同的插件来使用calico网络，kubernetes和mesos通过CNI插件形式使用calico，docker使用libnetwork插件使用calico网络进行跨主机容器间通信。OpenStack使用Neutron插件使用calico。</p>\n<h1 id=\"入门实践\"><a href=\"#入门实践\" class=\"headerlink\" title=\"入门实践\"></a>入门实践</h1><h2 id=\"环境搭建\"><a href=\"#环境搭建\" class=\"headerlink\" title=\"环境搭建\"></a>环境搭建</h2><p>这里根据<a href=\"http://docs.projectcalico.org/v2.0/getting-started/docker/installation/vagrant-ubuntu/\" target=\"_blank\" rel=\"external\">官网教程</a>使用vagrant进行docker+calico初始环境搭建。官方文档还提供了手动环境搭建的流程，但是由于一些坑（跨主机容器不能相互访问）放弃了，后来在vagrant上解决了也懒得重新解决一遍了。</p>\n<p>搭建命令如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 需要在主机上有git/vagrant/virtualbox</div><div class=\"line\">git clone https://github.com/projectcalico/calico.git</div><div class=\"line\">cd calico/v2.0/getting-started/docker/installation/vagrant-ubuntu</div><div class=\"line\"># 初始化虚拟机环境，此命令会创建两个主机calico-01/calico-02，且在01上运行了etcd</div><div class=\"line\">vagrant up</div><div class=\"line\"># 验证环境</div><div class=\"line\">vagrant ssh calico-01 # ssh into calico-01 host</div><div class=\"line\">ping 172.17.8.102 # ping calico-02 in calico-01</div><div class=\"line\"># run calico/node</div><div class=\"line\">sudo calico node run</div><div class=\"line\"># 查看运行</div><div class=\"line\">docker ps</div><div class=\"line\">exit # exit from calico-01</div><div class=\"line\">vagrant ssh calico-02 # ssh into calico-02 host</div><div class=\"line\">sudo calico node run</div><div class=\"line\"># 查看BGP信息</div><div class=\"line\">sudo calico node status</div><div class=\"line\">exit</div></pre></td></tr></table></figure>\n<p>上诉能ping通且<code>sudo calico node status</code>能显示对端的信息说明环境搭建成功。</p>\n<h2 id=\"测试工作\"><a href=\"#测试工作\" class=\"headerlink\" title=\"测试工作\"></a>测试工作</h2><p>安装<a href=\"http://docs.projectcalico.org/v2.0/getting-started/docker/tutorials/simple-policy\" target=\"_blank\" rel=\"external\">官方文档</a>的说明，跨主机的容器通信很简单。只要给docker创建calico的network，然后创建container时设置这个network就可以。具体如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 进入calico-01，创建docker网络</div><div class=\"line\">docker network create --driver calico --ipam-driver calico-ipam net1</div><div class=\"line\"># 创建容器并设置网络为net1</div><div class=\"line\">docker run -d --net net1 --name workload-A busybox tail -f /etc/hosts</div><div class=\"line\"># 查看容器ip地址</div><div class=\"line\">docker exec -it workload-A ip a # 查看到calixxx网络的地址为IP1</div><div class=\"line\"># 进入calico-02，查看docker网络</div><div class=\"line\">docker network ls # 运行这条命令可以看到net1的网络</div><div class=\"line\"># 创建容器</div><div class=\"line\">docker run -d --net net1 --name workload-B busybox tail -f /etc/hosts</div><div class=\"line\"># 在calico-02的容器中ping calico-01的容器地址</div><div class=\"line\">docker exec -it workload-B ping workload-A</div><div class=\"line\">docker exec -it workload-B ping $IP1</div><div class=\"line\"># 也可以直接在calico-02上ping calico-01的容器地址</div><div class=\"line\">ping $IP1</div></pre></td></tr></table></figure>\n<p>按照官方文档的说明，这里应该是能直接ping通的，但是这里就出现了上面一开始就说到的坑，并不能ping通，只有通一个主机的两个container直接可以ping。这个坑我首先在自己的azure上手动安装环境时就遇到了，同事帮忙查看了好久，看了iproute, iptables的各种信息，并用tcpdump进行抓包，但是都无法解决，认为可能是azure的问题。于是我又在自己的机器上安装使用virtualbox安装了两个虚拟机，结果还是一样。最后在Mac上直接使用vagrant也无效。这个问题直接浪费了我至少两天时间。最近同事终于发现原来是iptables会把这些包给drop掉。。。而解决这个问题的方法是需要设置calico的profile和policy对象，使得出入流量可以在两个主机之间互通。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 配置net1网络。在docker创建net1时就创建了这个profile，这里我们更改一些属性！</div><div class=\"line\">cat &lt;&lt; EOF | calicoctl apply -f -</div><div class=\"line\">- apiVersion: v1</div><div class=\"line\">  kind: profile</div><div class=\"line\">  metadata:</div><div class=\"line\">    name: net1</div><div class=\"line\">    labels:</div><div class=\"line\">      role: net1</div><div class=\"line\">EOF</div><div class=\"line\"></div><div class=\"line\"># 为net1创建policy，运行所有出入流量！</div><div class=\"line\">cat &lt;&lt; EOF | calicoctl create -f -</div><div class=\"line\">- apiVersion: v1</div><div class=\"line\">  kind: policy</div><div class=\"line\">  metadata:</div><div class=\"line\">    name: net1</div><div class=\"line\">  spec:</div><div class=\"line\">    order: 0</div><div class=\"line\">    selector: role == &apos;net1&apos;</div><div class=\"line\">    ingress:</div><div class=\"line\">    - action: allow</div><div class=\"line\">    egress:</div><div class=\"line\">    - action: allow</div><div class=\"line\">EOF</div></pre></td></tr></table></figure>\n<p>通过上面的设置，终于可以愉快的跨主机通信了^_^。<br>查看<code>ip route</code>可以发现，本地的ip直接走本地的calico创建的veth设备，其他主机的ip通过网卡直接路由到目标主机ip，然后交给目标主机的路由表处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">default via 10.0.2.2 dev enp0s3</div><div class=\"line\">10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15</div><div class=\"line\">172.17.8.0/24 dev enp0s8  proto kernel  scope link  src 172.17.8.101</div><div class=\"line\">172.18.0.0/16 dev docker0  proto kernel  scope link  src 172.18.0.1 linkdown</div><div class=\"line\"># 目的地址为192.168.50.64/26的请求通过主机上的enp0s8网卡发到172.17.8.102</div><div class=\"line\">192.168.50.64/26 via 172.17.8.102 dev enp0s8  proto bird</div><div class=\"line\">blackhole 192.168.84.192/26  proto bird</div><div class=\"line\"># 本机container直接打到对应设备上</div><div class=\"line\">192.168.84.209 dev calic18c1dc57ca  scope link</div></pre></td></tr></table></figure>\n<h2 id=\"ipip-隧道通信\"><a href=\"#ipip-隧道通信\" class=\"headerlink\" title=\"ipip 隧道通信\"></a>ipip 隧道通信</h2><p>calico支持两个container之间通过ipip隧道通信。在这种模式下，calico会为我们在主机上创建tunl0设备。使用这个设备进行ip封装和拆解。</p>\n<p>在打开ipip选项之前，可以先试用<code>ip link</code>看一下机器上的设备被没有tunl0设备。通过下面步骤打开</p>\n<ol>\n<li>执行<code>calicoctl config set ipip on</code>, 打开设置</li>\n<li>按照<a href=\"http://docs.projectcalico.org/v2.0/usage/troubleshooting/faq#how-do-i-enable-ipip-and-nat-outgoing-on-an-ip-pool\" target=\"_blank\" rel=\"external\">这里</a>的教程打开ipPool的ipip</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">calicoctl get ipPool -o yaml &gt; pool.yaml</div><div class=\"line\"># 修改spec内容，设置ipip和nat-outgoing</div><div class=\"line\"></div><div class=\"line\">- apiVersion: v1</div><div class=\"line\">  kind: ipPool</div><div class=\"line\">  metadata:</div><div class=\"line\">    cidr: 192.168.0.0/16</div><div class=\"line\">  spec:</div><div class=\"line\">    ipip:</div><div class=\"line\">      enabled: true</div><div class=\"line\">    nat-outgoing: true</div><div class=\"line\"></div><div class=\"line\">calicoctl replace -f pool.yaml</div></pre></td></tr></table></figure>\n<p>通过上诉设置，就打开了calico的ipip支持。查看<code>ip route</code>可以看到和原来的不同:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">default via 10.0.2.2 dev enp0s3</div><div class=\"line\">10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15</div><div class=\"line\">172.17.8.0/24 dev enp0s8  proto kernel  scope link  src 172.17.8.101</div><div class=\"line\">172.18.0.0/16 dev docker0  proto kernel  scope link  src 172.18.0.1 linkdown</div><div class=\"line\"># 注意这里使用到tunl0设备，与前面不同</div><div class=\"line\">192.168.50.64/26 via 172.17.8.102 dev tunl0  proto bird onlink</div><div class=\"line\">blackhole 192.168.84.192/26  proto bird</div><div class=\"line\"># 本机container直接打到对应设备上</div><div class=\"line\">192.168.84.208 dev cali445d36d1804  scope link</div></pre></td></tr></table></figure>\n<p>现在跨主机的通信通过tunl0设备而不是原来的enp0s8设备了。</p>\n<p>这样ping容器时进行<code>tcpdump -i tunl0 icmp</code>可以看到有icmp包。<code>tcpdump -i cali445d36d1804 icmp</code>可以看到流量。</p>\n<p><code>tcpdump -i enp0s8 | grep ipip</code>同样可以看到ipip报文，内容如图所示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">06:35:48.321025 IP 172.17.8.102 &gt; 172.17.8.101: IP 192.168.50.97 &gt; 192.168.84.208: ICMP echo request, id 2304, seq 0, length 64 (ipip-proto-4)</div><div class=\"line\">06:35:48.321149 IP 172.17.8.101 &gt; 172.17.8.102: IP 192.168.84.208 &gt; 192.168.50.97: ICMP echo reply, id 2304, seq 0, length 64 (ipip-proto-4)</div><div class=\"line\">06:35:49.322821 IP 172.17.8.102 &gt; 172.17.8.101: IP 192.168.50.97 &gt; 192.168.84.208: ICMP echo request, id 2304, seq 1, length 64 (ipip-proto-4)</div><div class=\"line\">06:35:49.322900 IP 172.17.8.101 &gt; 172.17.8.102: IP 192.168.84.208 &gt; 192.168.50.97: ICMP echo reply, id 2304, seq 1, length 64 (ipip-proto-4)</div></pre></td></tr></table></figure>\n<h2 id=\"性能测试\"><a href=\"#性能测试\" class=\"headerlink\" title=\"性能测试\"></a>性能测试</h2><p>这里简单的测试了calico网络的性能。测试环境是MacBook上创建的两个虚拟机。calico网络使用networkstatic/iperf3进行性能测试，host之间也适用iperf3测试。测试结果如下：</p>\n<table>\n<thead>\n<tr>\n<th>测试项</th>\n<th>命令</th>\n<th>Bandwidth</th>\n<th>Retr</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>主机网络</td>\n<td><code>iperf3 -c 172.17.8.101 -n 10000M -O 3</code></td>\n<td>2.25 Gbits/sec</td>\n<td>55672</td>\n</tr>\n<tr>\n<td>docker host</td>\n<td><code>docker run --rm -it --net host networkstatic/iperf3 -c 172.17.8.101 -n 10000M -O 3</code></td>\n<td>2.22 Gbits/sec</td>\n<td>55285</td>\n</tr>\n<tr>\n<td>calico</td>\n<td><code>docker run --rm -it --net net1 networkstatic/iperf3 -c 192.168.84.209 -n 10000M -O 3</code></td>\n<td>2.09 Gbits/sec</td>\n<td>36470</td>\n</tr>\n<tr>\n<td>calico-ipip</td>\n<td><code>docker run --rm -it --net net1 networkstatic/iperf3 -c 192.168.84.208 -n 10000M -O 3</code></td>\n<td>2.15 Gbits/sec</td>\n<td>4516</td>\n</tr>\n</tbody>\n</table>\n<p>可以看到ipip的性能还要稍微好于非ipip模式，且在ipip模式下TCP的重传较少。总体来看，对比host模式，calico的性能损失不大。</p>\n<p>对于上面的测试结果（ipip模式比非ipip模式要好）存在疑惑，因为实际上相比于非ipip模式，ipip模式下需要多经历一次ip包的封装。针对这个疑惑我在社区提了个<a href=\"https://github.com/projectcalico/calico/issues/621\" target=\"_blank\" rel=\"external\">issue</a>。根据回复中的建议在iperf命令中加入了<code>-M 1440</code>设置mtu参数，结果显示非ipip模式实际是要比较好的，这比较符合常理。（注：1440是calico的tunl0的mtu值）</p>\n<h1 id=\"自己动手\"><a href=\"#自己动手\" class=\"headerlink\" title=\"自己动手\"></a>自己动手</h1><p>calico实际上就是对本机容器ip在主机上建立路由，并将这些路由通过bgp协议告知其他主机。通过路由表的信息，达到主机垮主机的容器通信。<br>下面使用同事给的demo使用linux的ip命令工具来模拟calico的非ipip网络和ipip网络。</p>\n<ol>\n<li>首先创建两个虚拟机host1(dev enp0s8:172.17.8.101)和host2(dev enp0s8:172.17.8.102)，检查是否可以相互ping通</li>\n<li><p>在host1上执行以下命令创建容器网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"># netns内部ip, 假设本机上所有container的网段在192.168.41.0/24</div><div class=\"line\">ip=192.168.41.2</div><div class=\"line\">ctn=ctn1</div><div class=\"line\">ip netns add $ctn</div><div class=\"line\">ip li add dev veth_host type veth peer name veth_sbx</div><div class=\"line\">ip link set dev veth_sbx netns $ctn</div><div class=\"line\">ip netns exec $ctn ip ad add $ip dev veth_sbx</div><div class=\"line\">ip netns exec $ctn ip link set dev veth_sbx up</div><div class=\"line\">ip netns exec $ctn ip route add 169.254.1.1 dev veth_sbx</div><div class=\"line\">ip netns exec $ctn ip route add default via 169.254.1.1 dev veth_sbx</div><div class=\"line\">ip netns exec $ctn ip ad</div><div class=\"line\">ip netns exec $ctn ip link set dev veth_sbx up</div><div class=\"line\">ip link set dev veth_host up</div><div class=\"line\">ip ad show veth_host</div><div class=\"line\">ip netns exec $ctn ip neigh add 169.254.1.1 dev veth_sbx lladdr `cat /sys/class/net/veth_host/address` </div><div class=\"line\">ip route add $ip dev veth_host</div><div class=\"line\"># 打开ip_forward</div><div class=\"line\">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</div></pre></td></tr></table></figure>\n</li>\n<li><p>将上诉脚本的ip地址改为192.168.42.2，在host2执行</p>\n</li>\n<li><p>执行以下步骤添加路由表项以达到跨主机container访问</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 在host2执行下面命令</div><div class=\"line\">ip route add 192.168.41.0/24 via 172.17.8.101 dev enp0s8</div><div class=\"line\"># 在host1执行下面命令</div><div class=\"line\">ip route add 192.168.42.0/24 via 172.17.8.102 dev enp0s8</div></pre></td></tr></table></figure>\n</li>\n<li><p>这样就可以在主机或者容器网络空间内ping跨主机的container ip了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 在host1 ping host2的container</div><div class=\"line\">ip netns exec ctn1 ping 192.168.42.2</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>通过上诉步骤，就模拟了calico的默认网络。</p>\n<p>通过之前的描述，calico实际还支持ipip模式的跨主机通信，原理就是通过tunnel设备对原始ip报文进行封装。只需要对上述脚本做一些修改就可以：</p>\n<ol>\n<li>在两台主机上将上诉过程中的第4步添加的路由规则去掉</li>\n<li><p>在host1上执行以下脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">ipip=192.168.41.3</div><div class=\"line\"># 这个命令会生成一个tunl0设备</div><div class=\"line\">modprobe ipip</div><div class=\"line\">ip link set tunl0 up</div><div class=\"line\">ip a add $ipip brd + dev tunl0</div><div class=\"line\"># 注意这里的路由规则，前面已经提到过，使用tunl0设备！最后一个参数onlink是必须的，具体作用参考[这里](http://lartc.vger.kernel.narkive.com/XgcjFTGM/aw-onlink-option-for-ip-route)</div><div class=\"line\">ip r add 192.168.42.0/24 via 172.17.8.102 dev tunl0 proto bird onlink</div></pre></td></tr></table></figure>\n</li>\n<li><p>在host2上执行类似上诉步骤</p>\n</li>\n<li>重新进入网络空间ping跨主机container ip</li>\n<li><p>可以在对端的enp0s8网卡上使用tcpdump进行截包</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">tcpdump -vvnneSs 0 -i enp0s8</div><div class=\"line\"></div><div class=\"line\">07:41:03.985150 08:00:27:d5:4b:b1 &gt; 08:00:27:29:bc:de, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 63, id 55151, offset 0, flags [DF], proto IPIP (4), length 104)</div><div class=\"line\">    172.17.8.101 &gt; 172.17.8.103: (tos 0x0, ttl 63, id 16085, offset 0, flags [DF], proto ICMP (1), length 84)</div><div class=\"line\">    192.168.41.2 &gt; 192.168.43.2: ICMP echo request, id 15973, seq 30, length 64</div><div class=\"line\">07:41:03.985243 08:00:27:29:bc:de &gt; 08:00:27:d5:4b:b1, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 63, id 32595, offset 0, flags [none], proto IPIP (4), length 104)</div><div class=\"line\">    172.17.8.103 &gt; 172.17.8.101: (tos 0x0, ttl 63, id 42711, offset 0, flags [none], proto ICMP (1), length 84)</div><div class=\"line\">    192.168.43.2 &gt; 192.168.41.2: ICMP echo reply, id 15973, seq 30, length 64</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>ipip相对于非ipip模式会有一些性能的损失，但是好处在于ipip模式下可以进行跨网段的主机间容器通信！将上诉的脚本的两个不同网段的主机上测试可以验证这个结果。</p>\n","excerpt":"","more":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p><a href=\"https://www.projectcalico.org/\">Calico</a>是一个纯3层虚拟网络，可以为夸主机的容器/虚拟机等提供网络访问，同时支持IPv4和IPv6。并且可以根据策略提供访问控制能力。</p>\n<p>Calico的工作原理主要依靠linux本身提供的ip转发机制，不需要虚拟交换设备或者overlay支持。每一个主机都会将自己的路由信息告知数据中心网络中的其他主机：在小型网络中，直接通过BGP协议交换信息；在大型网络中，通过BGP route reflectors完整路由信息的交换。</p>\n<p>Calico为各个不同的云环境提供了不同的插件来使用calico网络，kubernetes和mesos通过CNI插件形式使用calico，docker使用libnetwork插件使用calico网络进行跨主机容器间通信。OpenStack使用Neutron插件使用calico。</p>\n<h1 id=\"入门实践\"><a href=\"#入门实践\" class=\"headerlink\" title=\"入门实践\"></a>入门实践</h1><h2 id=\"环境搭建\"><a href=\"#环境搭建\" class=\"headerlink\" title=\"环境搭建\"></a>环境搭建</h2><p>这里根据<a href=\"http://docs.projectcalico.org/v2.0/getting-started/docker/installation/vagrant-ubuntu/\">官网教程</a>使用vagrant进行docker+calico初始环境搭建。官方文档还提供了手动环境搭建的流程，但是由于一些坑（跨主机容器不能相互访问）放弃了，后来在vagrant上解决了也懒得重新解决一遍了。</p>\n<p>搭建命令如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 需要在主机上有git/vagrant/virtualbox</div><div class=\"line\">git clone https://github.com/projectcalico/calico.git</div><div class=\"line\">cd calico/v2.0/getting-started/docker/installation/vagrant-ubuntu</div><div class=\"line\"># 初始化虚拟机环境，此命令会创建两个主机calico-01/calico-02，且在01上运行了etcd</div><div class=\"line\">vagrant up</div><div class=\"line\"># 验证环境</div><div class=\"line\">vagrant ssh calico-01 # ssh into calico-01 host</div><div class=\"line\">ping 172.17.8.102 # ping calico-02 in calico-01</div><div class=\"line\"># run calico/node</div><div class=\"line\">sudo calico node run</div><div class=\"line\"># 查看运行</div><div class=\"line\">docker ps</div><div class=\"line\">exit # exit from calico-01</div><div class=\"line\">vagrant ssh calico-02 # ssh into calico-02 host</div><div class=\"line\">sudo calico node run</div><div class=\"line\"># 查看BGP信息</div><div class=\"line\">sudo calico node status</div><div class=\"line\">exit</div></pre></td></tr></table></figure>\n<p>上诉能ping通且<code>sudo calico node status</code>能显示对端的信息说明环境搭建成功。</p>\n<h2 id=\"测试工作\"><a href=\"#测试工作\" class=\"headerlink\" title=\"测试工作\"></a>测试工作</h2><p>安装<a href=\"http://docs.projectcalico.org/v2.0/getting-started/docker/tutorials/simple-policy\">官方文档</a>的说明，跨主机的容器通信很简单。只要给docker创建calico的network，然后创建container时设置这个network就可以。具体如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 进入calico-01，创建docker网络</div><div class=\"line\">docker network create --driver calico --ipam-driver calico-ipam net1</div><div class=\"line\"># 创建容器并设置网络为net1</div><div class=\"line\">docker run -d --net net1 --name workload-A busybox tail -f /etc/hosts</div><div class=\"line\"># 查看容器ip地址</div><div class=\"line\">docker exec -it workload-A ip a # 查看到calixxx网络的地址为IP1</div><div class=\"line\"># 进入calico-02，查看docker网络</div><div class=\"line\">docker network ls # 运行这条命令可以看到net1的网络</div><div class=\"line\"># 创建容器</div><div class=\"line\">docker run -d --net net1 --name workload-B busybox tail -f /etc/hosts</div><div class=\"line\"># 在calico-02的容器中ping calico-01的容器地址</div><div class=\"line\">docker exec -it workload-B ping workload-A</div><div class=\"line\">docker exec -it workload-B ping $IP1</div><div class=\"line\"># 也可以直接在calico-02上ping calico-01的容器地址</div><div class=\"line\">ping $IP1</div></pre></td></tr></table></figure>\n<p>按照官方文档的说明，这里应该是能直接ping通的，但是这里就出现了上面一开始就说到的坑，并不能ping通，只有通一个主机的两个container直接可以ping。这个坑我首先在自己的azure上手动安装环境时就遇到了，同事帮忙查看了好久，看了iproute, iptables的各种信息，并用tcpdump进行抓包，但是都无法解决，认为可能是azure的问题。于是我又在自己的机器上安装使用virtualbox安装了两个虚拟机，结果还是一样。最后在Mac上直接使用vagrant也无效。这个问题直接浪费了我至少两天时间。最近同事终于发现原来是iptables会把这些包给drop掉。。。而解决这个问题的方法是需要设置calico的profile和policy对象，使得出入流量可以在两个主机之间互通。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 配置net1网络。在docker创建net1时就创建了这个profile，这里我们更改一些属性！</div><div class=\"line\">cat &lt;&lt; EOF | calicoctl apply -f -</div><div class=\"line\">- apiVersion: v1</div><div class=\"line\">  kind: profile</div><div class=\"line\">  metadata:</div><div class=\"line\">    name: net1</div><div class=\"line\">    labels:</div><div class=\"line\">      role: net1</div><div class=\"line\">EOF</div><div class=\"line\"></div><div class=\"line\"># 为net1创建policy，运行所有出入流量！</div><div class=\"line\">cat &lt;&lt; EOF | calicoctl create -f -</div><div class=\"line\">- apiVersion: v1</div><div class=\"line\">  kind: policy</div><div class=\"line\">  metadata:</div><div class=\"line\">    name: net1</div><div class=\"line\">  spec:</div><div class=\"line\">    order: 0</div><div class=\"line\">    selector: role == &apos;net1&apos;</div><div class=\"line\">    ingress:</div><div class=\"line\">    - action: allow</div><div class=\"line\">    egress:</div><div class=\"line\">    - action: allow</div><div class=\"line\">EOF</div></pre></td></tr></table></figure>\n<p>通过上面的设置，终于可以愉快的跨主机通信了^_^。<br>查看<code>ip route</code>可以发现，本地的ip直接走本地的calico创建的veth设备，其他主机的ip通过网卡直接路由到目标主机ip，然后交给目标主机的路由表处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">default via 10.0.2.2 dev enp0s3</div><div class=\"line\">10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15</div><div class=\"line\">172.17.8.0/24 dev enp0s8  proto kernel  scope link  src 172.17.8.101</div><div class=\"line\">172.18.0.0/16 dev docker0  proto kernel  scope link  src 172.18.0.1 linkdown</div><div class=\"line\"># 目的地址为192.168.50.64/26的请求通过主机上的enp0s8网卡发到172.17.8.102</div><div class=\"line\">192.168.50.64/26 via 172.17.8.102 dev enp0s8  proto bird</div><div class=\"line\">blackhole 192.168.84.192/26  proto bird</div><div class=\"line\"># 本机container直接打到对应设备上</div><div class=\"line\">192.168.84.209 dev calic18c1dc57ca  scope link</div></pre></td></tr></table></figure>\n<h2 id=\"ipip-隧道通信\"><a href=\"#ipip-隧道通信\" class=\"headerlink\" title=\"ipip 隧道通信\"></a>ipip 隧道通信</h2><p>calico支持两个container之间通过ipip隧道通信。在这种模式下，calico会为我们在主机上创建tunl0设备。使用这个设备进行ip封装和拆解。</p>\n<p>在打开ipip选项之前，可以先试用<code>ip link</code>看一下机器上的设备被没有tunl0设备。通过下面步骤打开</p>\n<ol>\n<li>执行<code>calicoctl config set ipip on</code>, 打开设置</li>\n<li>按照<a href=\"http://docs.projectcalico.org/v2.0/usage/troubleshooting/faq#how-do-i-enable-ipip-and-nat-outgoing-on-an-ip-pool\">这里</a>的教程打开ipPool的ipip</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">calicoctl get ipPool -o yaml &gt; pool.yaml</div><div class=\"line\"># 修改spec内容，设置ipip和nat-outgoing</div><div class=\"line\"></div><div class=\"line\">- apiVersion: v1</div><div class=\"line\">  kind: ipPool</div><div class=\"line\">  metadata:</div><div class=\"line\">    cidr: 192.168.0.0/16</div><div class=\"line\">  spec:</div><div class=\"line\">    ipip:</div><div class=\"line\">      enabled: true</div><div class=\"line\">    nat-outgoing: true</div><div class=\"line\"></div><div class=\"line\">calicoctl replace -f pool.yaml</div></pre></td></tr></table></figure>\n<p>通过上诉设置，就打开了calico的ipip支持。查看<code>ip route</code>可以看到和原来的不同:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">default via 10.0.2.2 dev enp0s3</div><div class=\"line\">10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15</div><div class=\"line\">172.17.8.0/24 dev enp0s8  proto kernel  scope link  src 172.17.8.101</div><div class=\"line\">172.18.0.0/16 dev docker0  proto kernel  scope link  src 172.18.0.1 linkdown</div><div class=\"line\"># 注意这里使用到tunl0设备，与前面不同</div><div class=\"line\">192.168.50.64/26 via 172.17.8.102 dev tunl0  proto bird onlink</div><div class=\"line\">blackhole 192.168.84.192/26  proto bird</div><div class=\"line\"># 本机container直接打到对应设备上</div><div class=\"line\">192.168.84.208 dev cali445d36d1804  scope link</div></pre></td></tr></table></figure>\n<p>现在跨主机的通信通过tunl0设备而不是原来的enp0s8设备了。</p>\n<p>这样ping容器时进行<code>tcpdump -i tunl0 icmp</code>可以看到有icmp包。<code>tcpdump -i cali445d36d1804 icmp</code>可以看到流量。</p>\n<p><code>tcpdump -i enp0s8 | grep ipip</code>同样可以看到ipip报文，内容如图所示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">06:35:48.321025 IP 172.17.8.102 &gt; 172.17.8.101: IP 192.168.50.97 &gt; 192.168.84.208: ICMP echo request, id 2304, seq 0, length 64 (ipip-proto-4)</div><div class=\"line\">06:35:48.321149 IP 172.17.8.101 &gt; 172.17.8.102: IP 192.168.84.208 &gt; 192.168.50.97: ICMP echo reply, id 2304, seq 0, length 64 (ipip-proto-4)</div><div class=\"line\">06:35:49.322821 IP 172.17.8.102 &gt; 172.17.8.101: IP 192.168.50.97 &gt; 192.168.84.208: ICMP echo request, id 2304, seq 1, length 64 (ipip-proto-4)</div><div class=\"line\">06:35:49.322900 IP 172.17.8.101 &gt; 172.17.8.102: IP 192.168.84.208 &gt; 192.168.50.97: ICMP echo reply, id 2304, seq 1, length 64 (ipip-proto-4)</div></pre></td></tr></table></figure>\n<h2 id=\"性能测试\"><a href=\"#性能测试\" class=\"headerlink\" title=\"性能测试\"></a>性能测试</h2><p>这里简单的测试了calico网络的性能。测试环境是MacBook上创建的两个虚拟机。calico网络使用networkstatic/iperf3进行性能测试，host之间也适用iperf3测试。测试结果如下：</p>\n<table>\n<thead>\n<tr>\n<th>测试项</th>\n<th>命令</th>\n<th>Bandwidth</th>\n<th>Retr</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>主机网络</td>\n<td><code>iperf3 -c 172.17.8.101 -n 10000M -O 3</code></td>\n<td>2.25 Gbits/sec</td>\n<td>55672</td>\n</tr>\n<tr>\n<td>docker host</td>\n<td><code>docker run --rm -it --net host networkstatic/iperf3 -c 172.17.8.101 -n 10000M -O 3</code></td>\n<td>2.22 Gbits/sec</td>\n<td>55285</td>\n</tr>\n<tr>\n<td>calico</td>\n<td><code>docker run --rm -it --net net1 networkstatic/iperf3 -c 192.168.84.209 -n 10000M -O 3</code></td>\n<td>2.09 Gbits/sec</td>\n<td>36470</td>\n</tr>\n<tr>\n<td>calico-ipip</td>\n<td><code>docker run --rm -it --net net1 networkstatic/iperf3 -c 192.168.84.208 -n 10000M -O 3</code></td>\n<td>2.15 Gbits/sec</td>\n<td>4516</td>\n</tr>\n</tbody>\n</table>\n<p>可以看到ipip的性能还要稍微好于非ipip模式，且在ipip模式下TCP的重传较少。总体来看，对比host模式，calico的性能损失不大。</p>\n<p>对于上面的测试结果（ipip模式比非ipip模式要好）存在疑惑，因为实际上相比于非ipip模式，ipip模式下需要多经历一次ip包的封装。针对这个疑惑我在社区提了个<a href=\"https://github.com/projectcalico/calico/issues/621\">issue</a>。根据回复中的建议在iperf命令中加入了<code>-M 1440</code>设置mtu参数，结果显示非ipip模式实际是要比较好的，这比较符合常理。（注：1440是calico的tunl0的mtu值）</p>\n<h1 id=\"自己动手\"><a href=\"#自己动手\" class=\"headerlink\" title=\"自己动手\"></a>自己动手</h1><p>calico实际上就是对本机容器ip在主机上建立路由，并将这些路由通过bgp协议告知其他主机。通过路由表的信息，达到主机垮主机的容器通信。<br>下面使用同事给的demo使用linux的ip命令工具来模拟calico的非ipip网络和ipip网络。</p>\n<ol>\n<li>首先创建两个虚拟机host1(dev enp0s8:172.17.8.101)和host2(dev enp0s8:172.17.8.102)，检查是否可以相互ping通</li>\n<li><p>在host1上执行以下命令创建容器网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"># netns内部ip, 假设本机上所有container的网段在192.168.41.0/24</div><div class=\"line\">ip=192.168.41.2</div><div class=\"line\">ctn=ctn1</div><div class=\"line\">ip netns add $ctn</div><div class=\"line\">ip li add dev veth_host type veth peer name veth_sbx</div><div class=\"line\">ip link set dev veth_sbx netns $ctn</div><div class=\"line\">ip netns exec $ctn ip ad add $ip dev veth_sbx</div><div class=\"line\">ip netns exec $ctn ip link set dev veth_sbx up</div><div class=\"line\">ip netns exec $ctn ip route add 169.254.1.1 dev veth_sbx</div><div class=\"line\">ip netns exec $ctn ip route add default via 169.254.1.1 dev veth_sbx</div><div class=\"line\">ip netns exec $ctn ip ad</div><div class=\"line\">ip netns exec $ctn ip link set dev veth_sbx up</div><div class=\"line\">ip link set dev veth_host up</div><div class=\"line\">ip ad show veth_host</div><div class=\"line\">ip netns exec $ctn ip neigh add 169.254.1.1 dev veth_sbx lladdr `cat /sys/class/net/veth_host/address` </div><div class=\"line\">ip route add $ip dev veth_host</div><div class=\"line\"># 打开ip_forward</div><div class=\"line\">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</div></pre></td></tr></table></figure>\n</li>\n<li><p>将上诉脚本的ip地址改为192.168.42.2，在host2执行</p>\n</li>\n<li><p>执行以下步骤添加路由表项以达到跨主机container访问</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 在host2执行下面命令</div><div class=\"line\">ip route add 192.168.41.0/24 via 172.17.8.101 dev enp0s8</div><div class=\"line\"># 在host1执行下面命令</div><div class=\"line\">ip route add 192.168.42.0/24 via 172.17.8.102 dev enp0s8</div></pre></td></tr></table></figure>\n</li>\n<li><p>这样就可以在主机或者容器网络空间内ping跨主机的container ip了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 在host1 ping host2的container</div><div class=\"line\">ip netns exec ctn1 ping 192.168.42.2</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>通过上诉步骤，就模拟了calico的默认网络。</p>\n<p>通过之前的描述，calico实际还支持ipip模式的跨主机通信，原理就是通过tunnel设备对原始ip报文进行封装。只需要对上述脚本做一些修改就可以：</p>\n<ol>\n<li>在两台主机上将上诉过程中的第4步添加的路由规则去掉</li>\n<li><p>在host1上执行以下脚本</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">ipip=192.168.41.3</div><div class=\"line\"># 这个命令会生成一个tunl0设备</div><div class=\"line\">modprobe ipip</div><div class=\"line\">ip link set tunl0 up</div><div class=\"line\">ip a add $ipip brd + dev tunl0</div><div class=\"line\"># 注意这里的路由规则，前面已经提到过，使用tunl0设备！最后一个参数onlink是必须的，具体作用参考[这里](http://lartc.vger.kernel.narkive.com/XgcjFTGM/aw-onlink-option-for-ip-route)</div><div class=\"line\">ip r add 192.168.42.0/24 via 172.17.8.102 dev tunl0 proto bird onlink</div></pre></td></tr></table></figure>\n</li>\n<li><p>在host2上执行类似上诉步骤</p>\n</li>\n<li>重新进入网络空间ping跨主机container ip</li>\n<li><p>可以在对端的enp0s8网卡上使用tcpdump进行截包</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">tcpdump -vvnneSs 0 -i enp0s8</div><div class=\"line\"></div><div class=\"line\">07:41:03.985150 08:00:27:d5:4b:b1 &gt; 08:00:27:29:bc:de, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 63, id 55151, offset 0, flags [DF], proto IPIP (4), length 104)</div><div class=\"line\">    172.17.8.101 &gt; 172.17.8.103: (tos 0x0, ttl 63, id 16085, offset 0, flags [DF], proto ICMP (1), length 84)</div><div class=\"line\">    192.168.41.2 &gt; 192.168.43.2: ICMP echo request, id 15973, seq 30, length 64</div><div class=\"line\">07:41:03.985243 08:00:27:29:bc:de &gt; 08:00:27:d5:4b:b1, ethertype IPv4 (0x0800), length 118: (tos 0x0, ttl 63, id 32595, offset 0, flags [none], proto IPIP (4), length 104)</div><div class=\"line\">    172.17.8.103 &gt; 172.17.8.101: (tos 0x0, ttl 63, id 42711, offset 0, flags [none], proto ICMP (1), length 84)</div><div class=\"line\">    192.168.43.2 &gt; 192.168.41.2: ICMP echo reply, id 15973, seq 30, length 64</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>ipip相对于非ipip模式会有一些性能的损失，但是好处在于ipip模式下可以进行跨网段的主机间容器通信！将上诉的脚本的两个不同网段的主机上测试可以验证这个结果。</p>\n"},{"title":"ipvs attempt","date":"2017-04-18T08:45:48.000Z","_content":"\n# 前序\n\nk8s社区最近提了一个[issue](https://github.com/kubernetes/kubernetes/issues/44063), 说的是huawei使用ipvs代替kube-proxy中的iptables模式作为service的负载均衡。根据我们组实际的情况，对ipvs整合k8s方案进行了一些尝试。\n\n为什么希望使用ipvs来替换iptables？\n1. ipvs的目标就是lb，有更多的lb算法支持；而iptables主要作为防火墙软件。\n2. 效率问题：在service较多的情况下，ipvs的效率比iptables要高。原因是在iptables中规则是顺序遍历的，而ipvs使用hash查找对应的规则进行lb。\n\nipvs相关的知识不在这里进行介绍，简单说明一下：\nipvs是L4负载均衡，主要有3种模式：NAT, TUN, DR. 每种都有其优缺点：\n\n1. NAT 模式下会对请求包在LB上进行DNAT，对RS上的回包进行SNAT，NAT本身就消耗资源，另外请求和回复都经过LB，使得请求多的情况下LB会成为瓶颈；另外在架构上，NAT模式要求设置RS的默认路由指向RS，不是很友好。但是能进行端口转化，在k8s里面这是必须的（service-port和pod-port可以不一样）。\n2. TUN 模式使用ip tunnel技术，对到达LB上的请求进行IP封包，再交给RS，RS处理后直接回包到client。这种方式的优势是只要两个节点本身是通的就可以使用这种模式。缺点是增加了tunnel的开销，并且无法做到端口转化。还有就是使用IPIP协议后，无法很好的使用多队列网卡特性来支持多CPU接收数据。\n3. DR(direct-routing) 直接修改请求的目的MAC地址将包路由到RS上，相比于TUN模式减少了tunnel的开销。但是需要LB和RS在同一个子网下，而且也无法做到端口的转化\n\n根据上诉的描述，只有NAT模式支持端口的转化，而在k8s中servicePort和podPort又可以是不同的，所以必然会用到端口转化，所以在这里只能选择NAT模式。下面对NAT进行尝试（探坑），看看是否能够替代iptables满足k8s的需求。\n\n# 实践\n\n现在lvs已经是内核的一部分了，所以一般我们不需要对内核重新编译加入lvs。\n实验环境下我们需要安装ipvsadm命令工具来操作rule。\n\n实验的环境基础采用之前博客里用脚本模拟的calico网络，使用ipip模式进行容器跨节点的通信。\n\n首先确定一个vip模拟serviceIP，需要将这个vip加到本地的网卡上(ipvs需要规则中的地址为本地地址，可以随意选择网卡，如lo设备)\n然后就可以使用ipvsadm在host1上建立NAT规则了。\n\n```shell\nipvsadm -A -t $vip:80 -s rr\nipvsadm -a -t $vip:80 -r $remote_container_ip:8000 -m\n```\n\n非常简单，这样只会在本机的容器网络空间里面就可以通过这个vip访问另一主机上容器中的服务了。\n例如本机ip为host1_ip容器的ip为container1_ip, 远端机器为host2_ip和container2_ip。在container2上启动一个webserver。\n在container1内发起http请求，可以得到结果。\n在host1上进行抓包，这里我们主要观察一下ipvs是如何起作用的，抓包命令为\n`tcpdump -vvnneSs 0 -i any host container1_ip`\n这里选择在host1上观察自己container请求流向，抓包情况如下\n\n1. 首先看到`container1_ip:{随机端口}->vip的请求`\n2. 然后经过ipvs模块的DNAT，请求变成了`container1_ip:{随机端口}->container2_ip`\n3. 然后就是正常的container之间的通信了，即通过tunnel设备进行封装后发送到远程主机处理并返回\n4. 接着看到`container2_ip->container1_ip:{随机端口}`的回来的请求，这里其实已经经过了本机的tunnel进行ipip包的解封了\n5. 回来的包也会被ipvs模块的SNAT处理，将请求改写为`vip->container1_ip:{随机端口}`，最后发送到容器中\n\n可以看出一个来回其实都会经过director-server进行DNAT和SNAT\n\n上面的方法已经走通了container之间跨机service通信，但是有两个缺陷没法解决：\n\n1. 需要往网卡上添加serviceIP，不确定地址太多会不会有额外的问题，暂时可以忽略（看到说可以使用local路由表来实现）\n2. k8s要求可以在节点主机上通过serviceIP对容器进行访问，但是上诉的配置无法做到这一点\n\n针对问题2在上诉的测试环境中进行抓包，发现问题主要出在在主机上发起请求的时候源IP地址也是vip，即如果发起请求`curl $vip`, 其初始的请求会是 `$vip->$vip`(这里涉及到了初始化请求时的地址选择)，然后经过ipvs模块后变成`$vip->container2_ip`并发送到远端，远端抓包可以发现这个请求，但是发现并没有交给用户空间进程进行处理（这里涉及到linux对请求的策略，linux会预判这个请求来回的路径是否一致，如果请求在设备1上接收，但是会在设备2上发出，就判定这个请求可能是不合法的，需要禁止`net.ipv4.rp_filter`），而且这里即使处理也是无法返回的，因为返回的请求是`container2_ip->$vip`,而不是发回给主机1.所以为了解决这个问题，主要需要将主机1请求的源地址进行改写，尝试使用iptables规则后失败了，网上查阅可能的原因是被ipvs处理的流量不会再进入iptables规则，详见[这里](http://zh.linuxvirtualserver.org/node/2245)！后来发现需要开启`net.ipv4.vs.conntrack`，并使用iptables的ipvs匹配模块对请求进行SNAT。\n\n至此，ipvs就可以完成原来iptables对ClusterIP类型service的处理了，而对于NodePort来说更加简单，nodePort的地址已经存在于主机上，可以省略设置ip的步骤。\n\n从上面的步骤来看ipvs可以完成原来iptables的负载均衡工作，目前huawei也已经提交了[PR](https://github.com/kubernetes/kubernetes/pull/46580)和[proposal](https://github.com/kubernetes/community/pull/692)\n\n\n\n\n\n","source":"_posts/2017-04-18-ipvs-attempt.md","raw":"---\ntitle: ipvs attempt\ndate: 2017-04-18 16:45:48\ntags: [network, kubernetes]\n---\n\n# 前序\n\nk8s社区最近提了一个[issue](https://github.com/kubernetes/kubernetes/issues/44063), 说的是huawei使用ipvs代替kube-proxy中的iptables模式作为service的负载均衡。根据我们组实际的情况，对ipvs整合k8s方案进行了一些尝试。\n\n为什么希望使用ipvs来替换iptables？\n1. ipvs的目标就是lb，有更多的lb算法支持；而iptables主要作为防火墙软件。\n2. 效率问题：在service较多的情况下，ipvs的效率比iptables要高。原因是在iptables中规则是顺序遍历的，而ipvs使用hash查找对应的规则进行lb。\n\nipvs相关的知识不在这里进行介绍，简单说明一下：\nipvs是L4负载均衡，主要有3种模式：NAT, TUN, DR. 每种都有其优缺点：\n\n1. NAT 模式下会对请求包在LB上进行DNAT，对RS上的回包进行SNAT，NAT本身就消耗资源，另外请求和回复都经过LB，使得请求多的情况下LB会成为瓶颈；另外在架构上，NAT模式要求设置RS的默认路由指向RS，不是很友好。但是能进行端口转化，在k8s里面这是必须的（service-port和pod-port可以不一样）。\n2. TUN 模式使用ip tunnel技术，对到达LB上的请求进行IP封包，再交给RS，RS处理后直接回包到client。这种方式的优势是只要两个节点本身是通的就可以使用这种模式。缺点是增加了tunnel的开销，并且无法做到端口转化。还有就是使用IPIP协议后，无法很好的使用多队列网卡特性来支持多CPU接收数据。\n3. DR(direct-routing) 直接修改请求的目的MAC地址将包路由到RS上，相比于TUN模式减少了tunnel的开销。但是需要LB和RS在同一个子网下，而且也无法做到端口的转化\n\n根据上诉的描述，只有NAT模式支持端口的转化，而在k8s中servicePort和podPort又可以是不同的，所以必然会用到端口转化，所以在这里只能选择NAT模式。下面对NAT进行尝试（探坑），看看是否能够替代iptables满足k8s的需求。\n\n# 实践\n\n现在lvs已经是内核的一部分了，所以一般我们不需要对内核重新编译加入lvs。\n实验环境下我们需要安装ipvsadm命令工具来操作rule。\n\n实验的环境基础采用之前博客里用脚本模拟的calico网络，使用ipip模式进行容器跨节点的通信。\n\n首先确定一个vip模拟serviceIP，需要将这个vip加到本地的网卡上(ipvs需要规则中的地址为本地地址，可以随意选择网卡，如lo设备)\n然后就可以使用ipvsadm在host1上建立NAT规则了。\n\n```shell\nipvsadm -A -t $vip:80 -s rr\nipvsadm -a -t $vip:80 -r $remote_container_ip:8000 -m\n```\n\n非常简单，这样只会在本机的容器网络空间里面就可以通过这个vip访问另一主机上容器中的服务了。\n例如本机ip为host1_ip容器的ip为container1_ip, 远端机器为host2_ip和container2_ip。在container2上启动一个webserver。\n在container1内发起http请求，可以得到结果。\n在host1上进行抓包，这里我们主要观察一下ipvs是如何起作用的，抓包命令为\n`tcpdump -vvnneSs 0 -i any host container1_ip`\n这里选择在host1上观察自己container请求流向，抓包情况如下\n\n1. 首先看到`container1_ip:{随机端口}->vip的请求`\n2. 然后经过ipvs模块的DNAT，请求变成了`container1_ip:{随机端口}->container2_ip`\n3. 然后就是正常的container之间的通信了，即通过tunnel设备进行封装后发送到远程主机处理并返回\n4. 接着看到`container2_ip->container1_ip:{随机端口}`的回来的请求，这里其实已经经过了本机的tunnel进行ipip包的解封了\n5. 回来的包也会被ipvs模块的SNAT处理，将请求改写为`vip->container1_ip:{随机端口}`，最后发送到容器中\n\n可以看出一个来回其实都会经过director-server进行DNAT和SNAT\n\n上面的方法已经走通了container之间跨机service通信，但是有两个缺陷没法解决：\n\n1. 需要往网卡上添加serviceIP，不确定地址太多会不会有额外的问题，暂时可以忽略（看到说可以使用local路由表来实现）\n2. k8s要求可以在节点主机上通过serviceIP对容器进行访问，但是上诉的配置无法做到这一点\n\n针对问题2在上诉的测试环境中进行抓包，发现问题主要出在在主机上发起请求的时候源IP地址也是vip，即如果发起请求`curl $vip`, 其初始的请求会是 `$vip->$vip`(这里涉及到了初始化请求时的地址选择)，然后经过ipvs模块后变成`$vip->container2_ip`并发送到远端，远端抓包可以发现这个请求，但是发现并没有交给用户空间进程进行处理（这里涉及到linux对请求的策略，linux会预判这个请求来回的路径是否一致，如果请求在设备1上接收，但是会在设备2上发出，就判定这个请求可能是不合法的，需要禁止`net.ipv4.rp_filter`），而且这里即使处理也是无法返回的，因为返回的请求是`container2_ip->$vip`,而不是发回给主机1.所以为了解决这个问题，主要需要将主机1请求的源地址进行改写，尝试使用iptables规则后失败了，网上查阅可能的原因是被ipvs处理的流量不会再进入iptables规则，详见[这里](http://zh.linuxvirtualserver.org/node/2245)！后来发现需要开启`net.ipv4.vs.conntrack`，并使用iptables的ipvs匹配模块对请求进行SNAT。\n\n至此，ipvs就可以完成原来iptables对ClusterIP类型service的处理了，而对于NodePort来说更加简单，nodePort的地址已经存在于主机上，可以省略设置ip的步骤。\n\n从上面的步骤来看ipvs可以完成原来iptables的负载均衡工作，目前huawei也已经提交了[PR](https://github.com/kubernetes/kubernetes/pull/46580)和[proposal](https://github.com/kubernetes/community/pull/692)\n\n\n\n\n\n","slug":"ipvs-attempt","published":1,"updated":"2017-06-22T08:53:43.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asaqih001bphv9w58bdl9v","content":"<h1 id=\"前序\"><a href=\"#前序\" class=\"headerlink\" title=\"前序\"></a>前序</h1><p>k8s社区最近提了一个<a href=\"https://github.com/kubernetes/kubernetes/issues/44063\" target=\"_blank\" rel=\"external\">issue</a>, 说的是huawei使用ipvs代替kube-proxy中的iptables模式作为service的负载均衡。根据我们组实际的情况，对ipvs整合k8s方案进行了一些尝试。</p>\n<p>为什么希望使用ipvs来替换iptables？</p>\n<ol>\n<li>ipvs的目标就是lb，有更多的lb算法支持；而iptables主要作为防火墙软件。</li>\n<li>效率问题：在service较多的情况下，ipvs的效率比iptables要高。原因是在iptables中规则是顺序遍历的，而ipvs使用hash查找对应的规则进行lb。</li>\n</ol>\n<p>ipvs相关的知识不在这里进行介绍，简单说明一下：<br>ipvs是L4负载均衡，主要有3种模式：NAT, TUN, DR. 每种都有其优缺点：</p>\n<ol>\n<li>NAT 模式下会对请求包在LB上进行DNAT，对RS上的回包进行SNAT，NAT本身就消耗资源，另外请求和回复都经过LB，使得请求多的情况下LB会成为瓶颈；另外在架构上，NAT模式要求设置RS的默认路由指向RS，不是很友好。但是能进行端口转化，在k8s里面这是必须的（service-port和pod-port可以不一样）。</li>\n<li>TUN 模式使用ip tunnel技术，对到达LB上的请求进行IP封包，再交给RS，RS处理后直接回包到client。这种方式的优势是只要两个节点本身是通的就可以使用这种模式。缺点是增加了tunnel的开销，并且无法做到端口转化。还有就是使用IPIP协议后，无法很好的使用多队列网卡特性来支持多CPU接收数据。</li>\n<li>DR(direct-routing) 直接修改请求的目的MAC地址将包路由到RS上，相比于TUN模式减少了tunnel的开销。但是需要LB和RS在同一个子网下，而且也无法做到端口的转化</li>\n</ol>\n<p>根据上诉的描述，只有NAT模式支持端口的转化，而在k8s中servicePort和podPort又可以是不同的，所以必然会用到端口转化，所以在这里只能选择NAT模式。下面对NAT进行尝试（探坑），看看是否能够替代iptables满足k8s的需求。</p>\n<h1 id=\"实践\"><a href=\"#实践\" class=\"headerlink\" title=\"实践\"></a>实践</h1><p>现在lvs已经是内核的一部分了，所以一般我们不需要对内核重新编译加入lvs。<br>实验环境下我们需要安装ipvsadm命令工具来操作rule。</p>\n<p>实验的环境基础采用之前博客里用脚本模拟的calico网络，使用ipip模式进行容器跨节点的通信。</p>\n<p>首先确定一个vip模拟serviceIP，需要将这个vip加到本地的网卡上(ipvs需要规则中的地址为本地地址，可以随意选择网卡，如lo设备)<br>然后就可以使用ipvsadm在host1上建立NAT规则了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ipvsadm -A -t $vip:80 -s rr</div><div class=\"line\">ipvsadm -a -t $vip:80 -r $remote_container_ip:8000 -m</div></pre></td></tr></table></figure>\n<p>非常简单，这样只会在本机的容器网络空间里面就可以通过这个vip访问另一主机上容器中的服务了。<br>例如本机ip为host1_ip容器的ip为container1_ip, 远端机器为host2_ip和container2_ip。在container2上启动一个webserver。<br>在container1内发起http请求，可以得到结果。<br>在host1上进行抓包，这里我们主要观察一下ipvs是如何起作用的，抓包命令为<br><code>tcpdump -vvnneSs 0 -i any host container1_ip</code><br>这里选择在host1上观察自己container请求流向，抓包情况如下</p>\n<ol>\n<li>首先看到<code>container1_ip:{随机端口}-&gt;vip的请求</code></li>\n<li>然后经过ipvs模块的DNAT，请求变成了<code>container1_ip:{随机端口}-&gt;container2_ip</code></li>\n<li>然后就是正常的container之间的通信了，即通过tunnel设备进行封装后发送到远程主机处理并返回</li>\n<li>接着看到<code>container2_ip-&gt;container1_ip:{随机端口}</code>的回来的请求，这里其实已经经过了本机的tunnel进行ipip包的解封了</li>\n<li>回来的包也会被ipvs模块的SNAT处理，将请求改写为<code>vip-&gt;container1_ip:{随机端口}</code>，最后发送到容器中</li>\n</ol>\n<p>可以看出一个来回其实都会经过director-server进行DNAT和SNAT</p>\n<p>上面的方法已经走通了container之间跨机service通信，但是有两个缺陷没法解决：</p>\n<ol>\n<li>需要往网卡上添加serviceIP，不确定地址太多会不会有额外的问题，暂时可以忽略（看到说可以使用local路由表来实现）</li>\n<li>k8s要求可以在节点主机上通过serviceIP对容器进行访问，但是上诉的配置无法做到这一点</li>\n</ol>\n<p>针对问题2在上诉的测试环境中进行抓包，发现问题主要出在在主机上发起请求的时候源IP地址也是vip，即如果发起请求<code>curl $vip</code>, 其初始的请求会是 <code>$vip-&gt;$vip</code>(这里涉及到了初始化请求时的地址选择)，然后经过ipvs模块后变成<code>$vip-&gt;container2_ip</code>并发送到远端，远端抓包可以发现这个请求，但是发现并没有交给用户空间进程进行处理（这里涉及到linux对请求的策略，linux会预判这个请求来回的路径是否一致，如果请求在设备1上接收，但是会在设备2上发出，就判定这个请求可能是不合法的，需要禁止<code>net.ipv4.rp_filter</code>），而且这里即使处理也是无法返回的，因为返回的请求是<code>container2_ip-&gt;$vip</code>,而不是发回给主机1.所以为了解决这个问题，主要需要将主机1请求的源地址进行改写，尝试使用iptables规则后失败了，网上查阅可能的原因是被ipvs处理的流量不会再进入iptables规则，详见<a href=\"http://zh.linuxvirtualserver.org/node/2245\" target=\"_blank\" rel=\"external\">这里</a>！后来发现需要开启<code>net.ipv4.vs.conntrack</code>，并使用iptables的ipvs匹配模块对请求进行SNAT。</p>\n<p>至此，ipvs就可以完成原来iptables对ClusterIP类型service的处理了，而对于NodePort来说更加简单，nodePort的地址已经存在于主机上，可以省略设置ip的步骤。</p>\n<p>从上面的步骤来看ipvs可以完成原来iptables的负载均衡工作，目前huawei也已经提交了<a href=\"https://github.com/kubernetes/kubernetes/pull/46580\" target=\"_blank\" rel=\"external\">PR</a>和<a href=\"https://github.com/kubernetes/community/pull/692\" target=\"_blank\" rel=\"external\">proposal</a></p>\n","excerpt":"","more":"<h1 id=\"前序\"><a href=\"#前序\" class=\"headerlink\" title=\"前序\"></a>前序</h1><p>k8s社区最近提了一个<a href=\"https://github.com/kubernetes/kubernetes/issues/44063\">issue</a>, 说的是huawei使用ipvs代替kube-proxy中的iptables模式作为service的负载均衡。根据我们组实际的情况，对ipvs整合k8s方案进行了一些尝试。</p>\n<p>为什么希望使用ipvs来替换iptables？</p>\n<ol>\n<li>ipvs的目标就是lb，有更多的lb算法支持；而iptables主要作为防火墙软件。</li>\n<li>效率问题：在service较多的情况下，ipvs的效率比iptables要高。原因是在iptables中规则是顺序遍历的，而ipvs使用hash查找对应的规则进行lb。</li>\n</ol>\n<p>ipvs相关的知识不在这里进行介绍，简单说明一下：<br>ipvs是L4负载均衡，主要有3种模式：NAT, TUN, DR. 每种都有其优缺点：</p>\n<ol>\n<li>NAT 模式下会对请求包在LB上进行DNAT，对RS上的回包进行SNAT，NAT本身就消耗资源，另外请求和回复都经过LB，使得请求多的情况下LB会成为瓶颈；另外在架构上，NAT模式要求设置RS的默认路由指向RS，不是很友好。但是能进行端口转化，在k8s里面这是必须的（service-port和pod-port可以不一样）。</li>\n<li>TUN 模式使用ip tunnel技术，对到达LB上的请求进行IP封包，再交给RS，RS处理后直接回包到client。这种方式的优势是只要两个节点本身是通的就可以使用这种模式。缺点是增加了tunnel的开销，并且无法做到端口转化。还有就是使用IPIP协议后，无法很好的使用多队列网卡特性来支持多CPU接收数据。</li>\n<li>DR(direct-routing) 直接修改请求的目的MAC地址将包路由到RS上，相比于TUN模式减少了tunnel的开销。但是需要LB和RS在同一个子网下，而且也无法做到端口的转化</li>\n</ol>\n<p>根据上诉的描述，只有NAT模式支持端口的转化，而在k8s中servicePort和podPort又可以是不同的，所以必然会用到端口转化，所以在这里只能选择NAT模式。下面对NAT进行尝试（探坑），看看是否能够替代iptables满足k8s的需求。</p>\n<h1 id=\"实践\"><a href=\"#实践\" class=\"headerlink\" title=\"实践\"></a>实践</h1><p>现在lvs已经是内核的一部分了，所以一般我们不需要对内核重新编译加入lvs。<br>实验环境下我们需要安装ipvsadm命令工具来操作rule。</p>\n<p>实验的环境基础采用之前博客里用脚本模拟的calico网络，使用ipip模式进行容器跨节点的通信。</p>\n<p>首先确定一个vip模拟serviceIP，需要将这个vip加到本地的网卡上(ipvs需要规则中的地址为本地地址，可以随意选择网卡，如lo设备)<br>然后就可以使用ipvsadm在host1上建立NAT规则了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ipvsadm -A -t $vip:80 -s rr</div><div class=\"line\">ipvsadm -a -t $vip:80 -r $remote_container_ip:8000 -m</div></pre></td></tr></table></figure>\n<p>非常简单，这样只会在本机的容器网络空间里面就可以通过这个vip访问另一主机上容器中的服务了。<br>例如本机ip为host1_ip容器的ip为container1_ip, 远端机器为host2_ip和container2_ip。在container2上启动一个webserver。<br>在container1内发起http请求，可以得到结果。<br>在host1上进行抓包，这里我们主要观察一下ipvs是如何起作用的，抓包命令为<br><code>tcpdump -vvnneSs 0 -i any host container1_ip</code><br>这里选择在host1上观察自己container请求流向，抓包情况如下</p>\n<ol>\n<li>首先看到<code>container1_ip:{随机端口}-&gt;vip的请求</code></li>\n<li>然后经过ipvs模块的DNAT，请求变成了<code>container1_ip:{随机端口}-&gt;container2_ip</code></li>\n<li>然后就是正常的container之间的通信了，即通过tunnel设备进行封装后发送到远程主机处理并返回</li>\n<li>接着看到<code>container2_ip-&gt;container1_ip:{随机端口}</code>的回来的请求，这里其实已经经过了本机的tunnel进行ipip包的解封了</li>\n<li>回来的包也会被ipvs模块的SNAT处理，将请求改写为<code>vip-&gt;container1_ip:{随机端口}</code>，最后发送到容器中</li>\n</ol>\n<p>可以看出一个来回其实都会经过director-server进行DNAT和SNAT</p>\n<p>上面的方法已经走通了container之间跨机service通信，但是有两个缺陷没法解决：</p>\n<ol>\n<li>需要往网卡上添加serviceIP，不确定地址太多会不会有额外的问题，暂时可以忽略（看到说可以使用local路由表来实现）</li>\n<li>k8s要求可以在节点主机上通过serviceIP对容器进行访问，但是上诉的配置无法做到这一点</li>\n</ol>\n<p>针对问题2在上诉的测试环境中进行抓包，发现问题主要出在在主机上发起请求的时候源IP地址也是vip，即如果发起请求<code>curl $vip</code>, 其初始的请求会是 <code>$vip-&gt;$vip</code>(这里涉及到了初始化请求时的地址选择)，然后经过ipvs模块后变成<code>$vip-&gt;container2_ip</code>并发送到远端，远端抓包可以发现这个请求，但是发现并没有交给用户空间进程进行处理（这里涉及到linux对请求的策略，linux会预判这个请求来回的路径是否一致，如果请求在设备1上接收，但是会在设备2上发出，就判定这个请求可能是不合法的，需要禁止<code>net.ipv4.rp_filter</code>），而且这里即使处理也是无法返回的，因为返回的请求是<code>container2_ip-&gt;$vip</code>,而不是发回给主机1.所以为了解决这个问题，主要需要将主机1请求的源地址进行改写，尝试使用iptables规则后失败了，网上查阅可能的原因是被ipvs处理的流量不会再进入iptables规则，详见<a href=\"http://zh.linuxvirtualserver.org/node/2245\">这里</a>！后来发现需要开启<code>net.ipv4.vs.conntrack</code>，并使用iptables的ipvs匹配模块对请求进行SNAT。</p>\n<p>至此，ipvs就可以完成原来iptables对ClusterIP类型service的处理了，而对于NodePort来说更加简单，nodePort的地址已经存在于主机上，可以省略设置ip的步骤。</p>\n<p>从上面的步骤来看ipvs可以完成原来iptables的负载均衡工作，目前huawei也已经提交了<a href=\"https://github.com/kubernetes/kubernetes/pull/46580\">PR</a>和<a href=\"https://github.com/kubernetes/community/pull/692\">proposal</a></p>\n"},{"title":"sriov getting start","date":"2017-06-22T03:28:56.000Z","_content":"\n# 前言\n\n最近在调研SR-IOV的使用，准备作为CNI插件用在kubernetes的Pod网络上。这篇文章是对SRIOV基础操作的介绍，通过介绍可以了解SRIOV的使用。\n\n# 简介\n\nSR-IOV是网卡支持的一种硬件IO虚拟化方案，简单的说就是可以将一个物理网卡虚拟成多个物理网卡设备。\nSR-IOV引入了PFs(physical functions)和VFs(virtual functions)的概念，每个VF都可以看做是一个独立的物理网卡(PCIe设备)可以被容器或虚拟机直接访问，从而提升性能。相比于传统的veth+bridge实现容器网络，除了性能上的优势之外，SR-IOV的另一个优点就是隔离性好，各个VF是独立的，发往VF的请求不会经过PF，所以不会被主机上的PF网卡嗅探到。\n\n# 使用\n\n当前公司的物理机一般都支持SR-IOV，但是并未开启。各个网卡类型支持的VF数量不同，在使用之前通过以下命令先查看物理网卡eth1最多支持几个VF\n`cat /sys/class/net/eth1/device/sriov_totalvfs`\n\n根据需要开启vf设备如开启7个vf设备\n`echo 7 > /sys/class/net/eth1/device/sriov_numvfs`\n\n开启之后，在机器上`ip link`就可以看到新增了7个设备ethX。\n\n这里需要注意VF设备是不能增量添加的，如果需要修改启动的VF数量，需要先将sriov_numvfs值重置为0后再重新设置为目标值，所以在使用SR-IOV功能最好能确定最多会使用到几个VF，以防在业务运行过程中需要扩展VF数影响正在使用VF的业务。\n\n开启SR-IOV功能后，在/sys/class/net/eth1/device目录下会多出多个virtfnX的目录，这些目录下分别记录了对应VF的信息，例如可以通过`ls /sys/class/net/eth1/device/virtfn*/net`显示对应vf设备名称,如下图所示：\n\n![sriov](/images/sriov01.png)\n\n如果VF已经被放入了其他网络名字空间，那么net目录下会显示为空，例如上图中的virtfn0。\n\n容器使用vf设备，只需要使用`ip link set dev $VF netns $NET_NS`将vf设备放入容器所在网络名字空间，配置浮动IP和对应路由规则并将设备UP即可。\n\n通过上诉的说明，已经可以使用VF为容器提供网络功能了。\n\n# 优化\n\n实验过程中发现开启SR-IOV后会对原先的多队列网卡有影响（关于多队列网卡这里不做介绍）。在开启之前，eth1根据不同网卡型号可能有8-24个队列，开启之后接收队列会可能会减少到两个，且此时默认情况下所有vf的硬中断都会集中在同一个CPU上，导致在请求较多的情况下使得CPU成为可能存在的瓶颈。为了缓解这个问题，可以将各个vf的队列分布到不同的CPU上处理。首先通过以下命令得到各个vf的中断号\n`ls /sys/class/net/eth1/device/virtfn0/msi_irqs/`\n如果知道vf设备名称，也可以直接`ls /sys/class/net/eth4/device/msi_irqs/`获取中断号，不过这种方式需要设备在当前网络空间，如果设备在容器里，主机上是没有eth4这个目录的。\n得知中断号后可以给中断号绑定不同的CPU，以下命令将将中断号为77的硬中断交给CPU1处理\n`echo 1 > /proc/irq/77/smp_affinity_list`\n\n除了设置硬中断CPU，根据业务场景需要，还可以使用CPU位掩码将网卡队列的软中断处理均衡到不同的CPU上，例如`echo f > /sys/class/net/$dev/queues/rx-0/rps_cpus`将$dev的接收队列rx-0发生的软中断绑定到0-3号CPU上\n\n# 性能测试\n\n使用SR-IOV的一个主要原因就是因为它通过硬件虚拟化来加速容器收包的速度，所以需要对性能进行验证。\n\n由于资源条件限制，我们只拿到了一台支持sriov的万兆网卡机器，为了测试其性能，我们同时用6个千兆网卡机器使用netperf进行性能对比测试。\n在万兆网卡上，根据虚拟比1:6启动了6个网络名字空间，每个名字空间内启动一个netserver。\n在6个客户端上，分别为每个容器启动200个netperf进程，分别测试TCP_RR(64,64)和TCP_CRR(64,64)在使用SR-IOV和veth+bridge模式下的性能。\n测试结果：\n在开启sriov后，TCP_RR包量达到108万，相对于veth+bridge方式提升约15%. TCP_CRR包量达到8.1万，相对于veth+bridge方法提升约10%\n\n# CNI插件\n\n这部分工作其实[社区](https://github.com/Intel-Corp/sriov-cni)已经有了，我们在做的时候也参考了它的代码实现。思路很简单，在初次使用时将SR-IOV功能开启，为容器分配网络时从主机上挑选一个未使用的VF给容器使用，设置floatingip和相关路由，最后UP。当删除容器网络时，将设备重命名并归还到主机上即可。","source":"_posts/2017-06-22-sriov-getting-start.md","raw":"---\ntitle: sriov getting start\ndate: 2017-06-22 11:28:56\ntags: [network]\n---\n\n# 前言\n\n最近在调研SR-IOV的使用，准备作为CNI插件用在kubernetes的Pod网络上。这篇文章是对SRIOV基础操作的介绍，通过介绍可以了解SRIOV的使用。\n\n# 简介\n\nSR-IOV是网卡支持的一种硬件IO虚拟化方案，简单的说就是可以将一个物理网卡虚拟成多个物理网卡设备。\nSR-IOV引入了PFs(physical functions)和VFs(virtual functions)的概念，每个VF都可以看做是一个独立的物理网卡(PCIe设备)可以被容器或虚拟机直接访问，从而提升性能。相比于传统的veth+bridge实现容器网络，除了性能上的优势之外，SR-IOV的另一个优点就是隔离性好，各个VF是独立的，发往VF的请求不会经过PF，所以不会被主机上的PF网卡嗅探到。\n\n# 使用\n\n当前公司的物理机一般都支持SR-IOV，但是并未开启。各个网卡类型支持的VF数量不同，在使用之前通过以下命令先查看物理网卡eth1最多支持几个VF\n`cat /sys/class/net/eth1/device/sriov_totalvfs`\n\n根据需要开启vf设备如开启7个vf设备\n`echo 7 > /sys/class/net/eth1/device/sriov_numvfs`\n\n开启之后，在机器上`ip link`就可以看到新增了7个设备ethX。\n\n这里需要注意VF设备是不能增量添加的，如果需要修改启动的VF数量，需要先将sriov_numvfs值重置为0后再重新设置为目标值，所以在使用SR-IOV功能最好能确定最多会使用到几个VF，以防在业务运行过程中需要扩展VF数影响正在使用VF的业务。\n\n开启SR-IOV功能后，在/sys/class/net/eth1/device目录下会多出多个virtfnX的目录，这些目录下分别记录了对应VF的信息，例如可以通过`ls /sys/class/net/eth1/device/virtfn*/net`显示对应vf设备名称,如下图所示：\n\n![sriov](/images/sriov01.png)\n\n如果VF已经被放入了其他网络名字空间，那么net目录下会显示为空，例如上图中的virtfn0。\n\n容器使用vf设备，只需要使用`ip link set dev $VF netns $NET_NS`将vf设备放入容器所在网络名字空间，配置浮动IP和对应路由规则并将设备UP即可。\n\n通过上诉的说明，已经可以使用VF为容器提供网络功能了。\n\n# 优化\n\n实验过程中发现开启SR-IOV后会对原先的多队列网卡有影响（关于多队列网卡这里不做介绍）。在开启之前，eth1根据不同网卡型号可能有8-24个队列，开启之后接收队列会可能会减少到两个，且此时默认情况下所有vf的硬中断都会集中在同一个CPU上，导致在请求较多的情况下使得CPU成为可能存在的瓶颈。为了缓解这个问题，可以将各个vf的队列分布到不同的CPU上处理。首先通过以下命令得到各个vf的中断号\n`ls /sys/class/net/eth1/device/virtfn0/msi_irqs/`\n如果知道vf设备名称，也可以直接`ls /sys/class/net/eth4/device/msi_irqs/`获取中断号，不过这种方式需要设备在当前网络空间，如果设备在容器里，主机上是没有eth4这个目录的。\n得知中断号后可以给中断号绑定不同的CPU，以下命令将将中断号为77的硬中断交给CPU1处理\n`echo 1 > /proc/irq/77/smp_affinity_list`\n\n除了设置硬中断CPU，根据业务场景需要，还可以使用CPU位掩码将网卡队列的软中断处理均衡到不同的CPU上，例如`echo f > /sys/class/net/$dev/queues/rx-0/rps_cpus`将$dev的接收队列rx-0发生的软中断绑定到0-3号CPU上\n\n# 性能测试\n\n使用SR-IOV的一个主要原因就是因为它通过硬件虚拟化来加速容器收包的速度，所以需要对性能进行验证。\n\n由于资源条件限制，我们只拿到了一台支持sriov的万兆网卡机器，为了测试其性能，我们同时用6个千兆网卡机器使用netperf进行性能对比测试。\n在万兆网卡上，根据虚拟比1:6启动了6个网络名字空间，每个名字空间内启动一个netserver。\n在6个客户端上，分别为每个容器启动200个netperf进程，分别测试TCP_RR(64,64)和TCP_CRR(64,64)在使用SR-IOV和veth+bridge模式下的性能。\n测试结果：\n在开启sriov后，TCP_RR包量达到108万，相对于veth+bridge方式提升约15%. TCP_CRR包量达到8.1万，相对于veth+bridge方法提升约10%\n\n# CNI插件\n\n这部分工作其实[社区](https://github.com/Intel-Corp/sriov-cni)已经有了，我们在做的时候也参考了它的代码实现。思路很简单，在初次使用时将SR-IOV功能开启，为容器分配网络时从主机上挑选一个未使用的VF给容器使用，设置floatingip和相关路由，最后UP。当删除容器网络时，将设备重命名并归还到主机上即可。","slug":"sriov-getting-start","published":1,"updated":"2017-06-22T09:13:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asaqii001ephv96cmwtzsr","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>最近在调研SR-IOV的使用，准备作为CNI插件用在kubernetes的Pod网络上。这篇文章是对SRIOV基础操作的介绍，通过介绍可以了解SRIOV的使用。</p>\n<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>SR-IOV是网卡支持的一种硬件IO虚拟化方案，简单的说就是可以将一个物理网卡虚拟成多个物理网卡设备。<br>SR-IOV引入了PFs(physical functions)和VFs(virtual functions)的概念，每个VF都可以看做是一个独立的物理网卡(PCIe设备)可以被容器或虚拟机直接访问，从而提升性能。相比于传统的veth+bridge实现容器网络，除了性能上的优势之外，SR-IOV的另一个优点就是隔离性好，各个VF是独立的，发往VF的请求不会经过PF，所以不会被主机上的PF网卡嗅探到。</p>\n<h1 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h1><p>当前公司的物理机一般都支持SR-IOV，但是并未开启。各个网卡类型支持的VF数量不同，在使用之前通过以下命令先查看物理网卡eth1最多支持几个VF<br><code>cat /sys/class/net/eth1/device/sriov_totalvfs</code></p>\n<p>根据需要开启vf设备如开启7个vf设备<br><code>echo 7 &gt; /sys/class/net/eth1/device/sriov_numvfs</code></p>\n<p>开启之后，在机器上<code>ip link</code>就可以看到新增了7个设备ethX。</p>\n<p>这里需要注意VF设备是不能增量添加的，如果需要修改启动的VF数量，需要先将sriov_numvfs值重置为0后再重新设置为目标值，所以在使用SR-IOV功能最好能确定最多会使用到几个VF，以防在业务运行过程中需要扩展VF数影响正在使用VF的业务。</p>\n<p>开启SR-IOV功能后，在/sys/class/net/eth1/device目录下会多出多个virtfnX的目录，这些目录下分别记录了对应VF的信息，例如可以通过<code>ls /sys/class/net/eth1/device/virtfn*/net</code>显示对应vf设备名称,如下图所示：</p>\n<p><img src=\"/images/sriov01.png\" alt=\"sriov\"></p>\n<p>如果VF已经被放入了其他网络名字空间，那么net目录下会显示为空，例如上图中的virtfn0。</p>\n<p>容器使用vf设备，只需要使用<code>ip link set dev $VF netns $NET_NS</code>将vf设备放入容器所在网络名字空间，配置浮动IP和对应路由规则并将设备UP即可。</p>\n<p>通过上诉的说明，已经可以使用VF为容器提供网络功能了。</p>\n<h1 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h1><p>实验过程中发现开启SR-IOV后会对原先的多队列网卡有影响（关于多队列网卡这里不做介绍）。在开启之前，eth1根据不同网卡型号可能有8-24个队列，开启之后接收队列会可能会减少到两个，且此时默认情况下所有vf的硬中断都会集中在同一个CPU上，导致在请求较多的情况下使得CPU成为可能存在的瓶颈。为了缓解这个问题，可以将各个vf的队列分布到不同的CPU上处理。首先通过以下命令得到各个vf的中断号<br><code>ls /sys/class/net/eth1/device/virtfn0/msi_irqs/</code><br>如果知道vf设备名称，也可以直接<code>ls /sys/class/net/eth4/device/msi_irqs/</code>获取中断号，不过这种方式需要设备在当前网络空间，如果设备在容器里，主机上是没有eth4这个目录的。<br>得知中断号后可以给中断号绑定不同的CPU，以下命令将将中断号为77的硬中断交给CPU1处理<br><code>echo 1 &gt; /proc/irq/77/smp_affinity_list</code></p>\n<p>除了设置硬中断CPU，根据业务场景需要，还可以使用CPU位掩码将网卡队列的软中断处理均衡到不同的CPU上，例如<code>echo f &gt; /sys/class/net/$dev/queues/rx-0/rps_cpus</code>将$dev的接收队列rx-0发生的软中断绑定到0-3号CPU上</p>\n<h1 id=\"性能测试\"><a href=\"#性能测试\" class=\"headerlink\" title=\"性能测试\"></a>性能测试</h1><p>使用SR-IOV的一个主要原因就是因为它通过硬件虚拟化来加速容器收包的速度，所以需要对性能进行验证。</p>\n<p>由于资源条件限制，我们只拿到了一台支持sriov的万兆网卡机器，为了测试其性能，我们同时用6个千兆网卡机器使用netperf进行性能对比测试。<br>在万兆网卡上，根据虚拟比1:6启动了6个网络名字空间，每个名字空间内启动一个netserver。<br>在6个客户端上，分别为每个容器启动200个netperf进程，分别测试TCP_RR(64,64)和TCP_CRR(64,64)在使用SR-IOV和veth+bridge模式下的性能。<br>测试结果：<br>在开启sriov后，TCP_RR包量达到108万，相对于veth+bridge方式提升约15%. TCP_CRR包量达到8.1万，相对于veth+bridge方法提升约10%</p>\n<h1 id=\"CNI插件\"><a href=\"#CNI插件\" class=\"headerlink\" title=\"CNI插件\"></a>CNI插件</h1><p>这部分工作其实<a href=\"https://github.com/Intel-Corp/sriov-cni\" target=\"_blank\" rel=\"external\">社区</a>已经有了，我们在做的时候也参考了它的代码实现。思路很简单，在初次使用时将SR-IOV功能开启，为容器分配网络时从主机上挑选一个未使用的VF给容器使用，设置floatingip和相关路由，最后UP。当删除容器网络时，将设备重命名并归还到主机上即可。</p>\n","excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>最近在调研SR-IOV的使用，准备作为CNI插件用在kubernetes的Pod网络上。这篇文章是对SRIOV基础操作的介绍，通过介绍可以了解SRIOV的使用。</p>\n<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>SR-IOV是网卡支持的一种硬件IO虚拟化方案，简单的说就是可以将一个物理网卡虚拟成多个物理网卡设备。<br>SR-IOV引入了PFs(physical functions)和VFs(virtual functions)的概念，每个VF都可以看做是一个独立的物理网卡(PCIe设备)可以被容器或虚拟机直接访问，从而提升性能。相比于传统的veth+bridge实现容器网络，除了性能上的优势之外，SR-IOV的另一个优点就是隔离性好，各个VF是独立的，发往VF的请求不会经过PF，所以不会被主机上的PF网卡嗅探到。</p>\n<h1 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h1><p>当前公司的物理机一般都支持SR-IOV，但是并未开启。各个网卡类型支持的VF数量不同，在使用之前通过以下命令先查看物理网卡eth1最多支持几个VF<br><code>cat /sys/class/net/eth1/device/sriov_totalvfs</code></p>\n<p>根据需要开启vf设备如开启7个vf设备<br><code>echo 7 &gt; /sys/class/net/eth1/device/sriov_numvfs</code></p>\n<p>开启之后，在机器上<code>ip link</code>就可以看到新增了7个设备ethX。</p>\n<p>这里需要注意VF设备是不能增量添加的，如果需要修改启动的VF数量，需要先将sriov_numvfs值重置为0后再重新设置为目标值，所以在使用SR-IOV功能最好能确定最多会使用到几个VF，以防在业务运行过程中需要扩展VF数影响正在使用VF的业务。</p>\n<p>开启SR-IOV功能后，在/sys/class/net/eth1/device目录下会多出多个virtfnX的目录，这些目录下分别记录了对应VF的信息，例如可以通过<code>ls /sys/class/net/eth1/device/virtfn*/net</code>显示对应vf设备名称,如下图所示：</p>\n<p><img src=\"/images/sriov01.png\" alt=\"sriov\"></p>\n<p>如果VF已经被放入了其他网络名字空间，那么net目录下会显示为空，例如上图中的virtfn0。</p>\n<p>容器使用vf设备，只需要使用<code>ip link set dev $VF netns $NET_NS</code>将vf设备放入容器所在网络名字空间，配置浮动IP和对应路由规则并将设备UP即可。</p>\n<p>通过上诉的说明，已经可以使用VF为容器提供网络功能了。</p>\n<h1 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h1><p>实验过程中发现开启SR-IOV后会对原先的多队列网卡有影响（关于多队列网卡这里不做介绍）。在开启之前，eth1根据不同网卡型号可能有8-24个队列，开启之后接收队列会可能会减少到两个，且此时默认情况下所有vf的硬中断都会集中在同一个CPU上，导致在请求较多的情况下使得CPU成为可能存在的瓶颈。为了缓解这个问题，可以将各个vf的队列分布到不同的CPU上处理。首先通过以下命令得到各个vf的中断号<br><code>ls /sys/class/net/eth1/device/virtfn0/msi_irqs/</code><br>如果知道vf设备名称，也可以直接<code>ls /sys/class/net/eth4/device/msi_irqs/</code>获取中断号，不过这种方式需要设备在当前网络空间，如果设备在容器里，主机上是没有eth4这个目录的。<br>得知中断号后可以给中断号绑定不同的CPU，以下命令将将中断号为77的硬中断交给CPU1处理<br><code>echo 1 &gt; /proc/irq/77/smp_affinity_list</code></p>\n<p>除了设置硬中断CPU，根据业务场景需要，还可以使用CPU位掩码将网卡队列的软中断处理均衡到不同的CPU上，例如<code>echo f &gt; /sys/class/net/$dev/queues/rx-0/rps_cpus</code>将$dev的接收队列rx-0发生的软中断绑定到0-3号CPU上</p>\n<h1 id=\"性能测试\"><a href=\"#性能测试\" class=\"headerlink\" title=\"性能测试\"></a>性能测试</h1><p>使用SR-IOV的一个主要原因就是因为它通过硬件虚拟化来加速容器收包的速度，所以需要对性能进行验证。</p>\n<p>由于资源条件限制，我们只拿到了一台支持sriov的万兆网卡机器，为了测试其性能，我们同时用6个千兆网卡机器使用netperf进行性能对比测试。<br>在万兆网卡上，根据虚拟比1:6启动了6个网络名字空间，每个名字空间内启动一个netserver。<br>在6个客户端上，分别为每个容器启动200个netperf进程，分别测试TCP_RR(64,64)和TCP_CRR(64,64)在使用SR-IOV和veth+bridge模式下的性能。<br>测试结果：<br>在开启sriov后，TCP_RR包量达到108万，相对于veth+bridge方式提升约15%. TCP_CRR包量达到8.1万，相对于veth+bridge方法提升约10%</p>\n<h1 id=\"CNI插件\"><a href=\"#CNI插件\" class=\"headerlink\" title=\"CNI插件\"></a>CNI插件</h1><p>这部分工作其实<a href=\"https://github.com/Intel-Corp/sriov-cni\">社区</a>已经有了，我们在做的时候也参考了它的代码实现。思路很简单，在初次使用时将SR-IOV功能开启，为容器分配网络时从主机上挑选一个未使用的VF给容器使用，设置floatingip和相关路由，最后UP。当删除容器网络时，将设备重命名并归还到主机上即可。</p>\n"},{"title":"k8s floatingip evolution","date":"2018-05-04T01:23:09.000Z","_content":"\n在我们内部的k8s系统的网络模式支持上，我们实现了多种网络模式的支持，最主要的就是overlay和floatingip的支持。\n在k8s系统中实现floatingip网络模式的方案，最初我们采用了bridge+veth的模式，在跑容器的主机（物理机或虚拟机）上创建一个linux bridge，将原主机的网卡桥接到这个bridge。每创建一个pod，都创建一对veth设备，一端连接bridge，一端扔进容器里达到容器与外界2层可达的效果。实现模型如下图所示：\n\n![bridge-veth](/images/fip_1.png)\n\n这种模式下，主机被作为一个交换机使用，包从容器发出在主机2层就决定走向，如果请求是对本机或者本机的其他容器，则走到相应网卡或进入内核网络栈，否则从原网卡流出到主机外。这种方式能够满足floatingip的pod和主机或者其他floatingip的pod互通。\n但是，在k8s场景下这里有个问题。k8s对pod网络的要求是，pod之间能相互访问，pod能通过serviceIP访问对端。如果目的地址是一个serviceIP，实际是需要经过主机的iptables规则的，而iptables规则通常工作在3层，这就会导致floatingip模式下的容器对serviceIP的访问出现异常，与k8s的网络标准不符，所以理论上并没有达到k8s的网络要求。不过在一般情况下，我们的业务并没有使用到serviceIP，所以也是一种切实有效的方案且已经使用在了生产环境。上面说到iptables通常工作在3层，其实内核提供了相关的参数可以对2层的包进行3层的规则匹配，需要打开`net.bridge.bridge-nf-call-iptables`，不过这种方式经同事测试会有其他网络上的问题，不建议打开。\n\n除了上面说到的serviceIP访问问题，bridge+veth模式还有一些其他问题：\n1. 我们的k8s集群是同时支持多种网络模式的，overlay的方案我们采用类似flannel+ipip模式。这种情况下，floatingip的容器无法访问到overlayip的容器，因为没有经过tun网卡封包就出主机了。这里也解释了上面打开`net.bridge.bridge-nf-call-iptables`仍不行的原因（经过iptables转成podIP）。\n2. 影响主机的网卡。bridge模式下需要将原主机的ethx设备桥接到bridge上，导致主机ip会从ethx移动到bridge上。一方面对主机不是很友好，有的用户可能无法接受这种ip设备的变化，另一方面，也可能对运行在上面的其他程序造成影响。例如我们的flannel就遇到了这种问题。flannel启动的时候启动参数里填写了主机的ip或对应的设备，并据此来配置相关路由，如果ip发生了变化，路由就会出错，这也是我们在生产环境下踩出来的坑。\n\n对于k8s网络本身而言，核心问题就是容器里的报文没有经过主机的3层（iptables规则,overlay封包）就发送出去了。如果我们能实现二层不可达的网络模式，就可以解决这个问题。所以这里需要将我们创建的bridge去掉，类似于overlay的实现模式，只用veth设备去实现网络连接。去掉bridge后，veth的主机端不会连接主机的其他设备，可以达到容器发出的包需要经过主机3层网络协议栈，在3层进行iptables的masq或者走ip隧道网卡进行ipip封包。另外，与overlay实现方案一样，我们在主机上设置一个路由，使得发往容器的包走对应的veth设备（这在bridge下是不需要的，bridge自动帮我们查到了对应mac地址的veth端）。\n但是进行测试之后发现容器还是无法与外部的主机进行通信。分析原因后发现在通信之前，我们需要知道ip对应的mac地址，这时候会发出arp广播。由于我们采用3层连通方式，2层是不互通的，而arp请求需要在2层连通的广播域传播，导致在3层方案中我们无法进行arp地址解析，通信在还没开始的时候就已经失败了。为了解决arp响应这个问题，我们需要配置内核参数`net.ipv4.conf.{DEV}.proxy_arp`。关于这个参数的介绍可以查阅网上的资料。设置了这个参数后，容器所在主机会响应从容器里发出的arp请求，也会响应从外界发来的查询容器ip对应mac地址的arp请求，从这个角度看，这里主机就相当于一个网关的角色。\n至此，容器终于可以和外界相互通信了。而且也解决了开始我们提到的serviceIP访问以及floatingip主动访问overlay的问题，并且顺带解决了问题2，因为没有引入bridge，主机原来的设备我们没有进行修改。\n\n总结下来，这种方式相比于bridge模式的优点：\n1. pod之间可以通过serviceIP访问\n2. 在多种网络模式共存下，floatingip的pod也可以访问overlay的pod\n3. 不更改原网卡的配置（IP）\n4. 不需要打开原设备的混杂模式。外界看到的容器ip对应的mac地址其实是主机网卡的mac，不需要混杂模式也能接收发给容器的包\n5. 交换机mac表项没有增加。交换机看到容器ip对应的mac地址是主机的mac地址，所以mac到端口的对应不变\n\n在使用了这种模式完成floatingip网络设置后，在新环境上新业务时又遇到了新问题。用户反馈发现在容器启动后的一段时间内无法与外界通信，需要过比较长的时间才将网络恢复。进行分析和测试后，发现如果ip在主机之间发生漂移，基本必会出现这种情况。这是由于在这段时间内其他机器都缓存了arp表项，ip对应的mac还是老的，导致交换机将包发往了错误的（原主机）端口。只有当地址老化后，重新发起arp请求得到最新的ip的mac才能正常通信。所以这里我们需要**主动**将最新的arp包发出去刷新arp表项，我们可以使用arping这个命令达到这一点。但是前面已经说了，容器里的arp请求并不能通往外界，所以直接在容器里使用arping工具发送arp是不行的，所以我们需要在分配容器的主机上进行这个操作`arping -c 2 -A -I ethx $containerIP`，但是会报错`bind: Cannot assign requested address`。报错信息提示很明显，因为我们尝试发送一个原地址并不是我们自己的包。为了解决这个问题，需要打开内核参数`net.ipv4.ip_nonlocal_bind`参数，作用就是本机程序可以绑定一个不属于本机地址的ip。测试后发现可以进行arping，floatingip漂移后也不会出现一段时间内无法通信的问题了。\n\n这里可能的一个缺点就是包传输的效率可能受到影响，例如两个在同一主机上的Pod通信，现在包都需要经过3层查询，而原来直接在2层走bridge转发即可。\n\n相关测试脚本\n\n```bash\naip=10.0.0.100 # floatingip\nip=$aip/23\nipr=$aip/32\ngw=10.0.0.1 # gateway\nip netns add ns1\nip l add dev veth_host type veth peer name veth_sbx\nip l set dev veth_sbx netns ns1\nip l set dev veth_host up\nip netns exec ns1 ip l set dev veth_sbx up\nip netns exec ns1 ip a add $ip dev veth_sbx\nip r add $ipr dev veth_host\nip netns exec ns1 ip r add default via $gw dev veth_sbx\nip netns exec ns1  ip l set dev lo up\n\n# set up some args\necho 1 > /proc/sys/net/ipv4/ip_forward\necho 1 > /proc/sys/net/ipv4/conf/veth_host/proxy_arp\necho 1 > /proc/sys/net/ipv4/ip_nonlocal_bind\n# send arp response to neighbours\narping -c 2 -A -I bond1 $aip\n```\n","source":"_posts/2018-05-04-k8s-floatingip-evolution.md","raw":"---\ntitle: k8s floatingip evolution\ndate: 2018-05-04 09:23:09\ntags: [network, kubernetes]\n---\n\n在我们内部的k8s系统的网络模式支持上，我们实现了多种网络模式的支持，最主要的就是overlay和floatingip的支持。\n在k8s系统中实现floatingip网络模式的方案，最初我们采用了bridge+veth的模式，在跑容器的主机（物理机或虚拟机）上创建一个linux bridge，将原主机的网卡桥接到这个bridge。每创建一个pod，都创建一对veth设备，一端连接bridge，一端扔进容器里达到容器与外界2层可达的效果。实现模型如下图所示：\n\n![bridge-veth](/images/fip_1.png)\n\n这种模式下，主机被作为一个交换机使用，包从容器发出在主机2层就决定走向，如果请求是对本机或者本机的其他容器，则走到相应网卡或进入内核网络栈，否则从原网卡流出到主机外。这种方式能够满足floatingip的pod和主机或者其他floatingip的pod互通。\n但是，在k8s场景下这里有个问题。k8s对pod网络的要求是，pod之间能相互访问，pod能通过serviceIP访问对端。如果目的地址是一个serviceIP，实际是需要经过主机的iptables规则的，而iptables规则通常工作在3层，这就会导致floatingip模式下的容器对serviceIP的访问出现异常，与k8s的网络标准不符，所以理论上并没有达到k8s的网络要求。不过在一般情况下，我们的业务并没有使用到serviceIP，所以也是一种切实有效的方案且已经使用在了生产环境。上面说到iptables通常工作在3层，其实内核提供了相关的参数可以对2层的包进行3层的规则匹配，需要打开`net.bridge.bridge-nf-call-iptables`，不过这种方式经同事测试会有其他网络上的问题，不建议打开。\n\n除了上面说到的serviceIP访问问题，bridge+veth模式还有一些其他问题：\n1. 我们的k8s集群是同时支持多种网络模式的，overlay的方案我们采用类似flannel+ipip模式。这种情况下，floatingip的容器无法访问到overlayip的容器，因为没有经过tun网卡封包就出主机了。这里也解释了上面打开`net.bridge.bridge-nf-call-iptables`仍不行的原因（经过iptables转成podIP）。\n2. 影响主机的网卡。bridge模式下需要将原主机的ethx设备桥接到bridge上，导致主机ip会从ethx移动到bridge上。一方面对主机不是很友好，有的用户可能无法接受这种ip设备的变化，另一方面，也可能对运行在上面的其他程序造成影响。例如我们的flannel就遇到了这种问题。flannel启动的时候启动参数里填写了主机的ip或对应的设备，并据此来配置相关路由，如果ip发生了变化，路由就会出错，这也是我们在生产环境下踩出来的坑。\n\n对于k8s网络本身而言，核心问题就是容器里的报文没有经过主机的3层（iptables规则,overlay封包）就发送出去了。如果我们能实现二层不可达的网络模式，就可以解决这个问题。所以这里需要将我们创建的bridge去掉，类似于overlay的实现模式，只用veth设备去实现网络连接。去掉bridge后，veth的主机端不会连接主机的其他设备，可以达到容器发出的包需要经过主机3层网络协议栈，在3层进行iptables的masq或者走ip隧道网卡进行ipip封包。另外，与overlay实现方案一样，我们在主机上设置一个路由，使得发往容器的包走对应的veth设备（这在bridge下是不需要的，bridge自动帮我们查到了对应mac地址的veth端）。\n但是进行测试之后发现容器还是无法与外部的主机进行通信。分析原因后发现在通信之前，我们需要知道ip对应的mac地址，这时候会发出arp广播。由于我们采用3层连通方式，2层是不互通的，而arp请求需要在2层连通的广播域传播，导致在3层方案中我们无法进行arp地址解析，通信在还没开始的时候就已经失败了。为了解决arp响应这个问题，我们需要配置内核参数`net.ipv4.conf.{DEV}.proxy_arp`。关于这个参数的介绍可以查阅网上的资料。设置了这个参数后，容器所在主机会响应从容器里发出的arp请求，也会响应从外界发来的查询容器ip对应mac地址的arp请求，从这个角度看，这里主机就相当于一个网关的角色。\n至此，容器终于可以和外界相互通信了。而且也解决了开始我们提到的serviceIP访问以及floatingip主动访问overlay的问题，并且顺带解决了问题2，因为没有引入bridge，主机原来的设备我们没有进行修改。\n\n总结下来，这种方式相比于bridge模式的优点：\n1. pod之间可以通过serviceIP访问\n2. 在多种网络模式共存下，floatingip的pod也可以访问overlay的pod\n3. 不更改原网卡的配置（IP）\n4. 不需要打开原设备的混杂模式。外界看到的容器ip对应的mac地址其实是主机网卡的mac，不需要混杂模式也能接收发给容器的包\n5. 交换机mac表项没有增加。交换机看到容器ip对应的mac地址是主机的mac地址，所以mac到端口的对应不变\n\n在使用了这种模式完成floatingip网络设置后，在新环境上新业务时又遇到了新问题。用户反馈发现在容器启动后的一段时间内无法与外界通信，需要过比较长的时间才将网络恢复。进行分析和测试后，发现如果ip在主机之间发生漂移，基本必会出现这种情况。这是由于在这段时间内其他机器都缓存了arp表项，ip对应的mac还是老的，导致交换机将包发往了错误的（原主机）端口。只有当地址老化后，重新发起arp请求得到最新的ip的mac才能正常通信。所以这里我们需要**主动**将最新的arp包发出去刷新arp表项，我们可以使用arping这个命令达到这一点。但是前面已经说了，容器里的arp请求并不能通往外界，所以直接在容器里使用arping工具发送arp是不行的，所以我们需要在分配容器的主机上进行这个操作`arping -c 2 -A -I ethx $containerIP`，但是会报错`bind: Cannot assign requested address`。报错信息提示很明显，因为我们尝试发送一个原地址并不是我们自己的包。为了解决这个问题，需要打开内核参数`net.ipv4.ip_nonlocal_bind`参数，作用就是本机程序可以绑定一个不属于本机地址的ip。测试后发现可以进行arping，floatingip漂移后也不会出现一段时间内无法通信的问题了。\n\n这里可能的一个缺点就是包传输的效率可能受到影响，例如两个在同一主机上的Pod通信，现在包都需要经过3层查询，而原来直接在2层走bridge转发即可。\n\n相关测试脚本\n\n```bash\naip=10.0.0.100 # floatingip\nip=$aip/23\nipr=$aip/32\ngw=10.0.0.1 # gateway\nip netns add ns1\nip l add dev veth_host type veth peer name veth_sbx\nip l set dev veth_sbx netns ns1\nip l set dev veth_host up\nip netns exec ns1 ip l set dev veth_sbx up\nip netns exec ns1 ip a add $ip dev veth_sbx\nip r add $ipr dev veth_host\nip netns exec ns1 ip r add default via $gw dev veth_sbx\nip netns exec ns1  ip l set dev lo up\n\n# set up some args\necho 1 > /proc/sys/net/ipv4/ip_forward\necho 1 > /proc/sys/net/ipv4/conf/veth_host/proxy_arp\necho 1 > /proc/sys/net/ipv4/ip_nonlocal_bind\n# send arp response to neighbours\narping -c 2 -A -I bond1 $aip\n```\n","slug":"k8s-floatingip-evolution","published":1,"updated":"2018-05-07T07:10:25.713Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asaqij001gphv9vntukbjh","content":"<p>在我们内部的k8s系统的网络模式支持上，我们实现了多种网络模式的支持，最主要的就是overlay和floatingip的支持。<br>在k8s系统中实现floatingip网络模式的方案，最初我们采用了bridge+veth的模式，在跑容器的主机（物理机或虚拟机）上创建一个linux bridge，将原主机的网卡桥接到这个bridge。每创建一个pod，都创建一对veth设备，一端连接bridge，一端扔进容器里达到容器与外界2层可达的效果。实现模型如下图所示：</p>\n<p><img src=\"/images/fip_1.png\" alt=\"bridge-veth\"></p>\n<p>这种模式下，主机被作为一个交换机使用，包从容器发出在主机2层就决定走向，如果请求是对本机或者本机的其他容器，则走到相应网卡或进入内核网络栈，否则从原网卡流出到主机外。这种方式能够满足floatingip的pod和主机或者其他floatingip的pod互通。<br>但是，在k8s场景下这里有个问题。k8s对pod网络的要求是，pod之间能相互访问，pod能通过serviceIP访问对端。如果目的地址是一个serviceIP，实际是需要经过主机的iptables规则的，而iptables规则通常工作在3层，这就会导致floatingip模式下的容器对serviceIP的访问出现异常，与k8s的网络标准不符，所以理论上并没有达到k8s的网络要求。不过在一般情况下，我们的业务并没有使用到serviceIP，所以也是一种切实有效的方案且已经使用在了生产环境。上面说到iptables通常工作在3层，其实内核提供了相关的参数可以对2层的包进行3层的规则匹配，需要打开<code>net.bridge.bridge-nf-call-iptables</code>，不过这种方式经同事测试会有其他网络上的问题，不建议打开。</p>\n<p>除了上面说到的serviceIP访问问题，bridge+veth模式还有一些其他问题：</p>\n<ol>\n<li>我们的k8s集群是同时支持多种网络模式的，overlay的方案我们采用类似flannel+ipip模式。这种情况下，floatingip的容器无法访问到overlayip的容器，因为没有经过tun网卡封包就出主机了。这里也解释了上面打开<code>net.bridge.bridge-nf-call-iptables</code>仍不行的原因（经过iptables转成podIP）。</li>\n<li>影响主机的网卡。bridge模式下需要将原主机的ethx设备桥接到bridge上，导致主机ip会从ethx移动到bridge上。一方面对主机不是很友好，有的用户可能无法接受这种ip设备的变化，另一方面，也可能对运行在上面的其他程序造成影响。例如我们的flannel就遇到了这种问题。flannel启动的时候启动参数里填写了主机的ip或对应的设备，并据此来配置相关路由，如果ip发生了变化，路由就会出错，这也是我们在生产环境下踩出来的坑。</li>\n</ol>\n<p>对于k8s网络本身而言，核心问题就是容器里的报文没有经过主机的3层（iptables规则,overlay封包）就发送出去了。如果我们能实现二层不可达的网络模式，就可以解决这个问题。所以这里需要将我们创建的bridge去掉，类似于overlay的实现模式，只用veth设备去实现网络连接。去掉bridge后，veth的主机端不会连接主机的其他设备，可以达到容器发出的包需要经过主机3层网络协议栈，在3层进行iptables的masq或者走ip隧道网卡进行ipip封包。另外，与overlay实现方案一样，我们在主机上设置一个路由，使得发往容器的包走对应的veth设备（这在bridge下是不需要的，bridge自动帮我们查到了对应mac地址的veth端）。<br>但是进行测试之后发现容器还是无法与外部的主机进行通信。分析原因后发现在通信之前，我们需要知道ip对应的mac地址，这时候会发出arp广播。由于我们采用3层连通方式，2层是不互通的，而arp请求需要在2层连通的广播域传播，导致在3层方案中我们无法进行arp地址解析，通信在还没开始的时候就已经失败了。为了解决arp响应这个问题，我们需要配置内核参数<code>net.ipv4.conf.{DEV}.proxy_arp</code>。关于这个参数的介绍可以查阅网上的资料。设置了这个参数后，容器所在主机会响应从容器里发出的arp请求，也会响应从外界发来的查询容器ip对应mac地址的arp请求，从这个角度看，这里主机就相当于一个网关的角色。<br>至此，容器终于可以和外界相互通信了。而且也解决了开始我们提到的serviceIP访问以及floatingip主动访问overlay的问题，并且顺带解决了问题2，因为没有引入bridge，主机原来的设备我们没有进行修改。</p>\n<p>总结下来，这种方式相比于bridge模式的优点：</p>\n<ol>\n<li>pod之间可以通过serviceIP访问</li>\n<li>在多种网络模式共存下，floatingip的pod也可以访问overlay的pod</li>\n<li>不更改原网卡的配置（IP）</li>\n<li>不需要打开原设备的混杂模式。外界看到的容器ip对应的mac地址其实是主机网卡的mac，不需要混杂模式也能接收发给容器的包</li>\n<li>交换机mac表项没有增加。交换机看到容器ip对应的mac地址是主机的mac地址，所以mac到端口的对应不变</li>\n</ol>\n<p>在使用了这种模式完成floatingip网络设置后，在新环境上新业务时又遇到了新问题。用户反馈发现在容器启动后的一段时间内无法与外界通信，需要过比较长的时间才将网络恢复。进行分析和测试后，发现如果ip在主机之间发生漂移，基本必会出现这种情况。这是由于在这段时间内其他机器都缓存了arp表项，ip对应的mac还是老的，导致交换机将包发往了错误的（原主机）端口。只有当地址老化后，重新发起arp请求得到最新的ip的mac才能正常通信。所以这里我们需要<strong>主动</strong>将最新的arp包发出去刷新arp表项，我们可以使用arping这个命令达到这一点。但是前面已经说了，容器里的arp请求并不能通往外界，所以直接在容器里使用arping工具发送arp是不行的，所以我们需要在分配容器的主机上进行这个操作<code>arping -c 2 -A -I ethx $containerIP</code>，但是会报错<code>bind: Cannot assign requested address</code>。报错信息提示很明显，因为我们尝试发送一个原地址并不是我们自己的包。为了解决这个问题，需要打开内核参数<code>net.ipv4.ip_nonlocal_bind</code>参数，作用就是本机程序可以绑定一个不属于本机地址的ip。测试后发现可以进行arping，floatingip漂移后也不会出现一段时间内无法通信的问题了。</p>\n<p>这里可能的一个缺点就是包传输的效率可能受到影响，例如两个在同一主机上的Pod通信，现在包都需要经过3层查询，而原来直接在2层走bridge转发即可。</p>\n<p>相关测试脚本</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">aip=10.0.0.100 <span class=\"comment\"># floatingip</span></div><div class=\"line\">ip=<span class=\"variable\">$aip</span>/23</div><div class=\"line\">ipr=<span class=\"variable\">$aip</span>/32</div><div class=\"line\">gw=10.0.0.1 <span class=\"comment\"># gateway</span></div><div class=\"line\">ip netns add ns1</div><div class=\"line\">ip l add dev veth_host <span class=\"built_in\">type</span> veth peer name veth_sbx</div><div class=\"line\">ip l <span class=\"built_in\">set</span> dev veth_sbx netns ns1</div><div class=\"line\">ip l <span class=\"built_in\">set</span> dev veth_host up</div><div class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ip l <span class=\"built_in\">set</span> dev veth_sbx up</div><div class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ip a add <span class=\"variable\">$ip</span> dev veth_sbx</div><div class=\"line\">ip r add <span class=\"variable\">$ipr</span> dev veth_host</div><div class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ip r add default via <span class=\"variable\">$gw</span> dev veth_sbx</div><div class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1  ip l <span class=\"built_in\">set</span> dev lo up</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># set up some args</span></div><div class=\"line\"><span class=\"built_in\">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</div><div class=\"line\"><span class=\"built_in\">echo</span> 1 &gt; /proc/sys/net/ipv4/conf/veth_host/proxy_arp</div><div class=\"line\"><span class=\"built_in\">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_nonlocal_bind</div><div class=\"line\"><span class=\"comment\"># send arp response to neighbours</span></div><div class=\"line\">arping -c 2 -A -I bond1 <span class=\"variable\">$aip</span></div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>在我们内部的k8s系统的网络模式支持上，我们实现了多种网络模式的支持，最主要的就是overlay和floatingip的支持。<br>在k8s系统中实现floatingip网络模式的方案，最初我们采用了bridge+veth的模式，在跑容器的主机（物理机或虚拟机）上创建一个linux bridge，将原主机的网卡桥接到这个bridge。每创建一个pod，都创建一对veth设备，一端连接bridge，一端扔进容器里达到容器与外界2层可达的效果。实现模型如下图所示：</p>\n<p><img src=\"/images/fip_1.png\" alt=\"bridge-veth\"></p>\n<p>这种模式下，主机被作为一个交换机使用，包从容器发出在主机2层就决定走向，如果请求是对本机或者本机的其他容器，则走到相应网卡或进入内核网络栈，否则从原网卡流出到主机外。这种方式能够满足floatingip的pod和主机或者其他floatingip的pod互通。<br>但是，在k8s场景下这里有个问题。k8s对pod网络的要求是，pod之间能相互访问，pod能通过serviceIP访问对端。如果目的地址是一个serviceIP，实际是需要经过主机的iptables规则的，而iptables规则通常工作在3层，这就会导致floatingip模式下的容器对serviceIP的访问出现异常，与k8s的网络标准不符，所以理论上并没有达到k8s的网络要求。不过在一般情况下，我们的业务并没有使用到serviceIP，所以也是一种切实有效的方案且已经使用在了生产环境。上面说到iptables通常工作在3层，其实内核提供了相关的参数可以对2层的包进行3层的规则匹配，需要打开<code>net.bridge.bridge-nf-call-iptables</code>，不过这种方式经同事测试会有其他网络上的问题，不建议打开。</p>\n<p>除了上面说到的serviceIP访问问题，bridge+veth模式还有一些其他问题：</p>\n<ol>\n<li>我们的k8s集群是同时支持多种网络模式的，overlay的方案我们采用类似flannel+ipip模式。这种情况下，floatingip的容器无法访问到overlayip的容器，因为没有经过tun网卡封包就出主机了。这里也解释了上面打开<code>net.bridge.bridge-nf-call-iptables</code>仍不行的原因（经过iptables转成podIP）。</li>\n<li>影响主机的网卡。bridge模式下需要将原主机的ethx设备桥接到bridge上，导致主机ip会从ethx移动到bridge上。一方面对主机不是很友好，有的用户可能无法接受这种ip设备的变化，另一方面，也可能对运行在上面的其他程序造成影响。例如我们的flannel就遇到了这种问题。flannel启动的时候启动参数里填写了主机的ip或对应的设备，并据此来配置相关路由，如果ip发生了变化，路由就会出错，这也是我们在生产环境下踩出来的坑。</li>\n</ol>\n<p>对于k8s网络本身而言，核心问题就是容器里的报文没有经过主机的3层（iptables规则,overlay封包）就发送出去了。如果我们能实现二层不可达的网络模式，就可以解决这个问题。所以这里需要将我们创建的bridge去掉，类似于overlay的实现模式，只用veth设备去实现网络连接。去掉bridge后，veth的主机端不会连接主机的其他设备，可以达到容器发出的包需要经过主机3层网络协议栈，在3层进行iptables的masq或者走ip隧道网卡进行ipip封包。另外，与overlay实现方案一样，我们在主机上设置一个路由，使得发往容器的包走对应的veth设备（这在bridge下是不需要的，bridge自动帮我们查到了对应mac地址的veth端）。<br>但是进行测试之后发现容器还是无法与外部的主机进行通信。分析原因后发现在通信之前，我们需要知道ip对应的mac地址，这时候会发出arp广播。由于我们采用3层连通方式，2层是不互通的，而arp请求需要在2层连通的广播域传播，导致在3层方案中我们无法进行arp地址解析，通信在还没开始的时候就已经失败了。为了解决arp响应这个问题，我们需要配置内核参数<code>net.ipv4.conf.{DEV}.proxy_arp</code>。关于这个参数的介绍可以查阅网上的资料。设置了这个参数后，容器所在主机会响应从容器里发出的arp请求，也会响应从外界发来的查询容器ip对应mac地址的arp请求，从这个角度看，这里主机就相当于一个网关的角色。<br>至此，容器终于可以和外界相互通信了。而且也解决了开始我们提到的serviceIP访问以及floatingip主动访问overlay的问题，并且顺带解决了问题2，因为没有引入bridge，主机原来的设备我们没有进行修改。</p>\n<p>总结下来，这种方式相比于bridge模式的优点：</p>\n<ol>\n<li>pod之间可以通过serviceIP访问</li>\n<li>在多种网络模式共存下，floatingip的pod也可以访问overlay的pod</li>\n<li>不更改原网卡的配置（IP）</li>\n<li>不需要打开原设备的混杂模式。外界看到的容器ip对应的mac地址其实是主机网卡的mac，不需要混杂模式也能接收发给容器的包</li>\n<li>交换机mac表项没有增加。交换机看到容器ip对应的mac地址是主机的mac地址，所以mac到端口的对应不变</li>\n</ol>\n<p>在使用了这种模式完成floatingip网络设置后，在新环境上新业务时又遇到了新问题。用户反馈发现在容器启动后的一段时间内无法与外界通信，需要过比较长的时间才将网络恢复。进行分析和测试后，发现如果ip在主机之间发生漂移，基本必会出现这种情况。这是由于在这段时间内其他机器都缓存了arp表项，ip对应的mac还是老的，导致交换机将包发往了错误的（原主机）端口。只有当地址老化后，重新发起arp请求得到最新的ip的mac才能正常通信。所以这里我们需要<strong>主动</strong>将最新的arp包发出去刷新arp表项，我们可以使用arping这个命令达到这一点。但是前面已经说了，容器里的arp请求并不能通往外界，所以直接在容器里使用arping工具发送arp是不行的，所以我们需要在分配容器的主机上进行这个操作<code>arping -c 2 -A -I ethx $containerIP</code>，但是会报错<code>bind: Cannot assign requested address</code>。报错信息提示很明显，因为我们尝试发送一个原地址并不是我们自己的包。为了解决这个问题，需要打开内核参数<code>net.ipv4.ip_nonlocal_bind</code>参数，作用就是本机程序可以绑定一个不属于本机地址的ip。测试后发现可以进行arping，floatingip漂移后也不会出现一段时间内无法通信的问题了。</p>\n<p>这里可能的一个缺点就是包传输的效率可能受到影响，例如两个在同一主机上的Pod通信，现在包都需要经过3层查询，而原来直接在2层走bridge转发即可。</p>\n<p>相关测试脚本</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">aip=10.0.0.100 <span class=\"comment\"># floatingip</span></div><div class=\"line\">ip=<span class=\"variable\">$aip</span>/23</div><div class=\"line\">ipr=<span class=\"variable\">$aip</span>/32</div><div class=\"line\">gw=10.0.0.1 <span class=\"comment\"># gateway</span></div><div class=\"line\">ip netns add ns1</div><div class=\"line\">ip l add dev veth_host <span class=\"built_in\">type</span> veth peer name veth_sbx</div><div class=\"line\">ip l <span class=\"built_in\">set</span> dev veth_sbx netns ns1</div><div class=\"line\">ip l <span class=\"built_in\">set</span> dev veth_host up</div><div class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ip l <span class=\"built_in\">set</span> dev veth_sbx up</div><div class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ip a add <span class=\"variable\">$ip</span> dev veth_sbx</div><div class=\"line\">ip r add <span class=\"variable\">$ipr</span> dev veth_host</div><div class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1 ip r add default via <span class=\"variable\">$gw</span> dev veth_sbx</div><div class=\"line\">ip netns <span class=\"built_in\">exec</span> ns1  ip l <span class=\"built_in\">set</span> dev lo up</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># set up some args</span></div><div class=\"line\"><span class=\"built_in\">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</div><div class=\"line\"><span class=\"built_in\">echo</span> 1 &gt; /proc/sys/net/ipv4/conf/veth_host/proxy_arp</div><div class=\"line\"><span class=\"built_in\">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_nonlocal_bind</div><div class=\"line\"><span class=\"comment\"># send arp response to neighbours</span></div><div class=\"line\">arping -c 2 -A -I bond1 <span class=\"variable\">$aip</span></div></pre></td></tr></table></figure>\n"},{"title":"k8s service ip problem","date":"2019-02-23T01:48:00.000Z","_content":"\n\n> 最近在部署山东电力gaiastack环境，现场部署的小伙伴突然遇到紧急问题，发现在容器里面无法通过kubernetes这个service来访问kube-apiserver，导致我们的云盘无法提供正常服务。\n\n> gaiastack是什么？gaiastack是我们组开发的企业级kubernetes容器云管理平台，目前已在公司内外树立了一批标杆客户\n\n\n\n在解决问题之前，我们先来看一下涉及到的一些概念。\n首先来简单介绍一下kubernetes中service的概念。在kubernetes中，实际提供服务的主体是Pod，每个Pod都有自己的IP地址。由于各种异常，Pod可能发生重启或者迁移，这个时候Pod的IP会发生变化。Service是对一组Pod的网络上的抽象，通过设置labelSelector来对应后端实际的Pod。service对应一个ServiceIP，这个IP是不变的，客户端可以通过访问这个不变的service IP来访问后端提供服务的会发生IP变化的Pod服务。\n\n![kubernetes service](/images/k8s-service.png)\n\n一般来说，service由用户主动创建，kubernetes中有一个controller的组件，会根据用户创建的service中的label Selector来选择相应的Pod，并将其信息写到与service名字同名的endpoint对象中。节点上的kube-proxy通过读取endpoint信息来找到映射关系，维护iptables规则。\n\n```\n[KUBE-SERVICES] \n-d 172.24.0.2/32 -p tcp -m tcp --dport 53 -j KUBE-SVC-ERI\n\n[KUBE-SVC-ERI] \n-m statistic --mode random --probability 0.5 -j KUBE-SEP-EME\n-j KUBE-SEP-QON\n\n[KUBE-SEP-EME] \n-p tcp -m tcp -j DNAT --to-destination 172.16.103.216:53\n```\n\n再来看一下这里遇到问题的名为kubernetes的service。这个service相较于一般的service有一些特殊之处。首先它是由kube-apiserver这个组件自己启动的时候创建的，且这个service没有label selector，它对应的endpoint信息是kube-apiserver自己更新的，会将自己的服务地址写到endpoint中，而不是通过controller去维护这个值。\n\n所以这里有一个问题就是一旦其中某个kube-apiserver挂了，它的endpoint信息还存在，很可能导致服务访问时访问到已经不提供服务的kube-apiserver。\n所以在看到这个问题时，首先需要排查是否对应的两个master节点服务都是可用的。telnet之后发现两个apiserver都是可以直接访问的，但是通过service时却不可以。那么问题就可能出在将serviceIP转成实际kube-apiserver的时候。需要进一步检查这个service的iptables规则。如下是现场的小伙伴发来的iptables相关的规则：\n\n![iptables规则](/images/k8s-iptables.png)\n\n可以看到iptables的规则是没问题的，是按照我们希望的方式在配置的。所以这里也不是这个问题。那么这里为什么直接通过机器ip可以但是通过serviceIP转一下就不行呢？突然一想今天现场的同事同步给我了一次环境网络变更，这次变更主要是由于这批机器有两张网卡，业务方今天为了解决网络冲突，删除了主机上的一个网关路由配置，而默认路由走的是另一张我们没有管理和使用的网卡(网段)。这个变更对这里的通信有什么影响呢？就是包的源地址选择！在之前的网络组件开发过程中，我们也遇到过这类由于源地址不是我们想要的源地址而造成的网络故障。linux在构造IP包时，需要填写源地址，那么如何确定这个源地址呢？通常是按照以下规则来的：\n1. 如果指定了源地址，直接使用，一般回包时都是这种情况，不存在需要重新选择源地址\n2. 如果没有指定，则需要根据目的地址来匹配主机路由规则，路由规则中有一个src选项，可以指定匹配这条路由规则的包的源地址使用src的IP\n3. 如果src上也没有指定，则使用路由规则中指定设备上的第一个IP地址作为其源地址\n4. 。。。\n\n有了这个怀疑，我们就查看了主机上的路由信息和网卡IP信息，如下图所示：\n\n![route表](/images/route.png)\n\n![网卡地址](/images/addr.png)\n\n结果正如我们所料，当指定目的地址是10.0.0.8时，匹配的路由 `10.0.0.0/24 dev enslf0`，源IP地址被设置为10.0.0.12。\n当我们指定的目的地址是172.24.0.1，匹配到了默认路由`default dev enslf1`，此时源地址是10.141.13.182，此时kube-apiserver收到包后无法通过网关往回发，导致无法通信。\n\n解决办法就是根据源地址选择的策略，我们手动配置一下serviceIP网段的路由，指导源地址的选择。这里只需要配置`ip r add 172.24.0.0/13 dev enslf0`，就会选择正确的源IP地址。为了防止重启后丢失这个路由，将其写入crontab即可。\n\n","source":"_posts/2019-02-23-k8s-service-ip-problem.md","raw":"---\ntitle: k8s service ip problem\ndate: 2019-02-23 09:48:00\ntags: [network, kubernetes]\n---\n\n\n> 最近在部署山东电力gaiastack环境，现场部署的小伙伴突然遇到紧急问题，发现在容器里面无法通过kubernetes这个service来访问kube-apiserver，导致我们的云盘无法提供正常服务。\n\n> gaiastack是什么？gaiastack是我们组开发的企业级kubernetes容器云管理平台，目前已在公司内外树立了一批标杆客户\n\n\n\n在解决问题之前，我们先来看一下涉及到的一些概念。\n首先来简单介绍一下kubernetes中service的概念。在kubernetes中，实际提供服务的主体是Pod，每个Pod都有自己的IP地址。由于各种异常，Pod可能发生重启或者迁移，这个时候Pod的IP会发生变化。Service是对一组Pod的网络上的抽象，通过设置labelSelector来对应后端实际的Pod。service对应一个ServiceIP，这个IP是不变的，客户端可以通过访问这个不变的service IP来访问后端提供服务的会发生IP变化的Pod服务。\n\n![kubernetes service](/images/k8s-service.png)\n\n一般来说，service由用户主动创建，kubernetes中有一个controller的组件，会根据用户创建的service中的label Selector来选择相应的Pod，并将其信息写到与service名字同名的endpoint对象中。节点上的kube-proxy通过读取endpoint信息来找到映射关系，维护iptables规则。\n\n```\n[KUBE-SERVICES] \n-d 172.24.0.2/32 -p tcp -m tcp --dport 53 -j KUBE-SVC-ERI\n\n[KUBE-SVC-ERI] \n-m statistic --mode random --probability 0.5 -j KUBE-SEP-EME\n-j KUBE-SEP-QON\n\n[KUBE-SEP-EME] \n-p tcp -m tcp -j DNAT --to-destination 172.16.103.216:53\n```\n\n再来看一下这里遇到问题的名为kubernetes的service。这个service相较于一般的service有一些特殊之处。首先它是由kube-apiserver这个组件自己启动的时候创建的，且这个service没有label selector，它对应的endpoint信息是kube-apiserver自己更新的，会将自己的服务地址写到endpoint中，而不是通过controller去维护这个值。\n\n所以这里有一个问题就是一旦其中某个kube-apiserver挂了，它的endpoint信息还存在，很可能导致服务访问时访问到已经不提供服务的kube-apiserver。\n所以在看到这个问题时，首先需要排查是否对应的两个master节点服务都是可用的。telnet之后发现两个apiserver都是可以直接访问的，但是通过service时却不可以。那么问题就可能出在将serviceIP转成实际kube-apiserver的时候。需要进一步检查这个service的iptables规则。如下是现场的小伙伴发来的iptables相关的规则：\n\n![iptables规则](/images/k8s-iptables.png)\n\n可以看到iptables的规则是没问题的，是按照我们希望的方式在配置的。所以这里也不是这个问题。那么这里为什么直接通过机器ip可以但是通过serviceIP转一下就不行呢？突然一想今天现场的同事同步给我了一次环境网络变更，这次变更主要是由于这批机器有两张网卡，业务方今天为了解决网络冲突，删除了主机上的一个网关路由配置，而默认路由走的是另一张我们没有管理和使用的网卡(网段)。这个变更对这里的通信有什么影响呢？就是包的源地址选择！在之前的网络组件开发过程中，我们也遇到过这类由于源地址不是我们想要的源地址而造成的网络故障。linux在构造IP包时，需要填写源地址，那么如何确定这个源地址呢？通常是按照以下规则来的：\n1. 如果指定了源地址，直接使用，一般回包时都是这种情况，不存在需要重新选择源地址\n2. 如果没有指定，则需要根据目的地址来匹配主机路由规则，路由规则中有一个src选项，可以指定匹配这条路由规则的包的源地址使用src的IP\n3. 如果src上也没有指定，则使用路由规则中指定设备上的第一个IP地址作为其源地址\n4. 。。。\n\n有了这个怀疑，我们就查看了主机上的路由信息和网卡IP信息，如下图所示：\n\n![route表](/images/route.png)\n\n![网卡地址](/images/addr.png)\n\n结果正如我们所料，当指定目的地址是10.0.0.8时，匹配的路由 `10.0.0.0/24 dev enslf0`，源IP地址被设置为10.0.0.12。\n当我们指定的目的地址是172.24.0.1，匹配到了默认路由`default dev enslf1`，此时源地址是10.141.13.182，此时kube-apiserver收到包后无法通过网关往回发，导致无法通信。\n\n解决办法就是根据源地址选择的策略，我们手动配置一下serviceIP网段的路由，指导源地址的选择。这里只需要配置`ip r add 172.24.0.0/13 dev enslf0`，就会选择正确的源IP地址。为了防止重启后丢失这个路由，将其写入crontab即可。\n\n","slug":"k8s-service-ip-problem","published":1,"updated":"2019-02-23T02:11:04.338Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asaqik001kphv9bld5ezhu","content":"<blockquote>\n<p>最近在部署山东电力gaiastack环境，现场部署的小伙伴突然遇到紧急问题，发现在容器里面无法通过kubernetes这个service来访问kube-apiserver，导致我们的云盘无法提供正常服务。</p>\n<p>gaiastack是什么？gaiastack是我们组开发的企业级kubernetes容器云管理平台，目前已在公司内外树立了一批标杆客户</p>\n</blockquote>\n<p>在解决问题之前，我们先来看一下涉及到的一些概念。<br>首先来简单介绍一下kubernetes中service的概念。在kubernetes中，实际提供服务的主体是Pod，每个Pod都有自己的IP地址。由于各种异常，Pod可能发生重启或者迁移，这个时候Pod的IP会发生变化。Service是对一组Pod的网络上的抽象，通过设置labelSelector来对应后端实际的Pod。service对应一个ServiceIP，这个IP是不变的，客户端可以通过访问这个不变的service IP来访问后端提供服务的会发生IP变化的Pod服务。</p>\n<p><img src=\"/images/k8s-service.png\" alt=\"kubernetes service\"></p>\n<p>一般来说，service由用户主动创建，kubernetes中有一个controller的组件，会根据用户创建的service中的label Selector来选择相应的Pod，并将其信息写到与service名字同名的endpoint对象中。节点上的kube-proxy通过读取endpoint信息来找到映射关系，维护iptables规则。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">[KUBE-SERVICES] </div><div class=\"line\">-d 172.24.0.2/32 -p tcp -m tcp --dport 53 -j KUBE-SVC-ERI</div><div class=\"line\"></div><div class=\"line\">[KUBE-SVC-ERI] </div><div class=\"line\">-m statistic --mode random --probability 0.5 -j KUBE-SEP-EME</div><div class=\"line\">-j KUBE-SEP-QON</div><div class=\"line\"></div><div class=\"line\">[KUBE-SEP-EME] </div><div class=\"line\">-p tcp -m tcp -j DNAT --to-destination 172.16.103.216:53</div></pre></td></tr></table></figure>\n<p>再来看一下这里遇到问题的名为kubernetes的service。这个service相较于一般的service有一些特殊之处。首先它是由kube-apiserver这个组件自己启动的时候创建的，且这个service没有label selector，它对应的endpoint信息是kube-apiserver自己更新的，会将自己的服务地址写到endpoint中，而不是通过controller去维护这个值。</p>\n<p>所以这里有一个问题就是一旦其中某个kube-apiserver挂了，它的endpoint信息还存在，很可能导致服务访问时访问到已经不提供服务的kube-apiserver。<br>所以在看到这个问题时，首先需要排查是否对应的两个master节点服务都是可用的。telnet之后发现两个apiserver都是可以直接访问的，但是通过service时却不可以。那么问题就可能出在将serviceIP转成实际kube-apiserver的时候。需要进一步检查这个service的iptables规则。如下是现场的小伙伴发来的iptables相关的规则：</p>\n<p><img src=\"/images/k8s-iptables.png\" alt=\"iptables规则\"></p>\n<p>可以看到iptables的规则是没问题的，是按照我们希望的方式在配置的。所以这里也不是这个问题。那么这里为什么直接通过机器ip可以但是通过serviceIP转一下就不行呢？突然一想今天现场的同事同步给我了一次环境网络变更，这次变更主要是由于这批机器有两张网卡，业务方今天为了解决网络冲突，删除了主机上的一个网关路由配置，而默认路由走的是另一张我们没有管理和使用的网卡(网段)。这个变更对这里的通信有什么影响呢？就是包的源地址选择！在之前的网络组件开发过程中，我们也遇到过这类由于源地址不是我们想要的源地址而造成的网络故障。linux在构造IP包时，需要填写源地址，那么如何确定这个源地址呢？通常是按照以下规则来的：</p>\n<ol>\n<li>如果指定了源地址，直接使用，一般回包时都是这种情况，不存在需要重新选择源地址</li>\n<li>如果没有指定，则需要根据目的地址来匹配主机路由规则，路由规则中有一个src选项，可以指定匹配这条路由规则的包的源地址使用src的IP</li>\n<li>如果src上也没有指定，则使用路由规则中指定设备上的第一个IP地址作为其源地址</li>\n<li>。。。</li>\n</ol>\n<p>有了这个怀疑，我们就查看了主机上的路由信息和网卡IP信息，如下图所示：</p>\n<p><img src=\"/images/route.png\" alt=\"route表\"></p>\n<p><img src=\"/images/addr.png\" alt=\"网卡地址\"></p>\n<p>结果正如我们所料，当指定目的地址是10.0.0.8时，匹配的路由 <code>10.0.0.0/24 dev enslf0</code>，源IP地址被设置为10.0.0.12。<br>当我们指定的目的地址是172.24.0.1，匹配到了默认路由<code>default dev enslf1</code>，此时源地址是10.141.13.182，此时kube-apiserver收到包后无法通过网关往回发，导致无法通信。</p>\n<p>解决办法就是根据源地址选择的策略，我们手动配置一下serviceIP网段的路由，指导源地址的选择。这里只需要配置<code>ip r add 172.24.0.0/13 dev enslf0</code>，就会选择正确的源IP地址。为了防止重启后丢失这个路由，将其写入crontab即可。</p>\n","excerpt":"","more":"<blockquote>\n<p>最近在部署山东电力gaiastack环境，现场部署的小伙伴突然遇到紧急问题，发现在容器里面无法通过kubernetes这个service来访问kube-apiserver，导致我们的云盘无法提供正常服务。</p>\n<p>gaiastack是什么？gaiastack是我们组开发的企业级kubernetes容器云管理平台，目前已在公司内外树立了一批标杆客户</p>\n</blockquote>\n<p>在解决问题之前，我们先来看一下涉及到的一些概念。<br>首先来简单介绍一下kubernetes中service的概念。在kubernetes中，实际提供服务的主体是Pod，每个Pod都有自己的IP地址。由于各种异常，Pod可能发生重启或者迁移，这个时候Pod的IP会发生变化。Service是对一组Pod的网络上的抽象，通过设置labelSelector来对应后端实际的Pod。service对应一个ServiceIP，这个IP是不变的，客户端可以通过访问这个不变的service IP来访问后端提供服务的会发生IP变化的Pod服务。</p>\n<p><img src=\"/images/k8s-service.png\" alt=\"kubernetes service\"></p>\n<p>一般来说，service由用户主动创建，kubernetes中有一个controller的组件，会根据用户创建的service中的label Selector来选择相应的Pod，并将其信息写到与service名字同名的endpoint对象中。节点上的kube-proxy通过读取endpoint信息来找到映射关系，维护iptables规则。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">[KUBE-SERVICES] </div><div class=\"line\">-d 172.24.0.2/32 -p tcp -m tcp --dport 53 -j KUBE-SVC-ERI</div><div class=\"line\"></div><div class=\"line\">[KUBE-SVC-ERI] </div><div class=\"line\">-m statistic --mode random --probability 0.5 -j KUBE-SEP-EME</div><div class=\"line\">-j KUBE-SEP-QON</div><div class=\"line\"></div><div class=\"line\">[KUBE-SEP-EME] </div><div class=\"line\">-p tcp -m tcp -j DNAT --to-destination 172.16.103.216:53</div></pre></td></tr></table></figure>\n<p>再来看一下这里遇到问题的名为kubernetes的service。这个service相较于一般的service有一些特殊之处。首先它是由kube-apiserver这个组件自己启动的时候创建的，且这个service没有label selector，它对应的endpoint信息是kube-apiserver自己更新的，会将自己的服务地址写到endpoint中，而不是通过controller去维护这个值。</p>\n<p>所以这里有一个问题就是一旦其中某个kube-apiserver挂了，它的endpoint信息还存在，很可能导致服务访问时访问到已经不提供服务的kube-apiserver。<br>所以在看到这个问题时，首先需要排查是否对应的两个master节点服务都是可用的。telnet之后发现两个apiserver都是可以直接访问的，但是通过service时却不可以。那么问题就可能出在将serviceIP转成实际kube-apiserver的时候。需要进一步检查这个service的iptables规则。如下是现场的小伙伴发来的iptables相关的规则：</p>\n<p><img src=\"/images/k8s-iptables.png\" alt=\"iptables规则\"></p>\n<p>可以看到iptables的规则是没问题的，是按照我们希望的方式在配置的。所以这里也不是这个问题。那么这里为什么直接通过机器ip可以但是通过serviceIP转一下就不行呢？突然一想今天现场的同事同步给我了一次环境网络变更，这次变更主要是由于这批机器有两张网卡，业务方今天为了解决网络冲突，删除了主机上的一个网关路由配置，而默认路由走的是另一张我们没有管理和使用的网卡(网段)。这个变更对这里的通信有什么影响呢？就是包的源地址选择！在之前的网络组件开发过程中，我们也遇到过这类由于源地址不是我们想要的源地址而造成的网络故障。linux在构造IP包时，需要填写源地址，那么如何确定这个源地址呢？通常是按照以下规则来的：</p>\n<ol>\n<li>如果指定了源地址，直接使用，一般回包时都是这种情况，不存在需要重新选择源地址</li>\n<li>如果没有指定，则需要根据目的地址来匹配主机路由规则，路由规则中有一个src选项，可以指定匹配这条路由规则的包的源地址使用src的IP</li>\n<li>如果src上也没有指定，则使用路由规则中指定设备上的第一个IP地址作为其源地址</li>\n<li>。。。</li>\n</ol>\n<p>有了这个怀疑，我们就查看了主机上的路由信息和网卡IP信息，如下图所示：</p>\n<p><img src=\"/images/route.png\" alt=\"route表\"></p>\n<p><img src=\"/images/addr.png\" alt=\"网卡地址\"></p>\n<p>结果正如我们所料，当指定目的地址是10.0.0.8时，匹配的路由 <code>10.0.0.0/24 dev enslf0</code>，源IP地址被设置为10.0.0.12。<br>当我们指定的目的地址是172.24.0.1，匹配到了默认路由<code>default dev enslf1</code>，此时源地址是10.141.13.182，此时kube-apiserver收到包后无法通过网关往回发，导致无法通信。</p>\n<p>解决办法就是根据源地址选择的策略，我们手动配置一下serviceIP网段的路由，指导源地址的选择。这里只需要配置<code>ip r add 172.24.0.0/13 dev enslf0</code>，就会选择正确的源IP地址。为了防止重启后丢失这个路由，将其写入crontab即可。</p>\n"},{"title":"ebpf intro","date":"2020-01-07T12:44:58.000Z","_content":"\n# eBPF简介\n\neBPF(extended BPF)可以看作是可以高效且安全的在内核的一些hook point上执行用户代码的一个虚拟机，用户编写的代码被编译成字节码后加载到linux内核，内核内嵌了一个JIT将字节码转成native code后由事件触发形式执行BPF代码。eBPF由BPF发展而来，BPF全称Berkeley Packet Filter，当时主要是为了高效的过滤数据包而设计的，其历史可以追溯到1992年的论文[The BSD Packet Filter: A New Architecture for User-level Packet Capture](http://www.tcpdump.org/papers/bpf-usenix93.pdf)中。现在大家说到的BPF实际上是e(extended)BPF，相比于之前的BPF，eBPF是RISC指令集，有了更丰富的指令，11个64位的寄存器。开发者可以使用C语言写BPF程序，然后使用llvm+clang编译成bpf格式的obj file。然后通过bpf()系统调用加载在内核中hook point。下文中提到的BPF如果没有明确说明，都是指代eBPF。\n\n![eBPF](/images/bpf.jpg)\n\n在BPF出现之前，如果要抓包，需要使用`tap`工具将所有的包先拷贝到用户态然后使用匹配规则（并不高效的算法）去过滤拿到满足条件的包，而BPF可以将匹配算法在内核执行，不需要全量拷贝数据包到用户空间，且匹配算法更加高效，使得其相对于`tap`有更高的效率。虽然大家可能不熟悉BPF，但是linux下大名鼎鼎的抓包工具tcpdump即是基于这项技术实现的。\n\n在介绍eBPF之前，我们先提前感受一下tcpdump中BPF的痕迹。tcpdump中有一个`-d`参数，`Dump the compiled packet-matching code in a human readable form to standard output and stop.`，用这个参数可以查看用户输入的匹配规则对应的bpf指令，例如\n```\n# tcpdump -i eth1 -d tcp and port 22\n(000) ldh      [12] # load half-byte to [x]，读取3层协议号\n(001) jeq      #0x86dd          jt 2\tjf 8 # 如果是IPv6，则根据IPv6检查包\n(002) ldb      [20]\n(003) jeq      #0x6             jt 4\tjf 19\n(004) ldh      [54]\n(005) jeq      #0x16            jt 18\tjf 6\n(006) ldh      [56]\n(007) jeq      #0x16            jt 18\tjf 19\n(008) jeq      #0x800           jt 9\tjf 19 # 判断是否为IPv4协议\n(009) ldb      [23]                           # 加载4层协议号\n(010) jeq      #0x6             jt 11\tjf 19 # TCP协议号\n(011) ldh      [20]                           # 加载 Flags和Fragment Offset\n(012) jset     #0x1fff          jt 19\tjf 13 # （前3bit是Flag）检测Fragment Offset 如果是IP分片，return 0\n(013) ldxb     4*([14]&0xf)                   # 加载 ip header的length\n(014) ldh      [x + 14]                       # 加载src port\n(015) jeq      #0x16            jt 18\tjf 16 # = 22\n(016) ldh      [x + 16]                       # 加载dst port\n(017) jeq      #0x16            jt 18\tjf 19 # = 22\n(018) ret      #262144                        # match\n(019) ret      #0                             # not match\n```\n\n\ttcpdump转化的指定是cBPF(classic)，可以看作是eBPF出现之前的BPF。只是在较新的内核(v3.15之后)中，内核支持eBPF，所以有专门的程序会负责将cBPF指令翻译成eBPF指令来执行。\n\n可以看出，tcpdump的规则被翻译成了20条指令，数据包仅仅被看作是字节的数组，指令对从数据包（数组）的不同位置读取(load)数据到寄存器并判断是否满足条件，最后返回。\n\ntcpdump使用的实际上是传统的BPF(cBPF)，而较新的内核中除了支持cBPF，主要是对eBPF的支持。功能上eBPF相对于cBPF已经做了很大的扩展。目前最新的内核代码中已经有20+类不同的BPF[程序类型](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L149)，根据不同的程序类型，从最初的相对单一的网络包过滤，扩展出了一个通用的内核虚拟机，可以将BPF程序附着到tracepoint/kprobe/uprobe/USDT，可以支持seccomp，扩展更多的网络功能例如配合tc完成更多的数据包处理能力，使用XDP提升网络性能等。从指令集来看，相对于cBPF，eBPF有更丰富的[指令集](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L14)，支持了更多的[寄存器](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L46)。此外，还引入了helper functions和maps。不同版本内核支持的BPF特性可以参考[这里](https://github.com/iovisor/bcc/blob/master/docs/kernel-versions.md)。\n\n## prog type\n每个BPF程序都属于某个特定的程序类型，目前内核支持20+不同类型的BPF程序类型，可以大致分为网络，跟踪，安全等几大类，BPF程序的输入参数也根据类型有所不同。\n```C\nenum bpf_prog_type {\n\tBPF_PROG_TYPE_UNSPEC,\n\tBPF_PROG_TYPE_SOCKET_FILTER,\n\tBPF_PROG_TYPE_KPROBE,\n\tBPF_PROG_TYPE_SCHED_CLS,\n\tBPF_PROG_TYPE_SCHED_ACT,\n\tBPF_PROG_TYPE_TRACEPOINT,\n\tBPF_PROG_TYPE_XDP,\n\tBPF_PROG_TYPE_PERF_EVENT,\n\tBPF_PROG_TYPE_CGROUP_SKB,\n\tBPF_PROG_TYPE_CGROUP_SOCK,\n\tBPF_PROG_TYPE_LWT_IN,\n\tBPF_PROG_TYPE_LWT_OUT,\n\tBPF_PROG_TYPE_LWT_XMIT,\n\tBPF_PROG_TYPE_SOCK_OPS,\n\tBPF_PROG_TYPE_SK_SKB,\n\tBPF_PROG_TYPE_CGROUP_DEVICE,\n\tBPF_PROG_TYPE_SK_MSG,\n\tBPF_PROG_TYPE_RAW_TRACEPOINT,\n\tBPF_PROG_TYPE_CGROUP_SOCK_ADDR,\n\tBPF_PROG_TYPE_LWT_SEG6LOCAL,\n\tBPF_PROG_TYPE_LIRC_MODE2,\n\tBPF_PROG_TYPE_SK_REUSEPORT,\n\tBPF_PROG_TYPE_FLOW_DISSECTOR,\n\tBPF_PROG_TYPE_CGROUP_SYSCTL,\n\tBPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE,\n\tBPF_PROG_TYPE_CGROUP_SOCKOPT,\n};\n```\n\n例如，`BPF_PROG_TYPE_KPROBE` `BPF_PROG_TYPE_TRACEPOINT` 等属于追踪。`BPF_PROG_TYPE_XDP`程序用于将BPF程序offload到driver层，在包刚从网卡上接收还未构造成skb之前，即执行BPF代码，效率相比于其他hook点要高，目前已有一些公司用XDP来抵御DDoS攻击，XDP具体使用方式以后再做详细介绍。`BPF_PROG_TYPE_SOCK_OPS`支持给socket设置一些TCP参数。`BPF_PROG_TYPE_SK_MSG`程序可以在socket调用sendmsg系统调用时被执行。\n\n不同的程序类型[挂载的方式](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L178)有所不同，例如`BPF_PROG_TYPE_SOCK_OPS`程序可以使用`BPF_CGROUP_SOCK_OPS`方式将程序挂载到cgroup上，属于这个cgroup下的socket会执行程序。`BPF_PROG_TYPE_SK_MSG`可以以`BPF_SK_MSG_VERDICT`的方式挂载到某些特殊的map上，记录在map里的socket会调用BPF程序。\n\n## helper functions\n[helper functions](http://man7.org/linux/man-pages/man7/bpf-helpers.7.html)是提供给BPF程序使用的辅助函数，BPF程序通常无法直接访问内核数据，所以提供了helper functions，通过这些函数完成一些辅助工作，比如从内核获取数据，操作内核的对象。\n不同的BPF程序类型可以使用部分的辅助函数，例如XDP（`BPF_PROG_TYPE_XDP`）类型程序能使用的辅助函数在[这里](https://github.com/torvalds/linux/blob/v5.4/net/core/filter.c#L6226)定义。\n\n## maps\n\nmaps是BPF程序中驻留在内核中存储 key/value 数据的存储方式的统称，实际上BPF提供了[很多类型的map](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L112)，很多map类型都有一些特殊的使用方式。BPF程序可以通过helper function读写map，用户态程序也可以通过`bpf(...)`系统调用读写map，因此可以通过map来达到BPF程序之间，BPF程序与用户态程序之间的数据交互与控制。\n```C\nenum bpf_map_type {\n\tBPF_MAP_TYPE_UNSPEC,\n\tBPF_MAP_TYPE_HASH,\n\tBPF_MAP_TYPE_ARRAY,\n\tBPF_MAP_TYPE_PROG_ARRAY,\n\tBPF_MAP_TYPE_PERF_EVENT_ARRAY,\n\tBPF_MAP_TYPE_PERCPU_HASH,\n\tBPF_MAP_TYPE_PERCPU_ARRAY,\n\tBPF_MAP_TYPE_STACK_TRACE,\n\tBPF_MAP_TYPE_CGROUP_ARRAY,\n\tBPF_MAP_TYPE_LRU_HASH,\n\tBPF_MAP_TYPE_LRU_PERCPU_HASH,\n\tBPF_MAP_TYPE_LPM_TRIE,\n\tBPF_MAP_TYPE_ARRAY_OF_MAPS,\n\tBPF_MAP_TYPE_HASH_OF_MAPS,\n\tBPF_MAP_TYPE_DEVMAP,\n\tBPF_MAP_TYPE_SOCKMAP,\n\tBPF_MAP_TYPE_CPUMAP,\n\tBPF_MAP_TYPE_XSKMAP,\n\tBPF_MAP_TYPE_SOCKHASH,\n\tBPF_MAP_TYPE_CGROUP_STORAGE,\n\tBPF_MAP_TYPE_REUSEPORT_SOCKARRAY,\n\tBPF_MAP_TYPE_PERCPU_CGROUP_STORAGE,\n\tBPF_MAP_TYPE_QUEUE,\n\tBPF_MAP_TYPE_STACK,\n\tBPF_MAP_TYPE_SK_STORAGE,\n\tBPF_MAP_TYPE_DEVMAP_HASH,\n};\n```\n一个MAP除了需要定义其所属类型，通常还需要定义其kv的大小（BPF并不关心其实际类型，可以看作是按字节码存储）以及最大的entry数，另外还可以指定是否提前分配内存，例如`BPF_MAP_TYPE_LPM_TRIE`类型的map就需要在创建时指定不分配entry。\n下面介绍几个比较常用的Map类型：\n\n* `BPF_MAP_TYPE_HASH`是大家普遍理解的kv存储的map，kv大小由用户自定义。\n* `BPF_MAP_TYPE_ARRAY`是数组，只能通过int类型作为key来访问map。\n* `BPF_MAP_TYPE_PROG_ARRAY`是一个特殊的存储，这个数组里存的是BPF程序。后文中我们会提到单个BPF程序限定了不能超过4096条指令，如果一个程序态复杂无法在4096条指令内完成，BPF提供了`BPF_MAP_TYPE_PROG_ARRAY`这个MAP来存储多个BPF程序，用户将拆分的BPF程序存入MAP中，BPF程序之间可以通过`tail-call`的形式来调用。\n* `BPF_MAP_TYPE_PERCPU_HASH` `BPF_MAP_TYPE_PERCPU_ARRAY` 类似于 `BPF_MAP_TYPE_HASH` `BPF_MAP_TYPE_ARRAY`，只是这类map在每个CPU上都有一个map实例。在BPF中使用helper function访问这类map和非PERCPU map一致，只能访问到本CPU的map，但是用户态得到的是一个数组，用户需要自己根据CPU数来聚合值。\n* `BPF_MAP_TYPE_LPM_TRIE`是字典树在BPF里的实现，通常可以用来匹配网段前缀。\n* `BPF_MAP_TYPE_DEVMAP`内存储的是网络设备号，XDP程序可以将包直接转发到存储在这里的设备中，提升包转发性能。\n* `BPF_MAP_TYPE_SOCKMAP` `BPF_MAP_TYPE_SOCKHASH`是用来存储socket的存储类型，以后会做详细介绍。\n\n---\n\n前面提到，BPF程序是用户编写然后加载到内核由事件驱动来同步执行的，所以如果程序有问题很可能导致内核的不稳定。为了确保BPF程序不影响内核正常工作，不影响执行效率，BPF严格规范了BPF程序。BPF程序的指令数不超过[4096](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf_common.h#L54)条，且程序中不能有loop以保证程序最终一定能退出。因此BPF在内核中引入了一个verify组件专门用来做程序的检查工作。实际上verify程序有很对安全检查，在BPF程序加载到内核时就会进行检查，检查的内容远不止指令条数和检测loop那么简单。例如在XDP程序类型中，每次访问包的某个索引位置之前，都需要BPF程序检查是否越界，如果没有检查，verify将会失败。所以虽然BPF程序本身可能逻辑并不复杂，在编写的过程中最好能够做到写一小部分逻辑后就编译加载到内核测试是否能通过检查，否则由于报错信息十分含糊，很难定位到错误的代码。\n\n编写BPF程序，[iovisor/bcc](https://github.com/iovisor/bcc)项目是一个很好的开始。使用这个项目，可以在python中写BPF代码直接运行，源码里有许多[例子](https://github.com/iovisor/bcc/tree/master/examples)可以学习。前面提到，我们可以自己编写BPF程序，然后使用llvm+clang编译成BPF格式的字节码编译命令也十分简单，`clang -O2 -target bpf -o bpf prog.o -c bpf prog.c.`，然后可以使用系统调用`bpf(...)`来加载到内核。除了自己写代码操作BPF程序，一些工具也可以帮助我们做到这一点。例如linux源码自带的[bpftool](https://github.com/torvalds/linux/tree/v5.4/tools/bpf/bpftool)可以操作部分BPF程序和map，iproute可以将BPF程序加载到网卡，tc可以将tc相关BPF程序加载到tc。\n\n# 参考资料：\n\n1. https://www.kernel.org/doc/Documentation/networking/filter.txt\n2. https://github.com/iovisor/bcc\n3. https://cilium.readthedocs.io/en/stable/bpf/\n4. https://lwn.net/Articles/740157/\n\n","source":"_posts/2020-01-07-ebpf-intro.md","raw":"---\ntitle: ebpf intro\ndate: 2020-01-07 20:44:58\ntags: [ebpf]\n---\n\n# eBPF简介\n\neBPF(extended BPF)可以看作是可以高效且安全的在内核的一些hook point上执行用户代码的一个虚拟机，用户编写的代码被编译成字节码后加载到linux内核，内核内嵌了一个JIT将字节码转成native code后由事件触发形式执行BPF代码。eBPF由BPF发展而来，BPF全称Berkeley Packet Filter，当时主要是为了高效的过滤数据包而设计的，其历史可以追溯到1992年的论文[The BSD Packet Filter: A New Architecture for User-level Packet Capture](http://www.tcpdump.org/papers/bpf-usenix93.pdf)中。现在大家说到的BPF实际上是e(extended)BPF，相比于之前的BPF，eBPF是RISC指令集，有了更丰富的指令，11个64位的寄存器。开发者可以使用C语言写BPF程序，然后使用llvm+clang编译成bpf格式的obj file。然后通过bpf()系统调用加载在内核中hook point。下文中提到的BPF如果没有明确说明，都是指代eBPF。\n\n![eBPF](/images/bpf.jpg)\n\n在BPF出现之前，如果要抓包，需要使用`tap`工具将所有的包先拷贝到用户态然后使用匹配规则（并不高效的算法）去过滤拿到满足条件的包，而BPF可以将匹配算法在内核执行，不需要全量拷贝数据包到用户空间，且匹配算法更加高效，使得其相对于`tap`有更高的效率。虽然大家可能不熟悉BPF，但是linux下大名鼎鼎的抓包工具tcpdump即是基于这项技术实现的。\n\n在介绍eBPF之前，我们先提前感受一下tcpdump中BPF的痕迹。tcpdump中有一个`-d`参数，`Dump the compiled packet-matching code in a human readable form to standard output and stop.`，用这个参数可以查看用户输入的匹配规则对应的bpf指令，例如\n```\n# tcpdump -i eth1 -d tcp and port 22\n(000) ldh      [12] # load half-byte to [x]，读取3层协议号\n(001) jeq      #0x86dd          jt 2\tjf 8 # 如果是IPv6，则根据IPv6检查包\n(002) ldb      [20]\n(003) jeq      #0x6             jt 4\tjf 19\n(004) ldh      [54]\n(005) jeq      #0x16            jt 18\tjf 6\n(006) ldh      [56]\n(007) jeq      #0x16            jt 18\tjf 19\n(008) jeq      #0x800           jt 9\tjf 19 # 判断是否为IPv4协议\n(009) ldb      [23]                           # 加载4层协议号\n(010) jeq      #0x6             jt 11\tjf 19 # TCP协议号\n(011) ldh      [20]                           # 加载 Flags和Fragment Offset\n(012) jset     #0x1fff          jt 19\tjf 13 # （前3bit是Flag）检测Fragment Offset 如果是IP分片，return 0\n(013) ldxb     4*([14]&0xf)                   # 加载 ip header的length\n(014) ldh      [x + 14]                       # 加载src port\n(015) jeq      #0x16            jt 18\tjf 16 # = 22\n(016) ldh      [x + 16]                       # 加载dst port\n(017) jeq      #0x16            jt 18\tjf 19 # = 22\n(018) ret      #262144                        # match\n(019) ret      #0                             # not match\n```\n\n\ttcpdump转化的指定是cBPF(classic)，可以看作是eBPF出现之前的BPF。只是在较新的内核(v3.15之后)中，内核支持eBPF，所以有专门的程序会负责将cBPF指令翻译成eBPF指令来执行。\n\n可以看出，tcpdump的规则被翻译成了20条指令，数据包仅仅被看作是字节的数组，指令对从数据包（数组）的不同位置读取(load)数据到寄存器并判断是否满足条件，最后返回。\n\ntcpdump使用的实际上是传统的BPF(cBPF)，而较新的内核中除了支持cBPF，主要是对eBPF的支持。功能上eBPF相对于cBPF已经做了很大的扩展。目前最新的内核代码中已经有20+类不同的BPF[程序类型](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L149)，根据不同的程序类型，从最初的相对单一的网络包过滤，扩展出了一个通用的内核虚拟机，可以将BPF程序附着到tracepoint/kprobe/uprobe/USDT，可以支持seccomp，扩展更多的网络功能例如配合tc完成更多的数据包处理能力，使用XDP提升网络性能等。从指令集来看，相对于cBPF，eBPF有更丰富的[指令集](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L14)，支持了更多的[寄存器](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L46)。此外，还引入了helper functions和maps。不同版本内核支持的BPF特性可以参考[这里](https://github.com/iovisor/bcc/blob/master/docs/kernel-versions.md)。\n\n## prog type\n每个BPF程序都属于某个特定的程序类型，目前内核支持20+不同类型的BPF程序类型，可以大致分为网络，跟踪，安全等几大类，BPF程序的输入参数也根据类型有所不同。\n```C\nenum bpf_prog_type {\n\tBPF_PROG_TYPE_UNSPEC,\n\tBPF_PROG_TYPE_SOCKET_FILTER,\n\tBPF_PROG_TYPE_KPROBE,\n\tBPF_PROG_TYPE_SCHED_CLS,\n\tBPF_PROG_TYPE_SCHED_ACT,\n\tBPF_PROG_TYPE_TRACEPOINT,\n\tBPF_PROG_TYPE_XDP,\n\tBPF_PROG_TYPE_PERF_EVENT,\n\tBPF_PROG_TYPE_CGROUP_SKB,\n\tBPF_PROG_TYPE_CGROUP_SOCK,\n\tBPF_PROG_TYPE_LWT_IN,\n\tBPF_PROG_TYPE_LWT_OUT,\n\tBPF_PROG_TYPE_LWT_XMIT,\n\tBPF_PROG_TYPE_SOCK_OPS,\n\tBPF_PROG_TYPE_SK_SKB,\n\tBPF_PROG_TYPE_CGROUP_DEVICE,\n\tBPF_PROG_TYPE_SK_MSG,\n\tBPF_PROG_TYPE_RAW_TRACEPOINT,\n\tBPF_PROG_TYPE_CGROUP_SOCK_ADDR,\n\tBPF_PROG_TYPE_LWT_SEG6LOCAL,\n\tBPF_PROG_TYPE_LIRC_MODE2,\n\tBPF_PROG_TYPE_SK_REUSEPORT,\n\tBPF_PROG_TYPE_FLOW_DISSECTOR,\n\tBPF_PROG_TYPE_CGROUP_SYSCTL,\n\tBPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE,\n\tBPF_PROG_TYPE_CGROUP_SOCKOPT,\n};\n```\n\n例如，`BPF_PROG_TYPE_KPROBE` `BPF_PROG_TYPE_TRACEPOINT` 等属于追踪。`BPF_PROG_TYPE_XDP`程序用于将BPF程序offload到driver层，在包刚从网卡上接收还未构造成skb之前，即执行BPF代码，效率相比于其他hook点要高，目前已有一些公司用XDP来抵御DDoS攻击，XDP具体使用方式以后再做详细介绍。`BPF_PROG_TYPE_SOCK_OPS`支持给socket设置一些TCP参数。`BPF_PROG_TYPE_SK_MSG`程序可以在socket调用sendmsg系统调用时被执行。\n\n不同的程序类型[挂载的方式](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L178)有所不同，例如`BPF_PROG_TYPE_SOCK_OPS`程序可以使用`BPF_CGROUP_SOCK_OPS`方式将程序挂载到cgroup上，属于这个cgroup下的socket会执行程序。`BPF_PROG_TYPE_SK_MSG`可以以`BPF_SK_MSG_VERDICT`的方式挂载到某些特殊的map上，记录在map里的socket会调用BPF程序。\n\n## helper functions\n[helper functions](http://man7.org/linux/man-pages/man7/bpf-helpers.7.html)是提供给BPF程序使用的辅助函数，BPF程序通常无法直接访问内核数据，所以提供了helper functions，通过这些函数完成一些辅助工作，比如从内核获取数据，操作内核的对象。\n不同的BPF程序类型可以使用部分的辅助函数，例如XDP（`BPF_PROG_TYPE_XDP`）类型程序能使用的辅助函数在[这里](https://github.com/torvalds/linux/blob/v5.4/net/core/filter.c#L6226)定义。\n\n## maps\n\nmaps是BPF程序中驻留在内核中存储 key/value 数据的存储方式的统称，实际上BPF提供了[很多类型的map](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L112)，很多map类型都有一些特殊的使用方式。BPF程序可以通过helper function读写map，用户态程序也可以通过`bpf(...)`系统调用读写map，因此可以通过map来达到BPF程序之间，BPF程序与用户态程序之间的数据交互与控制。\n```C\nenum bpf_map_type {\n\tBPF_MAP_TYPE_UNSPEC,\n\tBPF_MAP_TYPE_HASH,\n\tBPF_MAP_TYPE_ARRAY,\n\tBPF_MAP_TYPE_PROG_ARRAY,\n\tBPF_MAP_TYPE_PERF_EVENT_ARRAY,\n\tBPF_MAP_TYPE_PERCPU_HASH,\n\tBPF_MAP_TYPE_PERCPU_ARRAY,\n\tBPF_MAP_TYPE_STACK_TRACE,\n\tBPF_MAP_TYPE_CGROUP_ARRAY,\n\tBPF_MAP_TYPE_LRU_HASH,\n\tBPF_MAP_TYPE_LRU_PERCPU_HASH,\n\tBPF_MAP_TYPE_LPM_TRIE,\n\tBPF_MAP_TYPE_ARRAY_OF_MAPS,\n\tBPF_MAP_TYPE_HASH_OF_MAPS,\n\tBPF_MAP_TYPE_DEVMAP,\n\tBPF_MAP_TYPE_SOCKMAP,\n\tBPF_MAP_TYPE_CPUMAP,\n\tBPF_MAP_TYPE_XSKMAP,\n\tBPF_MAP_TYPE_SOCKHASH,\n\tBPF_MAP_TYPE_CGROUP_STORAGE,\n\tBPF_MAP_TYPE_REUSEPORT_SOCKARRAY,\n\tBPF_MAP_TYPE_PERCPU_CGROUP_STORAGE,\n\tBPF_MAP_TYPE_QUEUE,\n\tBPF_MAP_TYPE_STACK,\n\tBPF_MAP_TYPE_SK_STORAGE,\n\tBPF_MAP_TYPE_DEVMAP_HASH,\n};\n```\n一个MAP除了需要定义其所属类型，通常还需要定义其kv的大小（BPF并不关心其实际类型，可以看作是按字节码存储）以及最大的entry数，另外还可以指定是否提前分配内存，例如`BPF_MAP_TYPE_LPM_TRIE`类型的map就需要在创建时指定不分配entry。\n下面介绍几个比较常用的Map类型：\n\n* `BPF_MAP_TYPE_HASH`是大家普遍理解的kv存储的map，kv大小由用户自定义。\n* `BPF_MAP_TYPE_ARRAY`是数组，只能通过int类型作为key来访问map。\n* `BPF_MAP_TYPE_PROG_ARRAY`是一个特殊的存储，这个数组里存的是BPF程序。后文中我们会提到单个BPF程序限定了不能超过4096条指令，如果一个程序态复杂无法在4096条指令内完成，BPF提供了`BPF_MAP_TYPE_PROG_ARRAY`这个MAP来存储多个BPF程序，用户将拆分的BPF程序存入MAP中，BPF程序之间可以通过`tail-call`的形式来调用。\n* `BPF_MAP_TYPE_PERCPU_HASH` `BPF_MAP_TYPE_PERCPU_ARRAY` 类似于 `BPF_MAP_TYPE_HASH` `BPF_MAP_TYPE_ARRAY`，只是这类map在每个CPU上都有一个map实例。在BPF中使用helper function访问这类map和非PERCPU map一致，只能访问到本CPU的map，但是用户态得到的是一个数组，用户需要自己根据CPU数来聚合值。\n* `BPF_MAP_TYPE_LPM_TRIE`是字典树在BPF里的实现，通常可以用来匹配网段前缀。\n* `BPF_MAP_TYPE_DEVMAP`内存储的是网络设备号，XDP程序可以将包直接转发到存储在这里的设备中，提升包转发性能。\n* `BPF_MAP_TYPE_SOCKMAP` `BPF_MAP_TYPE_SOCKHASH`是用来存储socket的存储类型，以后会做详细介绍。\n\n---\n\n前面提到，BPF程序是用户编写然后加载到内核由事件驱动来同步执行的，所以如果程序有问题很可能导致内核的不稳定。为了确保BPF程序不影响内核正常工作，不影响执行效率，BPF严格规范了BPF程序。BPF程序的指令数不超过[4096](https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf_common.h#L54)条，且程序中不能有loop以保证程序最终一定能退出。因此BPF在内核中引入了一个verify组件专门用来做程序的检查工作。实际上verify程序有很对安全检查，在BPF程序加载到内核时就会进行检查，检查的内容远不止指令条数和检测loop那么简单。例如在XDP程序类型中，每次访问包的某个索引位置之前，都需要BPF程序检查是否越界，如果没有检查，verify将会失败。所以虽然BPF程序本身可能逻辑并不复杂，在编写的过程中最好能够做到写一小部分逻辑后就编译加载到内核测试是否能通过检查，否则由于报错信息十分含糊，很难定位到错误的代码。\n\n编写BPF程序，[iovisor/bcc](https://github.com/iovisor/bcc)项目是一个很好的开始。使用这个项目，可以在python中写BPF代码直接运行，源码里有许多[例子](https://github.com/iovisor/bcc/tree/master/examples)可以学习。前面提到，我们可以自己编写BPF程序，然后使用llvm+clang编译成BPF格式的字节码编译命令也十分简单，`clang -O2 -target bpf -o bpf prog.o -c bpf prog.c.`，然后可以使用系统调用`bpf(...)`来加载到内核。除了自己写代码操作BPF程序，一些工具也可以帮助我们做到这一点。例如linux源码自带的[bpftool](https://github.com/torvalds/linux/tree/v5.4/tools/bpf/bpftool)可以操作部分BPF程序和map，iproute可以将BPF程序加载到网卡，tc可以将tc相关BPF程序加载到tc。\n\n# 参考资料：\n\n1. https://www.kernel.org/doc/Documentation/networking/filter.txt\n2. https://github.com/iovisor/bcc\n3. https://cilium.readthedocs.io/en/stable/bpf/\n4. https://lwn.net/Articles/740157/\n\n","slug":"ebpf-intro","published":1,"updated":"2020-01-12T09:00:33.480Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asg8kx0000btv9yft380sc","content":"<h1 id=\"eBPF简介\"><a href=\"#eBPF简介\" class=\"headerlink\" title=\"eBPF简介\"></a>eBPF简介</h1><p>eBPF(extended BPF)可以看作是可以高效且安全的在内核的一些hook point上执行用户代码的一个虚拟机，用户编写的代码被编译成字节码后加载到linux内核，内核内嵌了一个JIT将字节码转成native code后由事件触发形式执行BPF代码。eBPF由BPF发展而来，BPF全称Berkeley Packet Filter，当时主要是为了高效的过滤数据包而设计的，其历史可以追溯到1992年的论文<a href=\"http://www.tcpdump.org/papers/bpf-usenix93.pdf\" target=\"_blank\" rel=\"external\">The BSD Packet Filter: A New Architecture for User-level Packet Capture</a>中。现在大家说到的BPF实际上是e(extended)BPF，相比于之前的BPF，eBPF是RISC指令集，有了更丰富的指令，11个64位的寄存器。开发者可以使用C语言写BPF程序，然后使用llvm+clang编译成bpf格式的obj file。然后通过bpf()系统调用加载在内核中hook point。下文中提到的BPF如果没有明确说明，都是指代eBPF。</p>\n<p><img src=\"/images/bpf.jpg\" alt=\"eBPF\"></p>\n<p>在BPF出现之前，如果要抓包，需要使用<code>tap</code>工具将所有的包先拷贝到用户态然后使用匹配规则（并不高效的算法）去过滤拿到满足条件的包，而BPF可以将匹配算法在内核执行，不需要全量拷贝数据包到用户空间，且匹配算法更加高效，使得其相对于<code>tap</code>有更高的效率。虽然大家可能不熟悉BPF，但是linux下大名鼎鼎的抓包工具tcpdump即是基于这项技术实现的。</p>\n<p>在介绍eBPF之前，我们先提前感受一下tcpdump中BPF的痕迹。tcpdump中有一个<code>-d</code>参数，<code>Dump the compiled packet-matching code in a human readable form to standard output and stop.</code>，用这个参数可以查看用户输入的匹配规则对应的bpf指令，例如<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"># tcpdump -i eth1 -d tcp and port 22</div><div class=\"line\">(000) ldh      [12] # load half-byte to [x]，读取3层协议号</div><div class=\"line\">(001) jeq      #0x86dd          jt 2\tjf 8 # 如果是IPv6，则根据IPv6检查包</div><div class=\"line\">(002) ldb      [20]</div><div class=\"line\">(003) jeq      #0x6             jt 4\tjf 19</div><div class=\"line\">(004) ldh      [54]</div><div class=\"line\">(005) jeq      #0x16            jt 18\tjf 6</div><div class=\"line\">(006) ldh      [56]</div><div class=\"line\">(007) jeq      #0x16            jt 18\tjf 19</div><div class=\"line\">(008) jeq      #0x800           jt 9\tjf 19 # 判断是否为IPv4协议</div><div class=\"line\">(009) ldb      [23]                           # 加载4层协议号</div><div class=\"line\">(010) jeq      #0x6             jt 11\tjf 19 # TCP协议号</div><div class=\"line\">(011) ldh      [20]                           # 加载 Flags和Fragment Offset</div><div class=\"line\">(012) jset     #0x1fff          jt 19\tjf 13 # （前3bit是Flag）检测Fragment Offset 如果是IP分片，return 0</div><div class=\"line\">(013) ldxb     4*([14]&amp;0xf)                   # 加载 ip header的length</div><div class=\"line\">(014) ldh      [x + 14]                       # 加载src port</div><div class=\"line\">(015) jeq      #0x16            jt 18\tjf 16 # = 22</div><div class=\"line\">(016) ldh      [x + 16]                       # 加载dst port</div><div class=\"line\">(017) jeq      #0x16            jt 18\tjf 19 # = 22</div><div class=\"line\">(018) ret      #262144                        # match</div><div class=\"line\">(019) ret      #0                             # not match</div></pre></td></tr></table></figure></p>\n<pre><code>tcpdump转化的指定是cBPF(classic)，可以看作是eBPF出现之前的BPF。只是在较新的内核(v3.15之后)中，内核支持eBPF，所以有专门的程序会负责将cBPF指令翻译成eBPF指令来执行。\n</code></pre><p>可以看出，tcpdump的规则被翻译成了20条指令，数据包仅仅被看作是字节的数组，指令对从数据包（数组）的不同位置读取(load)数据到寄存器并判断是否满足条件，最后返回。</p>\n<p>tcpdump使用的实际上是传统的BPF(cBPF)，而较新的内核中除了支持cBPF，主要是对eBPF的支持。功能上eBPF相对于cBPF已经做了很大的扩展。目前最新的内核代码中已经有20+类不同的BPF<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L149\" target=\"_blank\" rel=\"external\">程序类型</a>，根据不同的程序类型，从最初的相对单一的网络包过滤，扩展出了一个通用的内核虚拟机，可以将BPF程序附着到tracepoint/kprobe/uprobe/USDT，可以支持seccomp，扩展更多的网络功能例如配合tc完成更多的数据包处理能力，使用XDP提升网络性能等。从指令集来看，相对于cBPF，eBPF有更丰富的<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L14\" target=\"_blank\" rel=\"external\">指令集</a>，支持了更多的<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L46\" target=\"_blank\" rel=\"external\">寄存器</a>。此外，还引入了helper functions和maps。不同版本内核支持的BPF特性可以参考<a href=\"https://github.com/iovisor/bcc/blob/master/docs/kernel-versions.md\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<h2 id=\"prog-type\"><a href=\"#prog-type\" class=\"headerlink\" title=\"prog type\"></a>prog type</h2><p>每个BPF程序都属于某个特定的程序类型，目前内核支持20+不同类型的BPF程序类型，可以大致分为网络，跟踪，安全等几大类，BPF程序的输入参数也根据类型有所不同。<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">enum</span> bpf_prog_type &#123;</div><div class=\"line\">\tBPF_PROG_TYPE_UNSPEC,</div><div class=\"line\">\tBPF_PROG_TYPE_SOCKET_FILTER,</div><div class=\"line\">\tBPF_PROG_TYPE_KPROBE,</div><div class=\"line\">\tBPF_PROG_TYPE_SCHED_CLS,</div><div class=\"line\">\tBPF_PROG_TYPE_SCHED_ACT,</div><div class=\"line\">\tBPF_PROG_TYPE_TRACEPOINT,</div><div class=\"line\">\tBPF_PROG_TYPE_XDP,</div><div class=\"line\">\tBPF_PROG_TYPE_PERF_EVENT,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SKB,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SOCK,</div><div class=\"line\">\tBPF_PROG_TYPE_LWT_IN,</div><div class=\"line\">\tBPF_PROG_TYPE_LWT_OUT,</div><div class=\"line\">\tBPF_PROG_TYPE_LWT_XMIT,</div><div class=\"line\">\tBPF_PROG_TYPE_SOCK_OPS,</div><div class=\"line\">\tBPF_PROG_TYPE_SK_SKB,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_DEVICE,</div><div class=\"line\">\tBPF_PROG_TYPE_SK_MSG,</div><div class=\"line\">\tBPF_PROG_TYPE_RAW_TRACEPOINT,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SOCK_ADDR,</div><div class=\"line\">\tBPF_PROG_TYPE_LWT_SEG6LOCAL,</div><div class=\"line\">\tBPF_PROG_TYPE_LIRC_MODE2,</div><div class=\"line\">\tBPF_PROG_TYPE_SK_REUSEPORT,</div><div class=\"line\">\tBPF_PROG_TYPE_FLOW_DISSECTOR,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SYSCTL,</div><div class=\"line\">\tBPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SOCKOPT,</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>例如，<code>BPF_PROG_TYPE_KPROBE</code> <code>BPF_PROG_TYPE_TRACEPOINT</code> 等属于追踪。<code>BPF_PROG_TYPE_XDP</code>程序用于将BPF程序offload到driver层，在包刚从网卡上接收还未构造成skb之前，即执行BPF代码，效率相比于其他hook点要高，目前已有一些公司用XDP来抵御DDoS攻击，XDP具体使用方式以后再做详细介绍。<code>BPF_PROG_TYPE_SOCK_OPS</code>支持给socket设置一些TCP参数。<code>BPF_PROG_TYPE_SK_MSG</code>程序可以在socket调用sendmsg系统调用时被执行。</p>\n<p>不同的程序类型<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L178\" target=\"_blank\" rel=\"external\">挂载的方式</a>有所不同，例如<code>BPF_PROG_TYPE_SOCK_OPS</code>程序可以使用<code>BPF_CGROUP_SOCK_OPS</code>方式将程序挂载到cgroup上，属于这个cgroup下的socket会执行程序。<code>BPF_PROG_TYPE_SK_MSG</code>可以以<code>BPF_SK_MSG_VERDICT</code>的方式挂载到某些特殊的map上，记录在map里的socket会调用BPF程序。</p>\n<h2 id=\"helper-functions\"><a href=\"#helper-functions\" class=\"headerlink\" title=\"helper functions\"></a>helper functions</h2><p><a href=\"http://man7.org/linux/man-pages/man7/bpf-helpers.7.html\" target=\"_blank\" rel=\"external\">helper functions</a>是提供给BPF程序使用的辅助函数，BPF程序通常无法直接访问内核数据，所以提供了helper functions，通过这些函数完成一些辅助工作，比如从内核获取数据，操作内核的对象。<br>不同的BPF程序类型可以使用部分的辅助函数，例如XDP（<code>BPF_PROG_TYPE_XDP</code>）类型程序能使用的辅助函数在<a href=\"https://github.com/torvalds/linux/blob/v5.4/net/core/filter.c#L6226\" target=\"_blank\" rel=\"external\">这里</a>定义。</p>\n<h2 id=\"maps\"><a href=\"#maps\" class=\"headerlink\" title=\"maps\"></a>maps</h2><p>maps是BPF程序中驻留在内核中存储 key/value 数据的存储方式的统称，实际上BPF提供了<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L112\" target=\"_blank\" rel=\"external\">很多类型的map</a>，很多map类型都有一些特殊的使用方式。BPF程序可以通过helper function读写map，用户态程序也可以通过<code>bpf(...)</code>系统调用读写map，因此可以通过map来达到BPF程序之间，BPF程序与用户态程序之间的数据交互与控制。<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">enum</span> bpf_map_type &#123;</div><div class=\"line\">\tBPF_MAP_TYPE_UNSPEC,</div><div class=\"line\">\tBPF_MAP_TYPE_HASH,</div><div class=\"line\">\tBPF_MAP_TYPE_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_PROG_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_PERF_EVENT_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_PERCPU_HASH,</div><div class=\"line\">\tBPF_MAP_TYPE_PERCPU_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_STACK_TRACE,</div><div class=\"line\">\tBPF_MAP_TYPE_CGROUP_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_LRU_HASH,</div><div class=\"line\">\tBPF_MAP_TYPE_LRU_PERCPU_HASH,</div><div class=\"line\">\tBPF_MAP_TYPE_LPM_TRIE,</div><div class=\"line\">\tBPF_MAP_TYPE_ARRAY_OF_MAPS,</div><div class=\"line\">\tBPF_MAP_TYPE_HASH_OF_MAPS,</div><div class=\"line\">\tBPF_MAP_TYPE_DEVMAP,</div><div class=\"line\">\tBPF_MAP_TYPE_SOCKMAP,</div><div class=\"line\">\tBPF_MAP_TYPE_CPUMAP,</div><div class=\"line\">\tBPF_MAP_TYPE_XSKMAP,</div><div class=\"line\">\tBPF_MAP_TYPE_SOCKHASH,</div><div class=\"line\">\tBPF_MAP_TYPE_CGROUP_STORAGE,</div><div class=\"line\">\tBPF_MAP_TYPE_REUSEPORT_SOCKARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_PERCPU_CGROUP_STORAGE,</div><div class=\"line\">\tBPF_MAP_TYPE_QUEUE,</div><div class=\"line\">\tBPF_MAP_TYPE_STACK,</div><div class=\"line\">\tBPF_MAP_TYPE_SK_STORAGE,</div><div class=\"line\">\tBPF_MAP_TYPE_DEVMAP_HASH,</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>一个MAP除了需要定义其所属类型，通常还需要定义其kv的大小（BPF并不关心其实际类型，可以看作是按字节码存储）以及最大的entry数，另外还可以指定是否提前分配内存，例如<code>BPF_MAP_TYPE_LPM_TRIE</code>类型的map就需要在创建时指定不分配entry。<br>下面介绍几个比较常用的Map类型：</p>\n<ul>\n<li><code>BPF_MAP_TYPE_HASH</code>是大家普遍理解的kv存储的map，kv大小由用户自定义。</li>\n<li><code>BPF_MAP_TYPE_ARRAY</code>是数组，只能通过int类型作为key来访问map。</li>\n<li><code>BPF_MAP_TYPE_PROG_ARRAY</code>是一个特殊的存储，这个数组里存的是BPF程序。后文中我们会提到单个BPF程序限定了不能超过4096条指令，如果一个程序态复杂无法在4096条指令内完成，BPF提供了<code>BPF_MAP_TYPE_PROG_ARRAY</code>这个MAP来存储多个BPF程序，用户将拆分的BPF程序存入MAP中，BPF程序之间可以通过<code>tail-call</code>的形式来调用。</li>\n<li><code>BPF_MAP_TYPE_PERCPU_HASH</code> <code>BPF_MAP_TYPE_PERCPU_ARRAY</code> 类似于 <code>BPF_MAP_TYPE_HASH</code> <code>BPF_MAP_TYPE_ARRAY</code>，只是这类map在每个CPU上都有一个map实例。在BPF中使用helper function访问这类map和非PERCPU map一致，只能访问到本CPU的map，但是用户态得到的是一个数组，用户需要自己根据CPU数来聚合值。</li>\n<li><code>BPF_MAP_TYPE_LPM_TRIE</code>是字典树在BPF里的实现，通常可以用来匹配网段前缀。</li>\n<li><code>BPF_MAP_TYPE_DEVMAP</code>内存储的是网络设备号，XDP程序可以将包直接转发到存储在这里的设备中，提升包转发性能。</li>\n<li><code>BPF_MAP_TYPE_SOCKMAP</code> <code>BPF_MAP_TYPE_SOCKHASH</code>是用来存储socket的存储类型，以后会做详细介绍。</li>\n</ul>\n<hr>\n<p>前面提到，BPF程序是用户编写然后加载到内核由事件驱动来同步执行的，所以如果程序有问题很可能导致内核的不稳定。为了确保BPF程序不影响内核正常工作，不影响执行效率，BPF严格规范了BPF程序。BPF程序的指令数不超过<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf_common.h#L54\" target=\"_blank\" rel=\"external\">4096</a>条，且程序中不能有loop以保证程序最终一定能退出。因此BPF在内核中引入了一个verify组件专门用来做程序的检查工作。实际上verify程序有很对安全检查，在BPF程序加载到内核时就会进行检查，检查的内容远不止指令条数和检测loop那么简单。例如在XDP程序类型中，每次访问包的某个索引位置之前，都需要BPF程序检查是否越界，如果没有检查，verify将会失败。所以虽然BPF程序本身可能逻辑并不复杂，在编写的过程中最好能够做到写一小部分逻辑后就编译加载到内核测试是否能通过检查，否则由于报错信息十分含糊，很难定位到错误的代码。</p>\n<p>编写BPF程序，<a href=\"https://github.com/iovisor/bcc\" target=\"_blank\" rel=\"external\">iovisor/bcc</a>项目是一个很好的开始。使用这个项目，可以在python中写BPF代码直接运行，源码里有许多<a href=\"https://github.com/iovisor/bcc/tree/master/examples\" target=\"_blank\" rel=\"external\">例子</a>可以学习。前面提到，我们可以自己编写BPF程序，然后使用llvm+clang编译成BPF格式的字节码编译命令也十分简单，<code>clang -O2 -target bpf -o bpf prog.o -c bpf prog.c.</code>，然后可以使用系统调用<code>bpf(...)</code>来加载到内核。除了自己写代码操作BPF程序，一些工具也可以帮助我们做到这一点。例如linux源码自带的<a href=\"https://github.com/torvalds/linux/tree/v5.4/tools/bpf/bpftool\" target=\"_blank\" rel=\"external\">bpftool</a>可以操作部分BPF程序和map，iproute可以将BPF程序加载到网卡，tc可以将tc相关BPF程序加载到tc。</p>\n<h1 id=\"参考资料：\"><a href=\"#参考资料：\" class=\"headerlink\" title=\"参考资料：\"></a>参考资料：</h1><ol>\n<li><a href=\"https://www.kernel.org/doc/Documentation/networking/filter.txt\" target=\"_blank\" rel=\"external\">https://www.kernel.org/doc/Documentation/networking/filter.txt</a></li>\n<li><a href=\"https://github.com/iovisor/bcc\" target=\"_blank\" rel=\"external\">https://github.com/iovisor/bcc</a></li>\n<li><a href=\"https://cilium.readthedocs.io/en/stable/bpf/\" target=\"_blank\" rel=\"external\">https://cilium.readthedocs.io/en/stable/bpf/</a></li>\n<li><a href=\"https://lwn.net/Articles/740157/\" target=\"_blank\" rel=\"external\">https://lwn.net/Articles/740157/</a></li>\n</ol>\n","excerpt":"","more":"<h1 id=\"eBPF简介\"><a href=\"#eBPF简介\" class=\"headerlink\" title=\"eBPF简介\"></a>eBPF简介</h1><p>eBPF(extended BPF)可以看作是可以高效且安全的在内核的一些hook point上执行用户代码的一个虚拟机，用户编写的代码被编译成字节码后加载到linux内核，内核内嵌了一个JIT将字节码转成native code后由事件触发形式执行BPF代码。eBPF由BPF发展而来，BPF全称Berkeley Packet Filter，当时主要是为了高效的过滤数据包而设计的，其历史可以追溯到1992年的论文<a href=\"http://www.tcpdump.org/papers/bpf-usenix93.pdf\">The BSD Packet Filter: A New Architecture for User-level Packet Capture</a>中。现在大家说到的BPF实际上是e(extended)BPF，相比于之前的BPF，eBPF是RISC指令集，有了更丰富的指令，11个64位的寄存器。开发者可以使用C语言写BPF程序，然后使用llvm+clang编译成bpf格式的obj file。然后通过bpf()系统调用加载在内核中hook point。下文中提到的BPF如果没有明确说明，都是指代eBPF。</p>\n<p><img src=\"/images/bpf.jpg\" alt=\"eBPF\"></p>\n<p>在BPF出现之前，如果要抓包，需要使用<code>tap</code>工具将所有的包先拷贝到用户态然后使用匹配规则（并不高效的算法）去过滤拿到满足条件的包，而BPF可以将匹配算法在内核执行，不需要全量拷贝数据包到用户空间，且匹配算法更加高效，使得其相对于<code>tap</code>有更高的效率。虽然大家可能不熟悉BPF，但是linux下大名鼎鼎的抓包工具tcpdump即是基于这项技术实现的。</p>\n<p>在介绍eBPF之前，我们先提前感受一下tcpdump中BPF的痕迹。tcpdump中有一个<code>-d</code>参数，<code>Dump the compiled packet-matching code in a human readable form to standard output and stop.</code>，用这个参数可以查看用户输入的匹配规则对应的bpf指令，例如<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"># tcpdump -i eth1 -d tcp and port 22</div><div class=\"line\">(000) ldh      [12] # load half-byte to [x]，读取3层协议号</div><div class=\"line\">(001) jeq      #0x86dd          jt 2\tjf 8 # 如果是IPv6，则根据IPv6检查包</div><div class=\"line\">(002) ldb      [20]</div><div class=\"line\">(003) jeq      #0x6             jt 4\tjf 19</div><div class=\"line\">(004) ldh      [54]</div><div class=\"line\">(005) jeq      #0x16            jt 18\tjf 6</div><div class=\"line\">(006) ldh      [56]</div><div class=\"line\">(007) jeq      #0x16            jt 18\tjf 19</div><div class=\"line\">(008) jeq      #0x800           jt 9\tjf 19 # 判断是否为IPv4协议</div><div class=\"line\">(009) ldb      [23]                           # 加载4层协议号</div><div class=\"line\">(010) jeq      #0x6             jt 11\tjf 19 # TCP协议号</div><div class=\"line\">(011) ldh      [20]                           # 加载 Flags和Fragment Offset</div><div class=\"line\">(012) jset     #0x1fff          jt 19\tjf 13 # （前3bit是Flag）检测Fragment Offset 如果是IP分片，return 0</div><div class=\"line\">(013) ldxb     4*([14]&amp;0xf)                   # 加载 ip header的length</div><div class=\"line\">(014) ldh      [x + 14]                       # 加载src port</div><div class=\"line\">(015) jeq      #0x16            jt 18\tjf 16 # = 22</div><div class=\"line\">(016) ldh      [x + 16]                       # 加载dst port</div><div class=\"line\">(017) jeq      #0x16            jt 18\tjf 19 # = 22</div><div class=\"line\">(018) ret      #262144                        # match</div><div class=\"line\">(019) ret      #0                             # not match</div></pre></td></tr></table></figure></p>\n<pre><code>tcpdump转化的指定是cBPF(classic)，可以看作是eBPF出现之前的BPF。只是在较新的内核(v3.15之后)中，内核支持eBPF，所以有专门的程序会负责将cBPF指令翻译成eBPF指令来执行。\n</code></pre><p>可以看出，tcpdump的规则被翻译成了20条指令，数据包仅仅被看作是字节的数组，指令对从数据包（数组）的不同位置读取(load)数据到寄存器并判断是否满足条件，最后返回。</p>\n<p>tcpdump使用的实际上是传统的BPF(cBPF)，而较新的内核中除了支持cBPF，主要是对eBPF的支持。功能上eBPF相对于cBPF已经做了很大的扩展。目前最新的内核代码中已经有20+类不同的BPF<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L149\">程序类型</a>，根据不同的程序类型，从最初的相对单一的网络包过滤，扩展出了一个通用的内核虚拟机，可以将BPF程序附着到tracepoint/kprobe/uprobe/USDT，可以支持seccomp，扩展更多的网络功能例如配合tc完成更多的数据包处理能力，使用XDP提升网络性能等。从指令集来看，相对于cBPF，eBPF有更丰富的<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L14\">指令集</a>，支持了更多的<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L46\">寄存器</a>。此外，还引入了helper functions和maps。不同版本内核支持的BPF特性可以参考<a href=\"https://github.com/iovisor/bcc/blob/master/docs/kernel-versions.md\">这里</a>。</p>\n<h2 id=\"prog-type\"><a href=\"#prog-type\" class=\"headerlink\" title=\"prog type\"></a>prog type</h2><p>每个BPF程序都属于某个特定的程序类型，目前内核支持20+不同类型的BPF程序类型，可以大致分为网络，跟踪，安全等几大类，BPF程序的输入参数也根据类型有所不同。<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">enum</span> bpf_prog_type &#123;</div><div class=\"line\">\tBPF_PROG_TYPE_UNSPEC,</div><div class=\"line\">\tBPF_PROG_TYPE_SOCKET_FILTER,</div><div class=\"line\">\tBPF_PROG_TYPE_KPROBE,</div><div class=\"line\">\tBPF_PROG_TYPE_SCHED_CLS,</div><div class=\"line\">\tBPF_PROG_TYPE_SCHED_ACT,</div><div class=\"line\">\tBPF_PROG_TYPE_TRACEPOINT,</div><div class=\"line\">\tBPF_PROG_TYPE_XDP,</div><div class=\"line\">\tBPF_PROG_TYPE_PERF_EVENT,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SKB,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SOCK,</div><div class=\"line\">\tBPF_PROG_TYPE_LWT_IN,</div><div class=\"line\">\tBPF_PROG_TYPE_LWT_OUT,</div><div class=\"line\">\tBPF_PROG_TYPE_LWT_XMIT,</div><div class=\"line\">\tBPF_PROG_TYPE_SOCK_OPS,</div><div class=\"line\">\tBPF_PROG_TYPE_SK_SKB,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_DEVICE,</div><div class=\"line\">\tBPF_PROG_TYPE_SK_MSG,</div><div class=\"line\">\tBPF_PROG_TYPE_RAW_TRACEPOINT,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SOCK_ADDR,</div><div class=\"line\">\tBPF_PROG_TYPE_LWT_SEG6LOCAL,</div><div class=\"line\">\tBPF_PROG_TYPE_LIRC_MODE2,</div><div class=\"line\">\tBPF_PROG_TYPE_SK_REUSEPORT,</div><div class=\"line\">\tBPF_PROG_TYPE_FLOW_DISSECTOR,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SYSCTL,</div><div class=\"line\">\tBPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE,</div><div class=\"line\">\tBPF_PROG_TYPE_CGROUP_SOCKOPT,</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>例如，<code>BPF_PROG_TYPE_KPROBE</code> <code>BPF_PROG_TYPE_TRACEPOINT</code> 等属于追踪。<code>BPF_PROG_TYPE_XDP</code>程序用于将BPF程序offload到driver层，在包刚从网卡上接收还未构造成skb之前，即执行BPF代码，效率相比于其他hook点要高，目前已有一些公司用XDP来抵御DDoS攻击，XDP具体使用方式以后再做详细介绍。<code>BPF_PROG_TYPE_SOCK_OPS</code>支持给socket设置一些TCP参数。<code>BPF_PROG_TYPE_SK_MSG</code>程序可以在socket调用sendmsg系统调用时被执行。</p>\n<p>不同的程序类型<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L178\">挂载的方式</a>有所不同，例如<code>BPF_PROG_TYPE_SOCK_OPS</code>程序可以使用<code>BPF_CGROUP_SOCK_OPS</code>方式将程序挂载到cgroup上，属于这个cgroup下的socket会执行程序。<code>BPF_PROG_TYPE_SK_MSG</code>可以以<code>BPF_SK_MSG_VERDICT</code>的方式挂载到某些特殊的map上，记录在map里的socket会调用BPF程序。</p>\n<h2 id=\"helper-functions\"><a href=\"#helper-functions\" class=\"headerlink\" title=\"helper functions\"></a>helper functions</h2><p><a href=\"http://man7.org/linux/man-pages/man7/bpf-helpers.7.html\">helper functions</a>是提供给BPF程序使用的辅助函数，BPF程序通常无法直接访问内核数据，所以提供了helper functions，通过这些函数完成一些辅助工作，比如从内核获取数据，操作内核的对象。<br>不同的BPF程序类型可以使用部分的辅助函数，例如XDP（<code>BPF_PROG_TYPE_XDP</code>）类型程序能使用的辅助函数在<a href=\"https://github.com/torvalds/linux/blob/v5.4/net/core/filter.c#L6226\">这里</a>定义。</p>\n<h2 id=\"maps\"><a href=\"#maps\" class=\"headerlink\" title=\"maps\"></a>maps</h2><p>maps是BPF程序中驻留在内核中存储 key/value 数据的存储方式的统称，实际上BPF提供了<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf.h#L112\">很多类型的map</a>，很多map类型都有一些特殊的使用方式。BPF程序可以通过helper function读写map，用户态程序也可以通过<code>bpf(...)</code>系统调用读写map，因此可以通过map来达到BPF程序之间，BPF程序与用户态程序之间的数据交互与控制。<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">enum</span> bpf_map_type &#123;</div><div class=\"line\">\tBPF_MAP_TYPE_UNSPEC,</div><div class=\"line\">\tBPF_MAP_TYPE_HASH,</div><div class=\"line\">\tBPF_MAP_TYPE_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_PROG_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_PERF_EVENT_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_PERCPU_HASH,</div><div class=\"line\">\tBPF_MAP_TYPE_PERCPU_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_STACK_TRACE,</div><div class=\"line\">\tBPF_MAP_TYPE_CGROUP_ARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_LRU_HASH,</div><div class=\"line\">\tBPF_MAP_TYPE_LRU_PERCPU_HASH,</div><div class=\"line\">\tBPF_MAP_TYPE_LPM_TRIE,</div><div class=\"line\">\tBPF_MAP_TYPE_ARRAY_OF_MAPS,</div><div class=\"line\">\tBPF_MAP_TYPE_HASH_OF_MAPS,</div><div class=\"line\">\tBPF_MAP_TYPE_DEVMAP,</div><div class=\"line\">\tBPF_MAP_TYPE_SOCKMAP,</div><div class=\"line\">\tBPF_MAP_TYPE_CPUMAP,</div><div class=\"line\">\tBPF_MAP_TYPE_XSKMAP,</div><div class=\"line\">\tBPF_MAP_TYPE_SOCKHASH,</div><div class=\"line\">\tBPF_MAP_TYPE_CGROUP_STORAGE,</div><div class=\"line\">\tBPF_MAP_TYPE_REUSEPORT_SOCKARRAY,</div><div class=\"line\">\tBPF_MAP_TYPE_PERCPU_CGROUP_STORAGE,</div><div class=\"line\">\tBPF_MAP_TYPE_QUEUE,</div><div class=\"line\">\tBPF_MAP_TYPE_STACK,</div><div class=\"line\">\tBPF_MAP_TYPE_SK_STORAGE,</div><div class=\"line\">\tBPF_MAP_TYPE_DEVMAP_HASH,</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>一个MAP除了需要定义其所属类型，通常还需要定义其kv的大小（BPF并不关心其实际类型，可以看作是按字节码存储）以及最大的entry数，另外还可以指定是否提前分配内存，例如<code>BPF_MAP_TYPE_LPM_TRIE</code>类型的map就需要在创建时指定不分配entry。<br>下面介绍几个比较常用的Map类型：</p>\n<ul>\n<li><code>BPF_MAP_TYPE_HASH</code>是大家普遍理解的kv存储的map，kv大小由用户自定义。</li>\n<li><code>BPF_MAP_TYPE_ARRAY</code>是数组，只能通过int类型作为key来访问map。</li>\n<li><code>BPF_MAP_TYPE_PROG_ARRAY</code>是一个特殊的存储，这个数组里存的是BPF程序。后文中我们会提到单个BPF程序限定了不能超过4096条指令，如果一个程序态复杂无法在4096条指令内完成，BPF提供了<code>BPF_MAP_TYPE_PROG_ARRAY</code>这个MAP来存储多个BPF程序，用户将拆分的BPF程序存入MAP中，BPF程序之间可以通过<code>tail-call</code>的形式来调用。</li>\n<li><code>BPF_MAP_TYPE_PERCPU_HASH</code> <code>BPF_MAP_TYPE_PERCPU_ARRAY</code> 类似于 <code>BPF_MAP_TYPE_HASH</code> <code>BPF_MAP_TYPE_ARRAY</code>，只是这类map在每个CPU上都有一个map实例。在BPF中使用helper function访问这类map和非PERCPU map一致，只能访问到本CPU的map，但是用户态得到的是一个数组，用户需要自己根据CPU数来聚合值。</li>\n<li><code>BPF_MAP_TYPE_LPM_TRIE</code>是字典树在BPF里的实现，通常可以用来匹配网段前缀。</li>\n<li><code>BPF_MAP_TYPE_DEVMAP</code>内存储的是网络设备号，XDP程序可以将包直接转发到存储在这里的设备中，提升包转发性能。</li>\n<li><code>BPF_MAP_TYPE_SOCKMAP</code> <code>BPF_MAP_TYPE_SOCKHASH</code>是用来存储socket的存储类型，以后会做详细介绍。</li>\n</ul>\n<hr>\n<p>前面提到，BPF程序是用户编写然后加载到内核由事件驱动来同步执行的，所以如果程序有问题很可能导致内核的不稳定。为了确保BPF程序不影响内核正常工作，不影响执行效率，BPF严格规范了BPF程序。BPF程序的指令数不超过<a href=\"https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/bpf_common.h#L54\">4096</a>条，且程序中不能有loop以保证程序最终一定能退出。因此BPF在内核中引入了一个verify组件专门用来做程序的检查工作。实际上verify程序有很对安全检查，在BPF程序加载到内核时就会进行检查，检查的内容远不止指令条数和检测loop那么简单。例如在XDP程序类型中，每次访问包的某个索引位置之前，都需要BPF程序检查是否越界，如果没有检查，verify将会失败。所以虽然BPF程序本身可能逻辑并不复杂，在编写的过程中最好能够做到写一小部分逻辑后就编译加载到内核测试是否能通过检查，否则由于报错信息十分含糊，很难定位到错误的代码。</p>\n<p>编写BPF程序，<a href=\"https://github.com/iovisor/bcc\">iovisor/bcc</a>项目是一个很好的开始。使用这个项目，可以在python中写BPF代码直接运行，源码里有许多<a href=\"https://github.com/iovisor/bcc/tree/master/examples\">例子</a>可以学习。前面提到，我们可以自己编写BPF程序，然后使用llvm+clang编译成BPF格式的字节码编译命令也十分简单，<code>clang -O2 -target bpf -o bpf prog.o -c bpf prog.c.</code>，然后可以使用系统调用<code>bpf(...)</code>来加载到内核。除了自己写代码操作BPF程序，一些工具也可以帮助我们做到这一点。例如linux源码自带的<a href=\"https://github.com/torvalds/linux/tree/v5.4/tools/bpf/bpftool\">bpftool</a>可以操作部分BPF程序和map，iproute可以将BPF程序加载到网卡，tc可以将tc相关BPF程序加载到tc。</p>\n<h1 id=\"参考资料：\"><a href=\"#参考资料：\" class=\"headerlink\" title=\"参考资料：\"></a>参考资料：</h1><ol>\n<li><a href=\"https://www.kernel.org/doc/Documentation/networking/filter.txt\">https://www.kernel.org/doc/Documentation/networking/filter.txt</a></li>\n<li><a href=\"https://github.com/iovisor/bcc\">https://github.com/iovisor/bcc</a></li>\n<li><a href=\"https://cilium.readthedocs.io/en/stable/bpf/\">https://cilium.readthedocs.io/en/stable/bpf/</a></li>\n<li><a href=\"https://lwn.net/Articles/740157/\">https://lwn.net/Articles/740157/</a></li>\n</ol>\n"},{"title":"linux kernel build and submit patch","date":"2020-01-08T10:25:13.000Z","_content":"\n\n> 最近在写bpf/sockmap的时候发现一个sockhash的内核bug，经过一系列定位后终于找到了问题代码并修复，最后将修复的patch提交到了社区。这是第一次向linux kernel提交代码，在这里记录一下~\n\n# linux内核编译\n\n首先需要准备一下编译环境\n\n`apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison`\n\n接下来获取源码进行修改，如果只是在某个版本修改代码且不提交到linux社区，可以直接从[这里](http://cdn.kernel.org/pub/linux/kernel/)下载源码，这个比git clone会快很多。如果希望代码修改后能反馈到社区，则可以`git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git`获取最新代码\n\n进入linux源码目录后，好需要拷贝一份内核配置文件： `cp /boot/config-5.0.0-36-generic .config`\n\n然后可以通过命令`make menuconfig`在图形化界面选择一些配置项，一般我们直接保存退出就可以了。\n\n接下来进行编译，很简单，直接`make -j $(nproc)`进行多核编译，加快编译速度\n\n编译完成后安装内核模块 `make modules_install`\n\n然后安装内核本身 `make install`\n\n最后还需要更新grub 启动项\n\n```\n$ sudo update-initramfs -c -k 5.5.0-rc5\n$ sudo update-grub\n```\n\n最后的最后reboot重启机器，`uname -r`就可以看到是最新的内核版本了\n\n# 提交patch\n\n1. 新建一个分支 `git checkout -t -b fix_sockhash master`\n\n2. 在新分支上修改代码。\n\n3. 生成commit: git commit -s -v。此时会弹出编辑器，需要编辑commit message。\n\n\tcommit message需要按照一定的格式，首行需要按照格式`<subsystem>/<sub-subsystem>: <descriptive comment>` 这样在`git log --oneline`的时候看的更清晰\n\t然后空一行，然后具体描述这个commit做了什么。由于git commit时我们加上了-s参数，所以commit message里可以看到最后有`Signed-off-by` ，也就是作者的签名。如果此path是一个bug-fix, 在此之上最好能附上Fixes tag例如：`Fixes: 604326b41a6fb (\"bpf, sockmap: convert to generic sk_msg interface\")`\n\n\t以下是一个完整的commit message 示例\n\n\t```\n\t    bpf/sockmap: read psock ingress_msg before sk_receive_queue\n\t    \n\t    Right now in tcp_bpf_recvmsg, sock read data first from sk_receive_queue\n\t    if not empty than psock->ingress_msg otherwise. If a FIN packet arrives\n\t    and there's also some data in psock->ingress_msg, the data in\n\t    psock->ingress_msg will be purged. It is always happen when request to a\n\t    HTTP1.0 server like python SimpleHTTPServer since the server send FIN\n\t    packet after data is sent out.\n\t    \n\t    Fixes: 604326b41a6fb (\"bpf, sockmap: convert to generic sk_msg interface\")\n\t    Reported-by: Arika Chen <eaglesora@gmail.com>\n\t    Suggested-by: Arika Chen <eaglesora@gmail.com>\n\t    Signed-off-by: Lingpeng Chen <forrest0579@gmail.com>\n\t    Signed-off-by: John Fastabend <john.fastabend@gmail.com>\n\t```\n\n4. 然后使用脚本生成patch `git format-patch master`，或者 `git format-patch HEAD~<number of commits to convert to patches>` 。\n\n5. 检查patch是否有问题并修复： `./scripts/checkpatch.pl 0001-xxx.patch`。没啥问题就可以准备发邮件给社区review了。\n\n6. 接下来就是发送邮件给社区，建议使用 `git send-email` 功能来发送(需要安装git-email `apt install git-email -y`)\n\n\t首先需要配置一下email的配置信息，编辑`~/.gitconfig`输入相关邮箱信息，例如gmail的配置如下：\n\t```\n\t$ cat ~/.gitconfig:\n\t[user]\n\t\tname = Lingpeng Chen\n\t\temail = myemail@gmail.com\n\n\t[sendemail]\n\t\tfrom = Lingpeng Chen <myemail@gmail.com>\n\t\tsmtpserver = smtp.gmail.com\n\t\tsmtpuser = myemail@gmail.com\n\t\tsmtpencryption = tls\n\t\tsmtppass = mypassword\n\t\tchainreplyto = false\n\t\tsmtpserverport = 587\n\t```\n\n\t这里需要设置smtppass，google账号一般开启了`2-Step 验证`，所以直接使用账号的密码可能会发送失败，此时需要进入 `account->security->app-passwords`里面创建一个新的[应用密码](https://myaccount.google.com/apppasswords)。\n\n\t配置完后可以发送邮件 `git send-email --to \"forrest0579 <forrest0579@gmail.com>\" --cc \"lingpeng chen <cc@example.com>\" 0001-xxx.patch` 可以先往自己的邮箱里面发送看看效果。\n\n\t如果没啥问题，我们再往社区发。这里需要给相关的maintainer和一些邮件组发，可以通过脚本来获取，例如：\n\n\t```\n\t$ ./scripts/get_maintainer.pl 0001-bpf-sockmap-read-psock-ingress_msg-before-sk_receive.patch \n\tEric Dumazet <edumazet@google.com> (maintainer:NETWORKING [TCP])\n\tJohn Fastabend <john.fastabend@gmail.com> (maintainer:L7 BPF FRAMEWORK,blamed_fixes:1/1=100%)\n\tDaniel Borkmann <daniel@iogearbox.net> (maintainer:L7 BPF FRAMEWORK,blamed_fixes:1/1=100%)\n\t\"David S. Miller\" <davem@davemloft.net> (maintainer:NETWORKING [IPv4/IPv6])\n\tAlexey Kuznetsov <kuznet@ms2.inr.ac.ru> (maintainer:NETWORKING [IPv4/IPv6])\n\tHideaki YOSHIFUJI <yoshfuji@linux-ipv6.org> (maintainer:NETWORKING [IPv4/IPv6])\n\tAlexei Starovoitov <ast@kernel.org> (supporter:BPF (Safe dynamic programs and tools),blamed_fixes:1/1=100%)\n\tMartin KaFai Lau <kafai@fb.com> (reviewer:BPF (Safe dynamic programs and tools))\n\tSong Liu <songliubraving@fb.com> (reviewer:BPF (Safe dynamic programs and tools))\n\tYonghong Song <yhs@fb.com> (reviewer:BPF (Safe dynamic programs and tools))\n\tAndrii Nakryiko <andriin@fb.com> (reviewer:BPF (Safe dynamic programs and tools))\n\tnetdev@vger.kernel.org (open list:NETWORKING [TCP])\n\tbpf@vger.kernel.org (open list:L7 BPF FRAMEWORK)\n\tlinux-kernel@vger.kernel.org (open list)\n\t```\n\n\t挑选一些人作为收件对象然后发送邮件。\n\n7. 更新patch\n\t社区的人review之后可能会给出一些意见，修改后还可以使用send-email来回复。此时需要使用`--in-reply-to`来指定回复哪封邮件，邮件的ID可以在邮箱里查看邮件信息看到。例如gmail里可以通过 **显示原始邮件** 得到邮件ID。另外，更新的patch可以使用 `git format-patch -v2`来指定更新的版本号，方便大家review。\n\n\n最后，http://vger.kernel.org/vger-lists.html 这个网址可以看到各个子系统的邮件组信息。发送完后这里会显示你新发的邮件\n\n\n# 参考\n\n1. https://www.cyberciti.biz/tips/compiling-linux-kernel-26.html\n2. https://www.kernel.org/doc/html/latest/process/submitting-patches.html\n3. http://nickdesaulniers.github.io/blog/2017/05/16/submitting-your-first-patch-to-the-linux-kernel-and-responding-to-feedback/\n","source":"_posts/2020-01-08-linux-kernel-build-and-submit-patch.md","raw":"---\ntitle: linux kernel build and submit patch\ndate: 2020-01-08 18:25:13\ntags: [kernel]\n---\n\n\n> 最近在写bpf/sockmap的时候发现一个sockhash的内核bug，经过一系列定位后终于找到了问题代码并修复，最后将修复的patch提交到了社区。这是第一次向linux kernel提交代码，在这里记录一下~\n\n# linux内核编译\n\n首先需要准备一下编译环境\n\n`apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison`\n\n接下来获取源码进行修改，如果只是在某个版本修改代码且不提交到linux社区，可以直接从[这里](http://cdn.kernel.org/pub/linux/kernel/)下载源码，这个比git clone会快很多。如果希望代码修改后能反馈到社区，则可以`git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git`获取最新代码\n\n进入linux源码目录后，好需要拷贝一份内核配置文件： `cp /boot/config-5.0.0-36-generic .config`\n\n然后可以通过命令`make menuconfig`在图形化界面选择一些配置项，一般我们直接保存退出就可以了。\n\n接下来进行编译，很简单，直接`make -j $(nproc)`进行多核编译，加快编译速度\n\n编译完成后安装内核模块 `make modules_install`\n\n然后安装内核本身 `make install`\n\n最后还需要更新grub 启动项\n\n```\n$ sudo update-initramfs -c -k 5.5.0-rc5\n$ sudo update-grub\n```\n\n最后的最后reboot重启机器，`uname -r`就可以看到是最新的内核版本了\n\n# 提交patch\n\n1. 新建一个分支 `git checkout -t -b fix_sockhash master`\n\n2. 在新分支上修改代码。\n\n3. 生成commit: git commit -s -v。此时会弹出编辑器，需要编辑commit message。\n\n\tcommit message需要按照一定的格式，首行需要按照格式`<subsystem>/<sub-subsystem>: <descriptive comment>` 这样在`git log --oneline`的时候看的更清晰\n\t然后空一行，然后具体描述这个commit做了什么。由于git commit时我们加上了-s参数，所以commit message里可以看到最后有`Signed-off-by` ，也就是作者的签名。如果此path是一个bug-fix, 在此之上最好能附上Fixes tag例如：`Fixes: 604326b41a6fb (\"bpf, sockmap: convert to generic sk_msg interface\")`\n\n\t以下是一个完整的commit message 示例\n\n\t```\n\t    bpf/sockmap: read psock ingress_msg before sk_receive_queue\n\t    \n\t    Right now in tcp_bpf_recvmsg, sock read data first from sk_receive_queue\n\t    if not empty than psock->ingress_msg otherwise. If a FIN packet arrives\n\t    and there's also some data in psock->ingress_msg, the data in\n\t    psock->ingress_msg will be purged. It is always happen when request to a\n\t    HTTP1.0 server like python SimpleHTTPServer since the server send FIN\n\t    packet after data is sent out.\n\t    \n\t    Fixes: 604326b41a6fb (\"bpf, sockmap: convert to generic sk_msg interface\")\n\t    Reported-by: Arika Chen <eaglesora@gmail.com>\n\t    Suggested-by: Arika Chen <eaglesora@gmail.com>\n\t    Signed-off-by: Lingpeng Chen <forrest0579@gmail.com>\n\t    Signed-off-by: John Fastabend <john.fastabend@gmail.com>\n\t```\n\n4. 然后使用脚本生成patch `git format-patch master`，或者 `git format-patch HEAD~<number of commits to convert to patches>` 。\n\n5. 检查patch是否有问题并修复： `./scripts/checkpatch.pl 0001-xxx.patch`。没啥问题就可以准备发邮件给社区review了。\n\n6. 接下来就是发送邮件给社区，建议使用 `git send-email` 功能来发送(需要安装git-email `apt install git-email -y`)\n\n\t首先需要配置一下email的配置信息，编辑`~/.gitconfig`输入相关邮箱信息，例如gmail的配置如下：\n\t```\n\t$ cat ~/.gitconfig:\n\t[user]\n\t\tname = Lingpeng Chen\n\t\temail = myemail@gmail.com\n\n\t[sendemail]\n\t\tfrom = Lingpeng Chen <myemail@gmail.com>\n\t\tsmtpserver = smtp.gmail.com\n\t\tsmtpuser = myemail@gmail.com\n\t\tsmtpencryption = tls\n\t\tsmtppass = mypassword\n\t\tchainreplyto = false\n\t\tsmtpserverport = 587\n\t```\n\n\t这里需要设置smtppass，google账号一般开启了`2-Step 验证`，所以直接使用账号的密码可能会发送失败，此时需要进入 `account->security->app-passwords`里面创建一个新的[应用密码](https://myaccount.google.com/apppasswords)。\n\n\t配置完后可以发送邮件 `git send-email --to \"forrest0579 <forrest0579@gmail.com>\" --cc \"lingpeng chen <cc@example.com>\" 0001-xxx.patch` 可以先往自己的邮箱里面发送看看效果。\n\n\t如果没啥问题，我们再往社区发。这里需要给相关的maintainer和一些邮件组发，可以通过脚本来获取，例如：\n\n\t```\n\t$ ./scripts/get_maintainer.pl 0001-bpf-sockmap-read-psock-ingress_msg-before-sk_receive.patch \n\tEric Dumazet <edumazet@google.com> (maintainer:NETWORKING [TCP])\n\tJohn Fastabend <john.fastabend@gmail.com> (maintainer:L7 BPF FRAMEWORK,blamed_fixes:1/1=100%)\n\tDaniel Borkmann <daniel@iogearbox.net> (maintainer:L7 BPF FRAMEWORK,blamed_fixes:1/1=100%)\n\t\"David S. Miller\" <davem@davemloft.net> (maintainer:NETWORKING [IPv4/IPv6])\n\tAlexey Kuznetsov <kuznet@ms2.inr.ac.ru> (maintainer:NETWORKING [IPv4/IPv6])\n\tHideaki YOSHIFUJI <yoshfuji@linux-ipv6.org> (maintainer:NETWORKING [IPv4/IPv6])\n\tAlexei Starovoitov <ast@kernel.org> (supporter:BPF (Safe dynamic programs and tools),blamed_fixes:1/1=100%)\n\tMartin KaFai Lau <kafai@fb.com> (reviewer:BPF (Safe dynamic programs and tools))\n\tSong Liu <songliubraving@fb.com> (reviewer:BPF (Safe dynamic programs and tools))\n\tYonghong Song <yhs@fb.com> (reviewer:BPF (Safe dynamic programs and tools))\n\tAndrii Nakryiko <andriin@fb.com> (reviewer:BPF (Safe dynamic programs and tools))\n\tnetdev@vger.kernel.org (open list:NETWORKING [TCP])\n\tbpf@vger.kernel.org (open list:L7 BPF FRAMEWORK)\n\tlinux-kernel@vger.kernel.org (open list)\n\t```\n\n\t挑选一些人作为收件对象然后发送邮件。\n\n7. 更新patch\n\t社区的人review之后可能会给出一些意见，修改后还可以使用send-email来回复。此时需要使用`--in-reply-to`来指定回复哪封邮件，邮件的ID可以在邮箱里查看邮件信息看到。例如gmail里可以通过 **显示原始邮件** 得到邮件ID。另外，更新的patch可以使用 `git format-patch -v2`来指定更新的版本号，方便大家review。\n\n\n最后，http://vger.kernel.org/vger-lists.html 这个网址可以看到各个子系统的邮件组信息。发送完后这里会显示你新发的邮件\n\n\n# 参考\n\n1. https://www.cyberciti.biz/tips/compiling-linux-kernel-26.html\n2. https://www.kernel.org/doc/html/latest/process/submitting-patches.html\n3. http://nickdesaulniers.github.io/blog/2017/05/16/submitting-your-first-patch-to-the-linux-kernel-and-responding-to-feedback/\n","slug":"linux-kernel-build-and-submit-patch","published":1,"updated":"2020-01-12T09:00:33.480Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck5asg8l10001btv9ya1mp5l7","content":"<blockquote>\n<p>最近在写bpf/sockmap的时候发现一个sockhash的内核bug，经过一系列定位后终于找到了问题代码并修复，最后将修复的patch提交到了社区。这是第一次向linux kernel提交代码，在这里记录一下~</p>\n</blockquote>\n<h1 id=\"linux内核编译\"><a href=\"#linux内核编译\" class=\"headerlink\" title=\"linux内核编译\"></a>linux内核编译</h1><p>首先需要准备一下编译环境</p>\n<p><code>apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison</code></p>\n<p>接下来获取源码进行修改，如果只是在某个版本修改代码且不提交到linux社区，可以直接从<a href=\"http://cdn.kernel.org/pub/linux/kernel/\" target=\"_blank\" rel=\"external\">这里</a>下载源码，这个比git clone会快很多。如果希望代码修改后能反馈到社区，则可以<code>git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git</code>获取最新代码</p>\n<p>进入linux源码目录后，好需要拷贝一份内核配置文件： <code>cp /boot/config-5.0.0-36-generic .config</code></p>\n<p>然后可以通过命令<code>make menuconfig</code>在图形化界面选择一些配置项，一般我们直接保存退出就可以了。</p>\n<p>接下来进行编译，很简单，直接<code>make -j $(nproc)</code>进行多核编译，加快编译速度</p>\n<p>编译完成后安装内核模块 <code>make modules_install</code></p>\n<p>然后安装内核本身 <code>make install</code></p>\n<p>最后还需要更新grub 启动项</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo update-initramfs -c -k 5.5.0-rc5</div><div class=\"line\">$ sudo update-grub</div></pre></td></tr></table></figure>\n<p>最后的最后reboot重启机器，<code>uname -r</code>就可以看到是最新的内核版本了</p>\n<h1 id=\"提交patch\"><a href=\"#提交patch\" class=\"headerlink\" title=\"提交patch\"></a>提交patch</h1><ol>\n<li><p>新建一个分支 <code>git checkout -t -b fix_sockhash master</code></p>\n</li>\n<li><p>在新分支上修改代码。</p>\n</li>\n<li><p>生成commit: git commit -s -v。此时会弹出编辑器，需要编辑commit message。</p>\n<p> commit message需要按照一定的格式，首行需要按照格式<code>&lt;subsystem&gt;/&lt;sub-subsystem&gt;: &lt;descriptive comment&gt;</code> 这样在<code>git log --oneline</code>的时候看的更清晰<br> 然后空一行，然后具体描述这个commit做了什么。由于git commit时我们加上了-s参数，所以commit message里可以看到最后有<code>Signed-off-by</code> ，也就是作者的签名。如果此path是一个bug-fix, 在此之上最好能附上Fixes tag例如：<code>Fixes: 604326b41a6fb (&quot;bpf, sockmap: convert to generic sk_msg interface&quot;)</code></p>\n<p> 以下是一个完整的commit message 示例</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">bpf/sockmap: read psock ingress_msg before sk_receive_queue</div><div class=\"line\"></div><div class=\"line\">Right now in tcp_bpf_recvmsg, sock read data first from sk_receive_queue</div><div class=\"line\">if not empty than psock-&gt;ingress_msg otherwise. If a FIN packet arrives</div><div class=\"line\">and there&apos;s also some data in psock-&gt;ingress_msg, the data in</div><div class=\"line\">psock-&gt;ingress_msg will be purged. It is always happen when request to a</div><div class=\"line\">HTTP1.0 server like python SimpleHTTPServer since the server send FIN</div><div class=\"line\">packet after data is sent out.</div><div class=\"line\"></div><div class=\"line\">Fixes: 604326b41a6fb (&quot;bpf, sockmap: convert to generic sk_msg interface&quot;)</div><div class=\"line\">Reported-by: Arika Chen &lt;eaglesora@gmail.com&gt;</div><div class=\"line\">Suggested-by: Arika Chen &lt;eaglesora@gmail.com&gt;</div><div class=\"line\">Signed-off-by: Lingpeng Chen &lt;forrest0579@gmail.com&gt;</div><div class=\"line\">Signed-off-by: John Fastabend &lt;john.fastabend@gmail.com&gt;</div></pre></td></tr></table></figure>\n</li>\n<li><p>然后使用脚本生成patch <code>git format-patch master</code>，或者 <code>git format-patch HEAD~&lt;number of commits to convert to patches&gt;</code> 。</p>\n</li>\n<li><p>检查patch是否有问题并修复： <code>./scripts/checkpatch.pl 0001-xxx.patch</code>。没啥问题就可以准备发邮件给社区review了。</p>\n</li>\n<li><p>接下来就是发送邮件给社区，建议使用 <code>git send-email</code> 功能来发送(需要安装git-email <code>apt install git-email -y</code>)</p>\n<p> 首先需要配置一下email的配置信息，编辑<code>~/.gitconfig</code>输入相关邮箱信息，例如gmail的配置如下：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cat ~/.gitconfig:</div><div class=\"line\">[user]</div><div class=\"line\">\tname = Lingpeng Chen</div><div class=\"line\">\temail = myemail@gmail.com</div><div class=\"line\"></div><div class=\"line\">[sendemail]</div><div class=\"line\">\tfrom = Lingpeng Chen &lt;myemail@gmail.com&gt;</div><div class=\"line\">\tsmtpserver = smtp.gmail.com</div><div class=\"line\">\tsmtpuser = myemail@gmail.com</div><div class=\"line\">\tsmtpencryption = tls</div><div class=\"line\">\tsmtppass = mypassword</div><div class=\"line\">\tchainreplyto = false</div><div class=\"line\">\tsmtpserverport = 587</div></pre></td></tr></table></figure>\n<p> 这里需要设置smtppass，google账号一般开启了<code>2-Step 验证</code>，所以直接使用账号的密码可能会发送失败，此时需要进入 <code>account-&gt;security-&gt;app-passwords</code>里面创建一个新的<a href=\"https://myaccount.google.com/apppasswords\" target=\"_blank\" rel=\"external\">应用密码</a>。</p>\n<p> 配置完后可以发送邮件 <code>git send-email --to &quot;forrest0579 &lt;forrest0579@gmail.com&gt;&quot; --cc &quot;lingpeng chen &lt;cc@example.com&gt;&quot; 0001-xxx.patch</code> 可以先往自己的邮箱里面发送看看效果。</p>\n<p> 如果没啥问题，我们再往社区发。这里需要给相关的maintainer和一些邮件组发，可以通过脚本来获取，例如：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ ./scripts/get_maintainer.pl 0001-bpf-sockmap-read-psock-ingress_msg-before-sk_receive.patch </div><div class=\"line\">Eric Dumazet &lt;edumazet@google.com&gt; (maintainer:NETWORKING [TCP])</div><div class=\"line\">John Fastabend &lt;john.fastabend@gmail.com&gt; (maintainer:L7 BPF FRAMEWORK,blamed_fixes:1/1=100%)</div><div class=\"line\">Daniel Borkmann &lt;daniel@iogearbox.net&gt; (maintainer:L7 BPF FRAMEWORK,blamed_fixes:1/1=100%)</div><div class=\"line\">&quot;David S. Miller&quot; &lt;davem@davemloft.net&gt; (maintainer:NETWORKING [IPv4/IPv6])</div><div class=\"line\">Alexey Kuznetsov &lt;kuznet@ms2.inr.ac.ru&gt; (maintainer:NETWORKING [IPv4/IPv6])</div><div class=\"line\">Hideaki YOSHIFUJI &lt;yoshfuji@linux-ipv6.org&gt; (maintainer:NETWORKING [IPv4/IPv6])</div><div class=\"line\">Alexei Starovoitov &lt;ast@kernel.org&gt; (supporter:BPF (Safe dynamic programs and tools),blamed_fixes:1/1=100%)</div><div class=\"line\">Martin KaFai Lau &lt;kafai@fb.com&gt; (reviewer:BPF (Safe dynamic programs and tools))</div><div class=\"line\">Song Liu &lt;songliubraving@fb.com&gt; (reviewer:BPF (Safe dynamic programs and tools))</div><div class=\"line\">Yonghong Song &lt;yhs@fb.com&gt; (reviewer:BPF (Safe dynamic programs and tools))</div><div class=\"line\">Andrii Nakryiko &lt;andriin@fb.com&gt; (reviewer:BPF (Safe dynamic programs and tools))</div><div class=\"line\">netdev@vger.kernel.org (open list:NETWORKING [TCP])</div><div class=\"line\">bpf@vger.kernel.org (open list:L7 BPF FRAMEWORK)</div><div class=\"line\">linux-kernel@vger.kernel.org (open list)</div></pre></td></tr></table></figure>\n<p> 挑选一些人作为收件对象然后发送邮件。</p>\n</li>\n<li><p>更新patch<br> 社区的人review之后可能会给出一些意见，修改后还可以使用send-email来回复。此时需要使用<code>--in-reply-to</code>来指定回复哪封邮件，邮件的ID可以在邮箱里查看邮件信息看到。例如gmail里可以通过 <strong>显示原始邮件</strong> 得到邮件ID。另外，更新的patch可以使用 <code>git format-patch -v2</code>来指定更新的版本号，方便大家review。</p>\n</li>\n</ol>\n<p>最后，<a href=\"http://vger.kernel.org/vger-lists.html\" target=\"_blank\" rel=\"external\">http://vger.kernel.org/vger-lists.html</a> 这个网址可以看到各个子系统的邮件组信息。发送完后这里会显示你新发的邮件</p>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ol>\n<li><a href=\"https://www.cyberciti.biz/tips/compiling-linux-kernel-26.html\" target=\"_blank\" rel=\"external\">https://www.cyberciti.biz/tips/compiling-linux-kernel-26.html</a></li>\n<li><a href=\"https://www.kernel.org/doc/html/latest/process/submitting-patches.html\" target=\"_blank\" rel=\"external\">https://www.kernel.org/doc/html/latest/process/submitting-patches.html</a></li>\n<li><a href=\"http://nickdesaulniers.github.io/blog/2017/05/16/submitting-your-first-patch-to-the-linux-kernel-and-responding-to-feedback/\" target=\"_blank\" rel=\"external\">http://nickdesaulniers.github.io/blog/2017/05/16/submitting-your-first-patch-to-the-linux-kernel-and-responding-to-feedback/</a></li>\n</ol>\n","excerpt":"","more":"<blockquote>\n<p>最近在写bpf/sockmap的时候发现一个sockhash的内核bug，经过一系列定位后终于找到了问题代码并修复，最后将修复的patch提交到了社区。这是第一次向linux kernel提交代码，在这里记录一下~</p>\n</blockquote>\n<h1 id=\"linux内核编译\"><a href=\"#linux内核编译\" class=\"headerlink\" title=\"linux内核编译\"></a>linux内核编译</h1><p>首先需要准备一下编译环境</p>\n<p><code>apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison</code></p>\n<p>接下来获取源码进行修改，如果只是在某个版本修改代码且不提交到linux社区，可以直接从<a href=\"http://cdn.kernel.org/pub/linux/kernel/\">这里</a>下载源码，这个比git clone会快很多。如果希望代码修改后能反馈到社区，则可以<code>git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git</code>获取最新代码</p>\n<p>进入linux源码目录后，好需要拷贝一份内核配置文件： <code>cp /boot/config-5.0.0-36-generic .config</code></p>\n<p>然后可以通过命令<code>make menuconfig</code>在图形化界面选择一些配置项，一般我们直接保存退出就可以了。</p>\n<p>接下来进行编译，很简单，直接<code>make -j $(nproc)</code>进行多核编译，加快编译速度</p>\n<p>编译完成后安装内核模块 <code>make modules_install</code></p>\n<p>然后安装内核本身 <code>make install</code></p>\n<p>最后还需要更新grub 启动项</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo update-initramfs -c -k 5.5.0-rc5</div><div class=\"line\">$ sudo update-grub</div></pre></td></tr></table></figure>\n<p>最后的最后reboot重启机器，<code>uname -r</code>就可以看到是最新的内核版本了</p>\n<h1 id=\"提交patch\"><a href=\"#提交patch\" class=\"headerlink\" title=\"提交patch\"></a>提交patch</h1><ol>\n<li><p>新建一个分支 <code>git checkout -t -b fix_sockhash master</code></p>\n</li>\n<li><p>在新分支上修改代码。</p>\n</li>\n<li><p>生成commit: git commit -s -v。此时会弹出编辑器，需要编辑commit message。</p>\n<p> commit message需要按照一定的格式，首行需要按照格式<code>&lt;subsystem&gt;/&lt;sub-subsystem&gt;: &lt;descriptive comment&gt;</code> 这样在<code>git log --oneline</code>的时候看的更清晰<br> 然后空一行，然后具体描述这个commit做了什么。由于git commit时我们加上了-s参数，所以commit message里可以看到最后有<code>Signed-off-by</code> ，也就是作者的签名。如果此path是一个bug-fix, 在此之上最好能附上Fixes tag例如：<code>Fixes: 604326b41a6fb (&quot;bpf, sockmap: convert to generic sk_msg interface&quot;)</code></p>\n<p> 以下是一个完整的commit message 示例</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">bpf/sockmap: read psock ingress_msg before sk_receive_queue</div><div class=\"line\"></div><div class=\"line\">Right now in tcp_bpf_recvmsg, sock read data first from sk_receive_queue</div><div class=\"line\">if not empty than psock-&gt;ingress_msg otherwise. If a FIN packet arrives</div><div class=\"line\">and there&apos;s also some data in psock-&gt;ingress_msg, the data in</div><div class=\"line\">psock-&gt;ingress_msg will be purged. It is always happen when request to a</div><div class=\"line\">HTTP1.0 server like python SimpleHTTPServer since the server send FIN</div><div class=\"line\">packet after data is sent out.</div><div class=\"line\"></div><div class=\"line\">Fixes: 604326b41a6fb (&quot;bpf, sockmap: convert to generic sk_msg interface&quot;)</div><div class=\"line\">Reported-by: Arika Chen &lt;eaglesora@gmail.com&gt;</div><div class=\"line\">Suggested-by: Arika Chen &lt;eaglesora@gmail.com&gt;</div><div class=\"line\">Signed-off-by: Lingpeng Chen &lt;forrest0579@gmail.com&gt;</div><div class=\"line\">Signed-off-by: John Fastabend &lt;john.fastabend@gmail.com&gt;</div></pre></td></tr></table></figure>\n</li>\n<li><p>然后使用脚本生成patch <code>git format-patch master</code>，或者 <code>git format-patch HEAD~&lt;number of commits to convert to patches&gt;</code> 。</p>\n</li>\n<li><p>检查patch是否有问题并修复： <code>./scripts/checkpatch.pl 0001-xxx.patch</code>。没啥问题就可以准备发邮件给社区review了。</p>\n</li>\n<li><p>接下来就是发送邮件给社区，建议使用 <code>git send-email</code> 功能来发送(需要安装git-email <code>apt install git-email -y</code>)</p>\n<p> 首先需要配置一下email的配置信息，编辑<code>~/.gitconfig</code>输入相关邮箱信息，例如gmail的配置如下：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cat ~/.gitconfig:</div><div class=\"line\">[user]</div><div class=\"line\">\tname = Lingpeng Chen</div><div class=\"line\">\temail = myemail@gmail.com</div><div class=\"line\"></div><div class=\"line\">[sendemail]</div><div class=\"line\">\tfrom = Lingpeng Chen &lt;myemail@gmail.com&gt;</div><div class=\"line\">\tsmtpserver = smtp.gmail.com</div><div class=\"line\">\tsmtpuser = myemail@gmail.com</div><div class=\"line\">\tsmtpencryption = tls</div><div class=\"line\">\tsmtppass = mypassword</div><div class=\"line\">\tchainreplyto = false</div><div class=\"line\">\tsmtpserverport = 587</div></pre></td></tr></table></figure>\n<p> 这里需要设置smtppass，google账号一般开启了<code>2-Step 验证</code>，所以直接使用账号的密码可能会发送失败，此时需要进入 <code>account-&gt;security-&gt;app-passwords</code>里面创建一个新的<a href=\"https://myaccount.google.com/apppasswords\">应用密码</a>。</p>\n<p> 配置完后可以发送邮件 <code>git send-email --to &quot;forrest0579 &lt;forrest0579@gmail.com&gt;&quot; --cc &quot;lingpeng chen &lt;cc@example.com&gt;&quot; 0001-xxx.patch</code> 可以先往自己的邮箱里面发送看看效果。</p>\n<p> 如果没啥问题，我们再往社区发。这里需要给相关的maintainer和一些邮件组发，可以通过脚本来获取，例如：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ ./scripts/get_maintainer.pl 0001-bpf-sockmap-read-psock-ingress_msg-before-sk_receive.patch </div><div class=\"line\">Eric Dumazet &lt;edumazet@google.com&gt; (maintainer:NETWORKING [TCP])</div><div class=\"line\">John Fastabend &lt;john.fastabend@gmail.com&gt; (maintainer:L7 BPF FRAMEWORK,blamed_fixes:1/1=100%)</div><div class=\"line\">Daniel Borkmann &lt;daniel@iogearbox.net&gt; (maintainer:L7 BPF FRAMEWORK,blamed_fixes:1/1=100%)</div><div class=\"line\">&quot;David S. Miller&quot; &lt;davem@davemloft.net&gt; (maintainer:NETWORKING [IPv4/IPv6])</div><div class=\"line\">Alexey Kuznetsov &lt;kuznet@ms2.inr.ac.ru&gt; (maintainer:NETWORKING [IPv4/IPv6])</div><div class=\"line\">Hideaki YOSHIFUJI &lt;yoshfuji@linux-ipv6.org&gt; (maintainer:NETWORKING [IPv4/IPv6])</div><div class=\"line\">Alexei Starovoitov &lt;ast@kernel.org&gt; (supporter:BPF (Safe dynamic programs and tools),blamed_fixes:1/1=100%)</div><div class=\"line\">Martin KaFai Lau &lt;kafai@fb.com&gt; (reviewer:BPF (Safe dynamic programs and tools))</div><div class=\"line\">Song Liu &lt;songliubraving@fb.com&gt; (reviewer:BPF (Safe dynamic programs and tools))</div><div class=\"line\">Yonghong Song &lt;yhs@fb.com&gt; (reviewer:BPF (Safe dynamic programs and tools))</div><div class=\"line\">Andrii Nakryiko &lt;andriin@fb.com&gt; (reviewer:BPF (Safe dynamic programs and tools))</div><div class=\"line\">netdev@vger.kernel.org (open list:NETWORKING [TCP])</div><div class=\"line\">bpf@vger.kernel.org (open list:L7 BPF FRAMEWORK)</div><div class=\"line\">linux-kernel@vger.kernel.org (open list)</div></pre></td></tr></table></figure>\n<p> 挑选一些人作为收件对象然后发送邮件。</p>\n</li>\n<li><p>更新patch<br> 社区的人review之后可能会给出一些意见，修改后还可以使用send-email来回复。此时需要使用<code>--in-reply-to</code>来指定回复哪封邮件，邮件的ID可以在邮箱里查看邮件信息看到。例如gmail里可以通过 <strong>显示原始邮件</strong> 得到邮件ID。另外，更新的patch可以使用 <code>git format-patch -v2</code>来指定更新的版本号，方便大家review。</p>\n</li>\n</ol>\n<p>最后，<a href=\"http://vger.kernel.org/vger-lists.html\">http://vger.kernel.org/vger-lists.html</a> 这个网址可以看到各个子系统的邮件组信息。发送完后这里会显示你新发的邮件</p>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ol>\n<li><a href=\"https://www.cyberciti.biz/tips/compiling-linux-kernel-26.html\">https://www.cyberciti.biz/tips/compiling-linux-kernel-26.html</a></li>\n<li><a href=\"https://www.kernel.org/doc/html/latest/process/submitting-patches.html\">https://www.kernel.org/doc/html/latest/process/submitting-patches.html</a></li>\n<li><a href=\"http://nickdesaulniers.github.io/blog/2017/05/16/submitting-your-first-patch-to-the-linux-kernel-and-responding-to-feedback/\">http://nickdesaulniers.github.io/blog/2017/05/16/submitting-your-first-patch-to-the-linux-kernel-and-responding-to-feedback/</a></li>\n</ol>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ck5asapyv0006phv9cqz5o31i","category_id":"ck5asapz0000aphv9se6o7cms","_id":"ck5asapz6000lphv96d1vvave"},{"post_id":"ck5asapyy0009phv9foqgyepc","category_id":"ck5asapz0000aphv9se6o7cms","_id":"ck5asapz9000qphv9uuihxy6z"},{"post_id":"ck5asapz1000cphv9jwp171e7","category_id":"ck5asapz0000aphv9se6o7cms","_id":"ck5asapza000uphv92rgk72st"},{"post_id":"ck5asapz2000fphv9dbr2neym","category_id":"ck5asapz9000rphv9b6gzs199","_id":"ck5asapza000xphv97obh6v8h"},{"post_id":"ck5asaqi30016phv9nr7hsyey","category_id":"ck5asaqif0019phv97batfqk8","_id":"ck5asaqik001iphv9v9gtacum"}],"PostTag":[{"post_id":"ck5asapyu0005phv9j4ggygxi","tag_id":"ck5asapys0003phv9v7m69fe0","_id":"ck5asapyy0008phv91neleu4i"},{"post_id":"ck5asapyq0001phv996qzh3c8","tag_id":"ck5asapys0003phv9v7m69fe0","_id":"ck5asapz0000bphv90r89kivk"},{"post_id":"ck5asapyr0002phv98yij1t7v","tag_id":"ck5asapys0003phv9v7m69fe0","_id":"ck5asapz2000ephv9z4je5dnl"},{"post_id":"ck5asapyt0004phv9wd74tp2c","tag_id":"ck5asapz1000dphv91u6ljc2r","_id":"ck5asapz6000kphv9nratey0f"},{"post_id":"ck5asapyv0006phv9cqz5o31i","tag_id":"ck5asapz5000iphv9deauql8k","_id":"ck5asapz8000pphv90apca95d"},{"post_id":"ck5asapyy0009phv9foqgyepc","tag_id":"ck5asapz5000iphv9deauql8k","_id":"ck5asapza000tphv9gsv7chhj"},{"post_id":"ck5asapz1000cphv9jwp171e7","tag_id":"ck5asapz5000iphv9deauql8k","_id":"ck5asapza000wphv9bfmhobfl"},{"post_id":"ck5asapz3000gphv9qaydz238","tag_id":"ck5asapza000vphv9pkt7ulnf","_id":"ck5asapzb0010phv9xfckpom0"},{"post_id":"ck5asapz3000gphv9qaydz238","tag_id":"ck5asapzb000yphv9q4kcnvht","_id":"ck5asapzb0011phv9tan1mla9"},{"post_id":"ck5asapz5000jphv955drme57","tag_id":"ck5asapzb000zphv9do5o36rf","_id":"ck5asapzc0013phv9802prmg9"},{"post_id":"ck5asapz6000mphv9b05ktbn0","tag_id":"ck5asapzb0012phv966bg3thb","_id":"ck5asapzc0014phv964gmkl1r"},{"post_id":"ck5asaqi20015phv9906lxl5y","tag_id":"ck5asaqie0017phv9ho9mxnq8","_id":"ck5asaqii001dphv933pmxs2v"},{"post_id":"ck5asaqih001bphv9w58bdl9v","tag_id":"ck5asaqie0017phv9ho9mxnq8","_id":"ck5asaqij001fphv9gdshg29i"},{"post_id":"ck5asaqih001bphv9w58bdl9v","tag_id":"ck5asapza000vphv9pkt7ulnf","_id":"ck5asaqik001jphv9sabq8psx"},{"post_id":"ck5asaqii001ephv96cmwtzsr","tag_id":"ck5asaqie0017phv9ho9mxnq8","_id":"ck5asaqil001lphv9nvi6qxu7"},{"post_id":"ck5asaqij001gphv9vntukbjh","tag_id":"ck5asaqie0017phv9ho9mxnq8","_id":"ck5asaqim001nphv95eyx1o1t"},{"post_id":"ck5asaqij001gphv9vntukbjh","tag_id":"ck5asapza000vphv9pkt7ulnf","_id":"ck5asaqim001ophv9zatu1rz3"},{"post_id":"ck5asaqik001kphv9bld5ezhu","tag_id":"ck5asaqie0017phv9ho9mxnq8","_id":"ck5asaqim001qphv95h00rxvb"},{"post_id":"ck5asaqik001kphv9bld5ezhu","tag_id":"ck5asapza000vphv9pkt7ulnf","_id":"ck5asaqin001rphv9f7qs0s3r"},{"post_id":"ck5asaqi30016phv9nr7hsyey","tag_id":"ck5asaqih001cphv975tx0vxh","_id":"ck5asaqin001tphv9ycibzzt5"},{"post_id":"ck5asaqi30016phv9nr7hsyey","tag_id":"ck5asaqik001hphv9z2i5lsz7","_id":"ck5asaqio001uphv9ccg7zqq2"},{"post_id":"ck5asaqie0018phv9kbenq27o","tag_id":"ck5asaqie0017phv9ho9mxnq8","_id":"ck5asaqio001vphv9hpa8um98"},{"post_id":"ck5asaqie0018phv9kbenq27o","tag_id":"ck5asaqim001pphv9epuz3oh5","_id":"ck5asaqio001wphv9f4g4pak5"},{"post_id":"ck5asaqig001aphv9asr4865j","tag_id":"ck5asaqie0017phv9ho9mxnq8","_id":"ck5asaqio001xphv9bqzjepa6"},{"post_id":"ck5asaqig001aphv9asr4865j","tag_id":"ck5asaqin001sphv9j4vh98xe","_id":"ck5asaqio001yphv9j64iro27"},{"post_id":"ck5asg8kx0000btv9yft380sc","tag_id":"ck5asg8l30002btv9dijjcp0r","_id":"ck5asg8l90004btv9yei1vcjj"},{"post_id":"ck5asg8l10001btv9ya1mp5l7","tag_id":"ck5asg8l80003btv9a8wwqszc","_id":"ck5asg8la0005btv9jfgm3nvs"}],"Tag":[{"name":"neural network","_id":"ck5asapys0003phv9v7m69fe0"},{"name":"others","_id":"ck5asapz1000dphv91u6ljc2r"},{"name":"algorithm","_id":"ck5asapz5000iphv9deauql8k"},{"name":"kubernetes","_id":"ck5asapza000vphv9pkt7ulnf"},{"name":"kubelet","_id":"ck5asapzb000yphv9q4kcnvht"},{"name":"tc","_id":"ck5asapzb000zphv9do5o36rf"},{"name":"Distributed System","_id":"ck5asapzb0012phv966bg3thb"},{"name":"network","_id":"ck5asaqie0017phv9ho9mxnq8"},{"name":"lang","_id":"ck5asaqih001cphv975tx0vxh"},{"name":"golang","_id":"ck5asaqik001hphv9z2i5lsz7"},{"name":"tcpdump","_id":"ck5asaqim001pphv9epuz3oh5"},{"name":"calico","_id":"ck5asaqin001sphv9j4vh98xe"},{"name":"ebpf","_id":"ck5asg8l30002btv9dijjcp0r"},{"name":"kernel","_id":"ck5asg8l80003btv9a8wwqszc"}]}}